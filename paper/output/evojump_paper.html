<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>combined_paper</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" />
</head>
<body>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#abstract" id="toc-abstract"><span
class="toc-section-number">1</span> Abstract</a></li>
<li><a href="#introduction" id="toc-introduction"><span
class="toc-section-number">2</span> Introduction</a>
<ul>
<li><a href="#background-and-motivation"
id="toc-background-and-motivation"><span
class="toc-section-number">2.1</span> Background and Motivation</a></li>
<li><a href="#conceptual-framework-cross-sectional-analysis"
id="toc-conceptual-framework-cross-sectional-analysis"><span
class="toc-section-number">2.2</span> Conceptual Framework:
Cross-Sectional Analysis</a></li>
<li><a href="#objectives-and-contributions"
id="toc-objectives-and-contributions"><span
class="toc-section-number">2.3</span> Objectives and
Contributions</a></li>
<li><a href="#paper-organization" id="toc-paper-organization"><span
class="toc-section-number">2.4</span> Paper Organization</a></li>
</ul></li>
<li><a href="#mathematical-foundations"
id="toc-mathematical-foundations"><span
class="toc-section-number">3</span> Mathematical Foundations</a>
<ul>
<li><a href="#stochastic-process-modeling-in-biology"
id="toc-stochastic-process-modeling-in-biology"><span
class="toc-section-number">3.1</span> Stochastic Process Modeling in
Biology</a>
<ul>
<li><a href="#ornstein-uhlenbeck-processes"
id="toc-ornstein-uhlenbeck-processes"><span
class="toc-section-number">3.1.1</span> Ornstein-Uhlenbeck
Processes</a></li>
<li><a href="#fractional-brownian-motion"
id="toc-fractional-brownian-motion"><span
class="toc-section-number">3.1.2</span> Fractional Brownian
Motion</a></li>
<li><a href="#cox-ingersoll-ross-process"
id="toc-cox-ingersoll-ross-process"><span
class="toc-section-number">3.1.3</span> Cox-Ingersoll-Ross
Process</a></li>
<li><a href="#lévy-processes" id="toc-lévy-processes"><span
class="toc-section-number">3.1.4</span> Lévy Processes</a></li>
</ul></li>
<li><a href="#general-framework" id="toc-general-framework"><span
class="toc-section-number">3.2</span> General Framework</a>
<ul>
<li><a href="#jump-diffusion-framework"
id="toc-jump-diffusion-framework"><span
class="toc-section-number">3.2.1</span> Jump-Diffusion
Framework</a></li>
</ul></li>
<li><a href="#ornstein-uhlenbeck-process-with-jumps"
id="toc-ornstein-uhlenbeck-process-with-jumps"><span
class="toc-section-number">3.3</span> Ornstein-Uhlenbeck Process with
Jumps</a>
<ul>
<li><a href="#model-specification" id="toc-model-specification"><span
class="toc-section-number">3.3.1</span> Model Specification</a></li>
<li><a href="#analytical-properties"
id="toc-analytical-properties"><span
class="toc-section-number">3.3.2</span> Analytical Properties</a></li>
<li><a href="#parameter-estimation" id="toc-parameter-estimation"><span
class="toc-section-number">3.3.3</span> Parameter Estimation</a></li>
</ul></li>
<li><a href="#fractional-brownian-motion-1"
id="toc-fractional-brownian-motion-1"><span
class="toc-section-number">3.4</span> Fractional Brownian Motion</a>
<ul>
<li><a href="#definition-and-properties"
id="toc-definition-and-properties"><span
class="toc-section-number">3.4.1</span> Definition and
Properties</a></li>
<li><a href="#long-range-dependence"
id="toc-long-range-dependence"><span
class="toc-section-number">3.4.2</span> Long-Range Dependence</a></li>
<li><a href="#simulation-method" id="toc-simulation-method"><span
class="toc-section-number">3.4.3</span> Simulation Method</a></li>
<li><a href="#hurst-parameter-estimation"
id="toc-hurst-parameter-estimation"><span
class="toc-section-number">3.4.4</span> Hurst Parameter
Estimation</a></li>
</ul></li>
<li><a href="#cox-ingersoll-ross-process-1"
id="toc-cox-ingersoll-ross-process-1"><span
class="toc-section-number">3.5</span> Cox-Ingersoll-Ross Process</a>
<ul>
<li><a href="#model-specification-1"
id="toc-model-specification-1"><span
class="toc-section-number">3.5.1</span> Model Specification</a></li>
<li><a href="#non-central-chi-square-distribution"
id="toc-non-central-chi-square-distribution"><span
class="toc-section-number">3.5.2</span> Non-Central Chi-Square
Distribution</a></li>
<li><a href="#stationary-distribution"
id="toc-stationary-distribution"><span
class="toc-section-number">3.5.3</span> Stationary Distribution</a></li>
<li><a href="#parameter-estimation-1"
id="toc-parameter-estimation-1"><span
class="toc-section-number">3.5.4</span> Parameter Estimation</a></li>
</ul></li>
<li><a href="#lévy-processes-1" id="toc-lévy-processes-1"><span
class="toc-section-number">3.6</span> Lévy Processes</a>
<ul>
<li><a href="#alpha-stable-distributions"
id="toc-alpha-stable-distributions"><span
class="toc-section-number">3.6.1</span> <span
class="math inline">\alpha</span>-Stable Distributions</a></li>
<li><a href="#simulation-via-chambers-mallows-stuck"
id="toc-simulation-via-chambers-mallows-stuck"><span
class="toc-section-number">3.6.2</span> Simulation via
Chambers-Mallows-Stuck</a></li>
<li><a href="#tail-behavior" id="toc-tail-behavior"><span
class="toc-section-number">3.6.3</span> Tail Behavior</a></li>
</ul></li>
<li><a href="#inference-framework" id="toc-inference-framework"><span
class="toc-section-number">3.7</span> Inference Framework</a>
<ul>
<li><a href="#maximum-likelihood-estimation"
id="toc-maximum-likelihood-estimation"><span
class="toc-section-number">3.7.1</span> Maximum Likelihood
Estimation</a></li>
<li><a href="#method-of-moments" id="toc-method-of-moments"><span
class="toc-section-number">3.7.2</span> Method of Moments</a></li>
<li><a href="#bayesian-inference" id="toc-bayesian-inference"><span
class="toc-section-number">3.7.3</span> Bayesian Inference</a></li>
</ul></li>
</ul></li>
<li><a href="#advanced-statistical-methods"
id="toc-advanced-statistical-methods"><span
class="toc-section-number">4</span> Advanced Statistical Methods</a>
<ul>
<li><a href="#wavelet-analysis-for-multi-scale-temporal-patterns"
id="toc-wavelet-analysis-for-multi-scale-temporal-patterns"><span
class="toc-section-number">4.1</span> Wavelet Analysis for Multi-Scale
Temporal Patterns</a>
<ul>
<li><a href="#continuous-wavelet-transform"
id="toc-continuous-wavelet-transform"><span
class="toc-section-number">4.1.1</span> Continuous Wavelet
Transform</a></li>
<li><a href="#power-spectrum-and-applications"
id="toc-power-spectrum-and-applications"><span
class="toc-section-number">4.1.2</span> Power Spectrum and
Applications</a></li>
</ul></li>
<li><a href="#copula-methods-for-trait-dependencies"
id="toc-copula-methods-for-trait-dependencies"><span
class="toc-section-number">4.2</span> Copula Methods for Trait
Dependencies</a>
<ul>
<li><a href="#copula-theory" id="toc-copula-theory"><span
class="toc-section-number">4.2.1</span> Copula Theory</a></li>
<li><a href="#copula-families" id="toc-copula-families"><span
class="toc-section-number">4.2.2</span> Copula Families</a></li>
<li><a href="#dependence-measures" id="toc-dependence-measures"><span
class="toc-section-number">4.2.3</span> Dependence Measures</a></li>
<li><a href="#estimation" id="toc-estimation"><span
class="toc-section-number">4.2.4</span> Estimation</a></li>
<li><a href="#applications" id="toc-applications"><span
class="toc-section-number">4.2.5</span> Applications</a></li>
</ul></li>
<li><a href="#extreme-value-theory" id="toc-extreme-value-theory"><span
class="toc-section-number">4.3</span> Extreme Value Theory</a>
<ul>
<li><a href="#peaks-over-threshold-method"
id="toc-peaks-over-threshold-method"><span
class="toc-section-number">4.3.1</span> Peaks-Over-Threshold
Method</a></li>
<li><a href="#return-levels" id="toc-return-levels"><span
class="toc-section-number">4.3.2</span> Return Levels</a></li>
<li><a href="#block-maxima-method" id="toc-block-maxima-method"><span
class="toc-section-number">4.3.3</span> Block Maxima Method</a></li>
<li><a href="#hill-estimator" id="toc-hill-estimator"><span
class="toc-section-number">4.3.4</span> Hill Estimator</a></li>
<li><a href="#applications-1" id="toc-applications-1"><span
class="toc-section-number">4.3.5</span> Applications</a></li>
</ul></li>
<li><a href="#regime-switching-detection"
id="toc-regime-switching-detection"><span
class="toc-section-number">4.4</span> Regime Switching Detection</a>
<ul>
<li><a href="#hidden-markov-models" id="toc-hidden-markov-models"><span
class="toc-section-number">4.4.1</span> Hidden Markov Models</a></li>
<li><a href="#k-means-clustering-approach"
id="toc-k-means-clustering-approach"><span
class="toc-section-number">4.4.2</span> K-Means Clustering
Approach</a></li>
<li><a href="#transition-probability-matrix"
id="toc-transition-probability-matrix"><span
class="toc-section-number">4.4.3</span> Transition Probability
Matrix</a></li>
<li><a href="#regime-characterization"
id="toc-regime-characterization"><span
class="toc-section-number">4.4.4</span> Regime Characterization</a></li>
<li><a href="#applications-2" id="toc-applications-2"><span
class="toc-section-number">4.4.5</span> Applications</a></li>
</ul></li>
<li><a href="#information-theoretic-methods"
id="toc-information-theoretic-methods"><span
class="toc-section-number">4.5</span> Information-Theoretic Methods</a>
<ul>
<li><a href="#shannon-entropy" id="toc-shannon-entropy"><span
class="toc-section-number">4.5.1</span> Shannon Entropy</a></li>
<li><a href="#mutual-information" id="toc-mutual-information"><span
class="toc-section-number">4.5.2</span> Mutual Information</a></li>
<li><a href="#transfer-entropy" id="toc-transfer-entropy"><span
class="toc-section-number">4.5.3</span> Transfer Entropy</a></li>
<li><a href="#applications-3" id="toc-applications-3"><span
class="toc-section-number">4.5.4</span> Applications</a></li>
</ul></li>
<li><a href="#robust-statistical-methods"
id="toc-robust-statistical-methods"><span
class="toc-section-number">4.6</span> Robust Statistical Methods</a>
<ul>
<li><a href="#m-estimators" id="toc-m-estimators"><span
class="toc-section-number">4.6.1</span> M-Estimators</a></li>
<li><a href="#robust-scale-estimation"
id="toc-robust-scale-estimation"><span
class="toc-section-number">4.6.2</span> Robust Scale Estimation</a></li>
<li><a href="#applications-4" id="toc-applications-4"><span
class="toc-section-number">4.6.3</span> Applications</a></li>
</ul></li>
</ul></li>
<li><a href="#computational-implementation"
id="toc-computational-implementation"><span
class="toc-section-number">5</span> Computational Implementation</a>
<ul>
<li><a href="#software-architecture"
id="toc-software-architecture"><span
class="toc-section-number">5.1</span> Software Architecture</a>
<ul>
<li><a href="#design-principles" id="toc-design-principles"><span
class="toc-section-number">5.1.1</span> Design Principles</a></li>
<li><a href="#core-modules" id="toc-core-modules"><span
class="toc-section-number">5.1.2</span> Core Modules</a></li>
<li><a href="#class-hierarchy" id="toc-class-hierarchy"><span
class="toc-section-number">5.1.3</span> Class Hierarchy</a></li>
</ul></li>
<li><a href="#algorithmic-implementation"
id="toc-algorithmic-implementation"><span
class="toc-section-number">5.2</span> Algorithmic Implementation</a>
<ul>
<li><a href="#stochastic-process-simulation"
id="toc-stochastic-process-simulation"><span
class="toc-section-number">5.2.1</span> Stochastic Process
Simulation</a></li>
<li><a href="#parameter-estimation-2"
id="toc-parameter-estimation-2"><span
class="toc-section-number">5.2.2</span> Parameter Estimation</a></li>
<li><a href="#wavelet-transform-implementation"
id="toc-wavelet-transform-implementation"><span
class="toc-section-number">5.2.3</span> Wavelet Transform
Implementation</a></li>
<li><a href="#copula-fitting" id="toc-copula-fitting"><span
class="toc-section-number">5.2.4</span> Copula Fitting</a></li>
</ul></li>
<li><a href="#performance-optimization"
id="toc-performance-optimization"><span
class="toc-section-number">5.3</span> Performance Optimization</a>
<ul>
<li><a href="#vectorization" id="toc-vectorization"><span
class="toc-section-number">5.3.1</span> Vectorization</a></li>
<li><a href="#computational-efficiency"
id="toc-computational-efficiency"><span
class="toc-section-number">5.3.2</span> Computational
Efficiency</a></li>
<li><a href="#memory-efficiency" id="toc-memory-efficiency"><span
class="toc-section-number">5.3.3</span> Memory Efficiency</a></li>
</ul></li>
<li><a href="#testing-framework" id="toc-testing-framework"><span
class="toc-section-number">5.4</span> Testing Framework</a>
<ul>
<li><a href="#unit-tests" id="toc-unit-tests"><span
class="toc-section-number">5.4.1</span> Unit Tests</a></li>
<li><a href="#integration-tests" id="toc-integration-tests"><span
class="toc-section-number">5.4.2</span> Integration Tests</a></li>
<li><a href="#validation-tests" id="toc-validation-tests"><span
class="toc-section-number">5.4.3</span> Validation Tests</a></li>
</ul></li>
<li><a href="#documentation-system" id="toc-documentation-system"><span
class="toc-section-number">5.5</span> Documentation System</a>
<ul>
<li><a href="#docstring-format" id="toc-docstring-format"><span
class="toc-section-number">5.5.1</span> Docstring Format</a></li>
<li><a href="#sphinx-documentation" id="toc-sphinx-documentation"><span
class="toc-section-number">5.5.2</span> Sphinx Documentation</a></li>
<li><a href="#tutorials-and-examples"
id="toc-tutorials-and-examples"><span
class="toc-section-number">5.5.3</span> Tutorials and Examples</a></li>
</ul></li>
<li><a href="#visualization-framework"
id="toc-visualization-framework"><span
class="toc-section-number">5.6</span> Visualization Framework</a>
<ul>
<li><a href="#advanced-visualization-types"
id="toc-advanced-visualization-types"><span
class="toc-section-number">5.6.1</span> Advanced Visualization
Types</a></li>
<li><a href="#implementation-details"
id="toc-implementation-details"><span
class="toc-section-number">5.6.2</span> Implementation Details</a></li>
</ul></li>
<li><a href="#package-management-with-uv"
id="toc-package-management-with-uv"><span
class="toc-section-number">5.7</span> Package Management with UV</a>
<ul>
<li><a href="#project-configuration"
id="toc-project-configuration"><span
class="toc-section-number">5.7.1</span> Project Configuration</a></li>
<li><a href="#development-workflow" id="toc-development-workflow"><span
class="toc-section-number">5.7.2</span> Development Workflow</a></li>
<li><a href="#reproducible-environments"
id="toc-reproducible-environments"><span
class="toc-section-number">5.7.3</span> Reproducible
Environments</a></li>
</ul></li>
</ul></li>
<li><a href="#results-and-validation"
id="toc-results-and-validation"><span
class="toc-section-number">6</span> Results and Validation</a>
<ul>
<li><a href="#implementation-validation"
id="toc-implementation-validation"><span
class="toc-section-number">6.1</span> Implementation Validation</a>
<ul>
<li><a href="#ornstein-uhlenbeck-process"
id="toc-ornstein-uhlenbeck-process"><span
class="toc-section-number">6.1.1</span> Ornstein-Uhlenbeck
Process</a></li>
<li><a href="#fractional-brownian-motion-2"
id="toc-fractional-brownian-motion-2"><span
class="toc-section-number">6.1.2</span> Fractional Brownian
Motion</a></li>
<li><a href="#cox-ingersoll-ross-process-2"
id="toc-cox-ingersoll-ross-process-2"><span
class="toc-section-number">6.1.3</span> Cox-Ingersoll-Ross
Process</a></li>
<li><a href="#lévy-process" id="toc-lévy-process"><span
class="toc-section-number">6.1.4</span> Lévy Process</a></li>
</ul></li>
<li><a href="#statistical-methods-validation"
id="toc-statistical-methods-validation"><span
class="toc-section-number">6.2</span> Statistical Methods Validation</a>
<ul>
<li><a href="#wavelet-analysis" id="toc-wavelet-analysis"><span
class="toc-section-number">6.2.1</span> Wavelet Analysis</a></li>
<li><a href="#copula-methods" id="toc-copula-methods"><span
class="toc-section-number">6.2.2</span> Copula Methods</a></li>
<li><a href="#extreme-value-theory-1"
id="toc-extreme-value-theory-1"><span
class="toc-section-number">6.2.3</span> Extreme Value Theory</a></li>
<li><a href="#regime-switching-detection-1"
id="toc-regime-switching-detection-1"><span
class="toc-section-number">6.2.4</span> Regime Switching
Detection</a></li>
</ul></li>
<li><a href="#visualization-framework-validation"
id="toc-visualization-framework-validation"><span
class="toc-section-number">6.3</span> Visualization Framework
Validation</a>
<ul>
<li><a href="#trajectory-density-heatmap"
id="toc-trajectory-density-heatmap"><span
class="toc-section-number">6.3.1</span> Trajectory Density
Heatmap</a></li>
<li><a href="#phase-portrait-analysis"
id="toc-phase-portrait-analysis"><span
class="toc-section-number">6.3.2</span> Phase Portrait Analysis</a></li>
<li><a href="#ridge-plots-and-violin-plots"
id="toc-ridge-plots-and-violin-plots"><span
class="toc-section-number">6.3.3</span> Ridge Plots and Violin
Plots</a></li>
</ul></li>
<li><a href="#integration-testing" id="toc-integration-testing"><span
class="toc-section-number">6.4</span> Integration Testing</a></li>
<li><a href="#test-coverage" id="toc-test-coverage"><span
class="toc-section-number">6.5</span> Test Coverage</a></li>
</ul></li>
<li><a
href="#drosophila-case-study-selective-sweeps-and-genetic-hitchhiking"
id="toc-drosophila-case-study-selective-sweeps-and-genetic-hitchhiking"><span
class="toc-section-number">7</span> Drosophila Case Study: Selective
Sweeps and Genetic Hitchhiking</a>
<ul>
<li><a href="#introduction-to-drosophila-analysis"
id="toc-introduction-to-drosophila-analysis"><span
class="toc-section-number">7.1</span> Introduction to Drosophila
Analysis</a>
<ul>
<li><a href="#two-level-trait-model"
id="toc-two-level-trait-model"><span
class="toc-section-number">7.1.1</span> Two-Level Trait Model</a></li>
</ul></li>
<li><a href="#population-dynamics-model"
id="toc-population-dynamics-model"><span
class="toc-section-number">7.2</span> Population Dynamics Model</a></li>
<li><a href="#simulation-setup" id="toc-simulation-setup"><span
class="toc-section-number">7.3</span> Simulation Setup</a></li>
<li><a href="#selective-sweep-analysis"
id="toc-selective-sweep-analysis"><span
class="toc-section-number">7.4</span> Selective Sweep Analysis</a></li>
<li><a href="#genetic-hitchhiking-effects"
id="toc-genetic-hitchhiking-effects"><span
class="toc-section-number">7.5</span> Genetic Hitchhiking
Effects</a></li>
<li><a href="#cross-sectional-analysis"
id="toc-cross-sectional-analysis"><span
class="toc-section-number">7.6</span> Cross-Sectional Analysis</a></li>
<li><a href="#evolutionary-pattern-analysis"
id="toc-evolutionary-pattern-analysis"><span
class="toc-section-number">7.7</span> Evolutionary Pattern
Analysis</a></li>
<li><a href="#network-analysis-of-marker-correlations"
id="toc-network-analysis-of-marker-correlations"><span
class="toc-section-number">7.8</span> Network Analysis of Marker
Correlations</a></li>
<li><a href="#bayesian-analysis-of-selection"
id="toc-bayesian-analysis-of-selection"><span
class="toc-section-number">7.9</span> Bayesian Analysis of
Selection</a></li>
<li><a href="#scientific-insights-and-validation"
id="toc-scientific-insights-and-validation"><span
class="toc-section-number">7.10</span> Scientific Insights and
Validation</a>
<ul>
<li><a href="#selective-sweep-detection"
id="toc-selective-sweep-detection"><span
class="toc-section-number">7.10.1</span> Selective Sweep
Detection</a></li>
<li><a href="#genetic-hitchhiking-evidence"
id="toc-genetic-hitchhiking-evidence"><span
class="toc-section-number">7.10.2</span> Genetic Hitchhiking
Evidence</a></li>
<li><a href="#evolutionary-rate-estimation"
id="toc-evolutionary-rate-estimation"><span
class="toc-section-number">7.10.3</span> Evolutionary Rate
Estimation</a></li>
</ul></li>
<li><a href="#comparison-with-experimental-data"
id="toc-comparison-with-experimental-data"><span
class="toc-section-number">7.11</span> Comparison with Experimental
Data</a></li>
<li><a href="#broader-implications" id="toc-broader-implications"><span
class="toc-section-number">7.12</span> Broader Implications</a></li>
<li><a href="#future-extensions" id="toc-future-extensions"><span
class="toc-section-number">7.13</span> Future Extensions</a></li>
<li><a href="#conclusion" id="toc-conclusion"><span
class="toc-section-number">7.14</span> Conclusion</a></li>
</ul></li>
<li><a href="#discussion" id="toc-discussion"><span
class="toc-section-number">8</span> Discussion</a>
<ul>
<li><a href="#principal-contributions"
id="toc-principal-contributions"><span
class="toc-section-number">8.1</span> Principal Contributions</a>
<ul>
<li><a href="#methodological-integration"
id="toc-methodological-integration"><span
class="toc-section-number">8.1.1</span> Methodological
Integration</a></li>
<li><a href="#computational-achievements"
id="toc-computational-achievements"><span
class="toc-section-number">8.1.2</span> Computational
Achievements</a></li>
</ul></li>
<li><a href="#biological-insights" id="toc-biological-insights"><span
class="toc-section-number">8.2</span> Biological Insights</a>
<ul>
<li><a href="#long-range-temporal-dependencies"
id="toc-long-range-temporal-dependencies"><span
class="toc-section-number">8.2.1</span> Long-Range Temporal
Dependencies</a></li>
<li><a href="#developmental-jumps-vs.-continuous-change"
id="toc-developmental-jumps-vs.-continuous-change"><span
class="toc-section-number">8.2.2</span> Developmental Jumps
vs. Continuous Change</a></li>
<li><a href="#homeostatic-regulation"
id="toc-homeostatic-regulation"><span
class="toc-section-number">8.2.3</span> Homeostatic Regulation</a></li>
<li><a href="#extreme-phenotypes-and-constraints"
id="toc-extreme-phenotypes-and-constraints"><span
class="toc-section-number">8.2.4</span> Extreme Phenotypes and
Constraints</a></li>
</ul></li>
<li><a href="#comparison-with-alternative-approaches"
id="toc-comparison-with-alternative-approaches"><span
class="toc-section-number">8.3</span> Comparison with Alternative
Approaches</a>
<ul>
<li><a href="#growth-curve-models" id="toc-growth-curve-models"><span
class="toc-section-number">8.3.1</span> Growth Curve Models</a></li>
<li><a href="#functional-data-analysis"
id="toc-functional-data-analysis"><span
class="toc-section-number">8.3.2</span> Functional Data
Analysis</a></li>
<li><a href="#state-space-models" id="toc-state-space-models"><span
class="toc-section-number">8.3.3</span> State-Space Models</a></li>
</ul></li>
<li><a href="#limitations-and-assumptions"
id="toc-limitations-and-assumptions"><span
class="toc-section-number">8.4</span> Limitations and Assumptions</a>
<ul>
<li><a href="#model-assumptions" id="toc-model-assumptions"><span
class="toc-section-number">8.4.1</span> Model Assumptions</a></li>
<li><a href="#computational-limitations"
id="toc-computational-limitations"><span
class="toc-section-number">8.4.2</span> Computational
Limitations</a></li>
<li><a href="#biological-limitations"
id="toc-biological-limitations"><span
class="toc-section-number">8.4.3</span> Biological Limitations</a></li>
</ul></li>
<li><a href="#future-directions" id="toc-future-directions"><span
class="toc-section-number">8.5</span> Future Directions</a>
<ul>
<li><a href="#methodological-extensions"
id="toc-methodological-extensions"><span
class="toc-section-number">8.5.1</span> Methodological
Extensions</a></li>
<li><a href="#computational-enhancements"
id="toc-computational-enhancements"><span
class="toc-section-number">8.5.2</span> Computational
Enhancements</a></li>
<li><a href="#biological-applications"
id="toc-biological-applications"><span
class="toc-section-number">8.5.3</span> Biological Applications</a></li>
<li><a href="#integration-with-existing-tools"
id="toc-integration-with-existing-tools"><span
class="toc-section-number">8.5.4</span> Integration with Existing
Tools</a></li>
</ul></li>
<li><a href="#broader-impact" id="toc-broader-impact"><span
class="toc-section-number">8.6</span> Broader Impact</a>
<ul>
<li><a href="#research-impact" id="toc-research-impact"><span
class="toc-section-number">8.6.1</span> Research Impact</a></li>
<li><a href="#educational-impact" id="toc-educational-impact"><span
class="toc-section-number">8.6.2</span> Educational Impact</a></li>
<li><a href="#practical-applications"
id="toc-practical-applications"><span
class="toc-section-number">8.6.3</span> Practical Applications</a></li>
</ul></li>
</ul></li>
<li><a href="#conclusion-1" id="toc-conclusion-1"><span
class="toc-section-number">9</span> Conclusion</a>
<ul>
<li><a href="#summary-of-contributions"
id="toc-summary-of-contributions"><span
class="toc-section-number">9.1</span> Summary of Contributions</a></li>
<li><a href="#significance-for-evolutionary-biology"
id="toc-significance-for-evolutionary-biology"><span
class="toc-section-number">9.2</span> Significance for Evolutionary
Biology</a></li>
<li><a href="#practical-impact" id="toc-practical-impact"><span
class="toc-section-number">9.3</span> Practical Impact</a></li>
<li><a href="#looking-forward" id="toc-looking-forward"><span
class="toc-section-number">9.4</span> Looking Forward</a></li>
<li><a href="#final-thoughts" id="toc-final-thoughts"><span
class="toc-section-number">9.5</span> Final Thoughts</a></li>
<li><a href="#availability" id="toc-availability"><span
class="toc-section-number">9.6</span> Availability</a></li>
</ul></li>
<li><a href="#acknowledgments" id="toc-acknowledgments"><span
class="toc-section-number">10</span> Acknowledgments</a></li>
<li><a href="#references" id="toc-references"><span
class="toc-section-number">11</span> References</a>
<ul>
<li><a href="#additional-references"
id="toc-additional-references"><span
class="toc-section-number">11.1</span> Additional References</a>
<ul>
<li><a href="#stochastic-processes-in-biology"
id="toc-stochastic-processes-in-biology"><span
class="toc-section-number">11.1.1</span> Stochastic Processes in
Biology</a></li>
<li><a href="#quantitative-genetics"
id="toc-quantitative-genetics"><span
class="toc-section-number">11.1.2</span> Quantitative Genetics</a></li>
<li><a href="#evolutionary-developmental-biology"
id="toc-evolutionary-developmental-biology"><span
class="toc-section-number">11.1.3</span> Evolutionary Developmental
Biology</a></li>
<li><a href="#statistical-methods" id="toc-statistical-methods"><span
class="toc-section-number">11.1.4</span> Statistical Methods</a></li>
<li><a href="#computational-methods"
id="toc-computational-methods"><span
class="toc-section-number">11.1.5</span> Computational Methods</a></li>
<li><a href="#software-and-tools" id="toc-software-and-tools"><span
class="toc-section-number">11.1.6</span> Software and Tools</a></li>
<li><a href="#phylogenetic-comparative-methods"
id="toc-phylogenetic-comparative-methods"><span
class="toc-section-number">11.1.7</span> Phylogenetic Comparative
Methods</a></li>
<li><a href="#time-series-analysis" id="toc-time-series-analysis"><span
class="toc-section-number">11.1.8</span> Time Series Analysis</a></li>
<li><a href="#machine-learning-for-time-series"
id="toc-machine-learning-for-time-series"><span
class="toc-section-number">11.1.9</span> Machine Learning for Time
Series</a></li>
<li><a href="#developmental-biology-data"
id="toc-developmental-biology-data"><span
class="toc-section-number">11.1.10</span> Developmental Biology
Data</a></li>
</ul></li>
</ul></li>
<li><a href="#figure-generation-and-reproducibility"
id="toc-figure-generation-and-reproducibility"><span
class="toc-section-number">12</span> Figure Generation and
Reproducibility</a>
<ul>
<li><a href="#technical-details" id="toc-technical-details"><span
class="toc-section-number">12.1</span> Technical Details</a>
<ul>
<li><a href="#data-generation-parameters"
id="toc-data-generation-parameters"><span
class="toc-section-number">12.1.1</span> Data Generation
Parameters</a></li>
<li><a href="#figure-specifications"
id="toc-figure-specifications"><span
class="toc-section-number">12.1.2</span> Figure Specifications</a></li>
</ul></li>
<li><a href="#reproducibility" id="toc-reproducibility"><span
class="toc-section-number">12.2</span> Reproducibility</a></li>
</ul></li>
<li><a href="#glossary-of-mathematical-symbols"
id="toc-glossary-of-mathematical-symbols"><span
class="toc-section-number">13</span> Glossary of Mathematical
Symbols</a>
<ul>
<li><a href="#roman-symbols" id="toc-roman-symbols"><span
class="toc-section-number">13.1</span> Roman Symbols</a></li>
<li><a href="#greek-symbols" id="toc-greek-symbols"><span
class="toc-section-number">13.2</span> Greek Symbols</a></li>
<li><a href="#operators-and-functions"
id="toc-operators-and-functions"><span
class="toc-section-number">13.3</span> Operators and Functions</a></li>
<li><a href="#probability-distributions"
id="toc-probability-distributions"><span
class="toc-section-number">13.4</span> Probability
Distributions</a></li>
<li><a href="#statistical-notation" id="toc-statistical-notation"><span
class="toc-section-number">13.5</span> Statistical Notation</a></li>
<li><a href="#time-series-notation" id="toc-time-series-notation"><span
class="toc-section-number">13.6</span> Time Series Notation</a></li>
<li><a href="#wavelet-analysis-notation"
id="toc-wavelet-analysis-notation"><span
class="toc-section-number">13.7</span> Wavelet Analysis
Notation</a></li>
<li><a href="#extreme-value-theory-notation"
id="toc-extreme-value-theory-notation"><span
class="toc-section-number">13.8</span> Extreme Value Theory
Notation</a></li>
<li><a href="#network-analysis-notation"
id="toc-network-analysis-notation"><span
class="toc-section-number">13.9</span> Network Analysis
Notation</a></li>
<li><a href="#matrix-notation" id="toc-matrix-notation"><span
class="toc-section-number">13.10</span> Matrix Notation</a></li>
<li><a href="#indexing-and-sets" id="toc-indexing-and-sets"><span
class="toc-section-number">13.11</span> Indexing and Sets</a></li>
<li><a href="#special-functions" id="toc-special-functions"><span
class="toc-section-number">13.12</span> Special Functions</a></li>
<li><a href="#asymptotic-notation" id="toc-asymptotic-notation"><span
class="toc-section-number">13.13</span> Asymptotic Notation</a></li>
<li><a href="#abbreviations" id="toc-abbreviations"><span
class="toc-section-number">13.14</span> Abbreviations</a></li>
<li><a href="#model-specific-parameters"
id="toc-model-specific-parameters"><span
class="toc-section-number">13.15</span> Model-Specific Parameters</a>
<ul>
<li><a href="#ornstein-uhlenbeck-with-jumps"
id="toc-ornstein-uhlenbeck-with-jumps"><span
class="toc-section-number">13.15.1</span> Ornstein-Uhlenbeck with
Jumps</a></li>
<li><a href="#fractional-brownian-motion-3"
id="toc-fractional-brownian-motion-3"><span
class="toc-section-number">13.15.2</span> Fractional Brownian
Motion</a></li>
<li><a href="#cox-ingersoll-ross-process-3"
id="toc-cox-ingersoll-ross-process-3"><span
class="toc-section-number">13.15.3</span> Cox-Ingersoll-Ross
Process</a></li>
<li><a href="#lévy-processes-2" id="toc-lévy-processes-2"><span
class="toc-section-number">13.15.4</span> Lévy Processes</a></li>
<li><a href="#copula-models" id="toc-copula-models"><span
class="toc-section-number">13.15.5</span> Copula Models</a></li>
</ul></li>
<li><a href="#notes-on-notation" id="toc-notes-on-notation"><span
class="toc-section-number">13.16</span> Notes on Notation</a></li>
</ul></li>
<li><a href="#complete-code-listings"
id="toc-complete-code-listings"><span
class="toc-section-number">14</span> Complete Code Listings</a>
<ul>
<li><a href="#implementation-code" id="toc-implementation-code"><span
class="toc-section-number">14.1</span> Implementation Code</a>
<ul>
<li><a href="#software-architecture-1"
id="toc-software-architecture-1"><span
class="toc-section-number">14.1.1</span> Software Architecture</a></li>
<li><a href="#algorithmic-implementation-1"
id="toc-algorithmic-implementation-1"><span
class="toc-section-number">14.1.2</span> Algorithmic
Implementation</a></li>
<li><a href="#performance-optimization-1"
id="toc-performance-optimization-1"><span
class="toc-section-number">14.1.3</span> Performance
Optimization</a></li>
<li><a href="#testing-framework-1" id="toc-testing-framework-1"><span
class="toc-section-number">14.1.4</span> Testing Framework</a></li>
<li><a href="#documentation-system-1"
id="toc-documentation-system-1"><span
class="toc-section-number">14.1.5</span> Documentation System</a></li>
<li><a href="#visualization-framework-1"
id="toc-visualization-framework-1"><span
class="toc-section-number">14.1.6</span> Visualization
Framework</a></li>
<li><a href="#package-management-with-uv-1"
id="toc-package-management-with-uv-1"><span
class="toc-section-number">14.1.7</span> Package Management with
UV</a></li>
</ul></li>
<li><a href="#figure-generation-code"
id="toc-figure-generation-code"><span
class="toc-section-number">14.2</span> Figure Generation Code</a>
<ul>
<li><a href="#figure-generation-code-snippets"
id="toc-figure-generation-code-snippets"><span
class="toc-section-number">14.2.1</span> Figure Generation Code
Snippets</a></li>
<li><a href="#technical-details-1" id="toc-technical-details-1"><span
class="toc-section-number">14.2.2</span> Technical Details</a></li>
<li><a href="#software-requirements"
id="toc-software-requirements"><span
class="toc-section-number">14.2.3</span> Software Requirements</a></li>
<li><a href="#installation" id="toc-installation"><span
class="toc-section-number">14.2.4</span> Installation</a></li>
</ul></li>
<li><a href="#drosophila-case-study-code"
id="toc-drosophila-case-study-code"><span
class="toc-section-number">14.3</span> Drosophila Case Study Code</a>
<ul>
<li><a href="#population-configuration"
id="toc-population-configuration"><span
class="toc-section-number">14.3.1</span> Population
Configuration</a></li>
<li><a href="#selection-simulation" id="toc-selection-simulation"><span
class="toc-section-number">14.3.2</span> Selection Simulation</a></li>
<li><a href="#cross-sectional-analysis-1"
id="toc-cross-sectional-analysis-1"><span
class="toc-section-number">14.3.3</span> Cross-Sectional
Analysis</a></li>
<li><a href="#evolutionary-pattern-analysis-1"
id="toc-evolutionary-pattern-analysis-1"><span
class="toc-section-number">14.3.4</span> Evolutionary Pattern
Analysis</a></li>
<li><a href="#network-analysis" id="toc-network-analysis"><span
class="toc-section-number">14.3.5</span> Network Analysis</a></li>
<li><a href="#bayesian-analysis" id="toc-bayesian-analysis"><span
class="toc-section-number">14.3.6</span> Bayesian Analysis</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
<!-- Section: 01_abstract -->
<h1 data-number="1" id="abstract"><span
class="header-section-number">1</span> Abstract</h1>
<p>Biological development unfolds as a stochastic process characterized
by continuous variation and discrete transitions, yet traditional
analytical methods fail to capture this complexity. We present
<strong>EvoJump</strong>, a unified computational framework that models
developmental trajectories as stochastic processes analyzed through
cross-sectional “laser plane” views of phenotypic distributions.</p>
<p>EvoJump integrates multiple stochastic process models—jump-diffusion,
fractional Brownian motion, Cox-Ingersoll-Ross, and Lévy processes—with
advanced statistical methods including wavelet analysis, copula
modeling, extreme value theory, and regime-switching detection. This
comprehensive platform enables:</p>
<ul>
<li>Analysis of developmental trajectories and evolutionary
constraints</li>
<li>Prediction of phenotypic outcomes with uncertainty
quantification</li>
<li>Identification of developmental phase transitions and
dependencies</li>
</ul>
<p>Implemented in Python with comprehensive testing framework and
extensive documentation, EvoJump bridges quantitative genetics and
modern computational methods, enabling researchers to address
fundamental questions about the mechanistic basis of phenotypic
evolution across ontogeny. The framework demonstrates robust performance
with synthetic data validation and scales efficiently to large
phenotyping datasets.</p>
<!-- Section: 02_introduction -->
<h1 data-number="2" id="introduction"><span
class="header-section-number">2</span> Introduction</h1>
<h2 data-number="2.1" id="background-and-motivation"><span
class="header-section-number">2.1</span> Background and Motivation</h2>
<p>Development bridges genetics and evolution. Phenotypes unfold across
ontogeny through complex processes shaped by genes, environments, and
stochastic variation. Understanding how phenotypes change across
developmental time—and how this variation contributes to evolutionary
change—represents a fundamental challenge in modern biology
(West-Eberhard 2003, Arthur 2011).</p>
<p>Classical approaches using discrete timepoint measurements and linear
models have historically succeeded in describing average developmental
trends but inadequately capture three critical features of biological
development:</p>
<ol type="1">
<li><strong>Stochastic variation</strong> inherent in developmental
processes</li>
<li><strong>Discontinuous transitions</strong> between developmental
states</li>
<li><strong>Complex temporal dependencies</strong> linking early and
late developmental events</li>
</ol>
<p>Recent technological advances enable unprecedented characterization
of development: high-throughput phenotyping measures hundreds of traits
across thousands of individuals at fine temporal resolution, time-series
genomics reveals dynamic gene expression patterns, and advanced imaging
captures morphological change in real time. However, analytical
frameworks lag behind data generation capabilities.</p>
<p>Traditional statistical methods assume continuous, normally
distributed changes with independent increments, yet biological
development frequently exhibits:</p>
<ul>
<li><strong>Discrete transitions</strong>: metamorphosis, birth,
flowering</li>
<li><strong>Long-range dependencies</strong>: early events influencing
later outcomes through epigenetic memory or developmental cascades</li>
<li><strong>Mean-reverting dynamics</strong>: homeostatic regulation
maintaining traits near physiological optima</li>
<li><strong>Heavy-tailed distributions</strong>: rare but evolutionarily
important extreme phenotypes</li>
<li><strong>Regime switches</strong>: transitions between qualitatively
different developmental phases</li>
</ul>
<h2 data-number="2.2"
id="conceptual-framework-cross-sectional-analysis"><span
class="header-section-number">2.2</span> Conceptual Framework:
Cross-Sectional Analysis</h2>
<p>We conceptualize ontogeny as a stochastic process analyzed through
cross-sectional views of phenotypic distributions—a “laser plane”
sweeping through developmental time, illuminating phenotype
distributions at each moment. This framework, building on quantitative
genetics (Lande 1976, Lynch &amp; Walsh 1998) and phylogenetic
comparative methods (Felsenstein 1985, Hansen 1997), provides key
insights:</p>
<ul>
<li><strong>Temporal Progression</strong>: Development follows
stochastic trajectories through phenotype space, generating ensembles of
possible outcomes rather than deterministic paths</li>
<li><strong>Cross-Sectional Analysis</strong>: Each timepoint reveals a
phenotypic distribution across individuals, encoding information about
underlying dynamics and initial conditions</li>
<li><strong>Population-Level Dynamics</strong>: Multiple trajectories
generate population patterns; analyzing how cross-sectional
distributions evolve reveals the governing stochastic process</li>
<li><strong>Evolutionary Constraints</strong>: Distribution geometry
exposes developmental constraints—boundaries indicate hard limits, while
low-density regions suggest selective or energetic barriers</li>
</ul>
<p>This approach naturally accommodates continuous change (diffusion)
and discrete transitions (jumps) within a unified mathematical
structure, connecting individual-level stochastic dynamics to
population-level observable distributions.</p>
<h2 data-number="2.3" id="objectives-and-contributions"><span
class="header-section-number">2.3</span> Objectives and
Contributions</h2>
<p>This paper presents <strong>EvoJump</strong>, a comprehensive
computational framework that bridges sophisticated stochastic process
theory with practical developmental biology by addressing five key
challenges:</p>
<ol type="1">
<li><p><strong>Fragmented Tools</strong>: EvoJump unifies multiple
stochastic process models (Ornstein-Uhlenbeck with jumps, fractional
Brownian motion, Cox-Ingersoll-Ross, Lévy processes) in a single
coherent framework with consistent interfaces</p></li>
<li><p><strong>Limited Statistical Methods</strong>: Implements advanced
techniques adapted for developmental data: wavelet analysis for
multi-scale patterns, copula methods for complex dependencies, extreme
value theory for rare events, and regime-switching for phase
detection</p></li>
<li><p><strong>Inadequate Visualization</strong>: Provides specialized
tools for stochastic trajectories: density heatmaps showing distribution
evolution, phase portraits revealing dynamical structure, ridge plots
displaying temporal progression, and interactive exploratory
graphics</p></li>
<li><p><strong>Uncertain Reliability</strong>: Provides comprehensive
testing framework, validation against analytical solutions, and
synthetic data benchmarking for scientific rigor</p></li>
<li><p><strong>Accessibility Barriers</strong>: Delivers
production-ready software with extensive documentation, examples,
tutorials, and high-level APIs that abstract complexity while enabling
expert customization</p></li>
</ol>
<p><strong>Key Contributions</strong>: -
<strong>Methodological</strong>: Unified biological framework
integrating fBM, CIR, and Lévy processes with classical jump-diffusion
models - <strong>Analytical</strong>: Application of wavelet analysis,
copula modeling, and extreme value theory to developmental trajectories
- <strong>Computational</strong>: Specialized visualizations for
stochastic developmental processes - <strong>Validation</strong>:
Rigorous testing framework demonstrating implementation correctness
through synthetic data validation - <strong>Performance</strong>:
Optimized algorithms for large-scale phenotyping datasets</p>
<h2 data-number="2.4" id="paper-organization"><span
class="header-section-number">2.4</span> Paper Organization</h2>
<p>This paper guides readers from theoretical foundations through
practical implementation:</p>
<ul>
<li><strong>Mathematical Foundations</strong> (Section 3): Theoretical
framework with jump-diffusion processes, fractional Brownian motion, CIR
processes, and Lévy processes, emphasizing biological
interpretation</li>
<li><strong>Statistical Methods</strong> (Section 4): Wavelet analysis,
copula methods, extreme value theory, and regime-switching detection for
developmental data analysis</li>
<li><strong>Implementation</strong> (Section 5): Software architecture,
algorithms, performance optimization, and visualization framework</li>
<li><strong>Results and Validation</strong> (Section 6): Parameter
recovery studies, synthetic data validation, performance benchmarks, and
biological applications</li>
<li><strong>Discussion</strong> (Section 7): Contextualization,
limitations, assumptions, and future directions</li>
<li><strong>Conclusion</strong> (Section 8): Synthesis of contributions
and significance for evolutionary developmental biology</li>
</ul>
<p>Supporting materials include figure specifications (Section 10),
references (Section 9), mathematical glossary (Section 11), and complete
code listings (Section 12) for full reproducibility.</p>
<!-- Section: 03_mathematical_foundations -->
<h1 data-number="3" id="mathematical-foundations"><span
class="header-section-number">3</span> Mathematical Foundations</h1>
<h2 data-number="3.1" id="stochastic-process-modeling-in-biology"><span
class="header-section-number">3.1</span> Stochastic Process Modeling in
Biology</h2>
<p>Stochastic differential equations (SDEs) model biological processes
with deterministic trends and random fluctuations (Lande 1976, Turelli
1977). The general jump-diffusion form is:</p>
<p><span class="math display">dX_t = \mu(X_t, t)dt + \sigma(X_t, t)dW_t
+ dJ_t \label{eq:jump_diffusion}</span></p>
<p>This equation captures three components of phenotypic change:</p>
<ul>
<li><strong>Deterministic drift</strong> (<span
class="math inline">\mu(X_t, t)dt</span>): Expected directional change
from developmental programs or selection</li>
<li><strong>Continuous variation</strong> (<span
class="math inline">\sigma(X_t, t)dW_t</span>): Stochastic fluctuations
from noise, environment, or genetics, scaling as <span
class="math inline">\sqrt{dt}</span></li>
<li><strong>Discontinuous jumps</strong> (<span
class="math inline">dJ_t</span>): Sudden discrete transitions
(metamorphosis, environmental shifts)</li>
</ul>
<p>Specialized forms address specific biological scenarios:</p>
<h3 data-number="3.1.1" id="ornstein-uhlenbeck-processes"><span
class="header-section-number">3.1.1</span> Ornstein-Uhlenbeck
Processes</h3>
<p>For homeostatic traits (body temperature, metabolic rates):</p>
<p><span class="math display">dX_t = \kappa(\theta - X_t)dt + \sigma
dW_t \label{eq:ou_process}</span></p>
<p>This introduces <strong>mean reversion</strong>: drift term <span
class="math inline">\kappa(\theta - X_t)</span> pulls traits toward
equilibrium <span class="math inline">\theta</span> at rate <span
class="math inline">\kappa</span>, modeling homeostatic regulation and
stabilizing selection.</p>
<h3 data-number="3.1.2" id="fractional-brownian-motion"><span
class="header-section-number">3.1.2</span> Fractional Brownian
Motion</h3>
<p>For processes with long-range temporal dependencies (epigenetic
inheritance, developmental constraints):</p>
<p><span class="math display">X_t = X_0 + \int_0^t f(t, s)
dW_s</span></p>
<p>Exhibits temporal correlations via Hurst parameter <span
class="math inline">H \in (0,1)</span>: - <span class="math inline">H
&gt; 0.5</span>: Persistent (momentum) - <span class="math inline">H
&lt; 0.5</span>: Anti-persistent (oscillation) - <span
class="math inline">H = 0.5</span>: Standard Brownian motion
(independent increments)</p>
<p>Models situations where early developmental events create lasting
biases.</p>
<h3 data-number="3.1.3" id="cox-ingersoll-ross-process"><span
class="header-section-number">3.1.3</span> Cox-Ingersoll-Ross
Process</h3>
<p>For non-negative traits with state-dependent volatility (e.g., cell
counts, gene expression levels, resource allocation):</p>
<p><span class="math display">dX_t = \kappa(\theta - X_t)dt +
\sigma\sqrt{X_t} dW_t \label{eq:cir_intro}</span></p>
<p>Combines mean reversion with <strong>square-root diffusion</strong>
<span class="math inline">\sigma\sqrt{X_t}</span> for: - Non-negativity
(noise vanishes as <span class="math inline">X_t \to 0</span>) -
State-dependent volatility scaling with <span
class="math inline">\sqrt{X_t}</span> - Reflecting boundary at zero
without artificial constraints</p>
<p>Models biological phenomena where variability scales with population
size or concentration.</p>
<h3 data-number="3.1.4" id="lévy-processes"><span
class="header-section-number">3.1.4</span> Lévy Processes</h3>
<p>For heavy-tailed processes (population catastrophes, large-effect
mutations):</p>
<p><span class="math display">dX_t = \mu dt + \sigma dW_t + dL_t^\alpha
\label{eq:levy_process}</span></p>
<p><span class="math inline">L_t^\alpha</span> is <span
class="math inline">\alpha</span>-stable Lévy process with <span
class="math inline">\alpha \in (0, 2]</span>: - <span
class="math inline">\alpha = 2</span>: Gaussian process - <span
class="math inline">\alpha &lt; 2</span>: Heavy tails—extreme events
more frequent than Gaussian models predict</p>
<p>Captures developmental systems where rare large jumps shape
phenotypic distributions and evolutionary dynamics.</p>
<h2 data-number="3.2" id="general-framework"><span
class="header-section-number">3.2</span> General Framework</h2>
<p>Let <span class="math inline">(X_t)_{t \geq 0}</span> be a stochastic
process describing developmental trajectories of phenotypic traits.
Mathematically, <span class="math inline">X_t</span> evolves on a
filtered probability space <span class="math inline">(\Omega,
\mathcal{F}, (\mathcal{F}_t)_{t \geq 0}, \mathbb{P})</span> where <span
class="math inline">\Omega</span> contains all possible outcomes, <span
class="math inline">\mathcal{F}</span> collects observable events, <span
class="math inline">(\mathcal{F}_t)_{t \geq 0}</span> captures
information flow over time, and <span
class="math inline">\mathbb{P}</span> assigns probabilities.</p>
<h3 data-number="3.2.1" id="jump-diffusion-framework"><span
class="header-section-number">3.2.1</span> Jump-Diffusion Framework</h3>
<p>The general jump-diffusion model unifies continuous and discontinuous
dynamics:</p>
<p><span class="math display">dX_t = \mu(X_t, t)dt + \sigma(X_t, t)dW_t
+ \int_{\mathbb{R}} z \tilde{N}(dt, dz)
\label{eq:general_jump_diffusion}</span></p>
<p>Components: - <strong>Brownian motion</strong> (<span
class="math inline">W_t</span>): Continuous-time random walk with
independent Gaussian increments - <strong>Compensated Poisson
measure</strong> (<span class="math inline">\tilde{N}(dt, dz)</span>):
Framework for jumps at random times with random magnitudes <span
class="math inline">z</span> - <strong>Drift function</strong> (<span
class="math inline">\mu</span>): Deterministic expected change from
developmental programs, selection, or environmental trends -
<strong>Diffusion coefficient</strong> (<span
class="math inline">\sigma</span>): Magnitude of continuous stochastic
fluctuations, can depend on state and time</p>
<h2 data-number="3.3" id="ornstein-uhlenbeck-process-with-jumps"><span
class="header-section-number">3.3</span> Ornstein-Uhlenbeck Process with
Jumps</h2>
<h3 data-number="3.3.1" id="model-specification"><span
class="header-section-number">3.3.1</span> Model Specification</h3>
<p>The Ornstein-Uhlenbeck (OU) process with Poisson jumps combines
mean-reverting continuous dynamics with discrete transitions, making it
particularly suitable for modeling homeostatic regulation punctuated by
developmental transitions:</p>
<p><span class="math display">dX_t = \kappa(\theta - X_t)dt + \sigma
dW_t + dJ_t \label{eq:ou_jump}</span></p>
<p>The biological interpretation of each parameter is crucial for
application:</p>
<ul>
<li><p><span class="math inline">\kappa &gt; 0</span> is the
<strong>mean reversion speed</strong>—quantifying how quickly the trait
returns to equilibrium after perturbation. Larger <span
class="math inline">\kappa</span> indicates stronger homeostatic
regulation. The characteristic timescale of regulation is <span
class="math inline">1/\kappa</span>: after time <span
class="math inline">1/\kappa</span>, approximately 63% of a deviation
has been corrected.</p></li>
<li><p><span class="math inline">\theta</span> is the <strong>long-term
equilibrium level</strong>—the target value toward which regulation
drives the trait. In evolutionary terms, this represents the fitness
optimum under stabilizing selection. In physiological terms, it is the
homeostatic setpoint.</p></li>
<li><p><span class="math inline">\sigma &gt; 0</span> is the
<strong>diffusion coefficient</strong>—measuring the intensity of
continuous environmental or developmental noise. Larger <span
class="math inline">\sigma</span> produces more erratic trajectories
even with strong regulation.</p></li>
<li><p><span class="math inline">J_t</span> is a <strong>compound
Poisson process</strong> describing discontinuous jumps. Jumps occur at
times determined by a Poisson process with intensity <span
class="math inline">\lambda</span> (average rate of jumps per unit
time). When a jump occurs, its magnitude is drawn from a distribution,
here taken as <span class="math inline">N(\mu_J, \sigma_J^2)</span>.
This captures developmental transitions like metamorphosis or
environmental regime shifts.</p></li>
</ul>
<h3 data-number="3.3.2" id="analytical-properties"><span
class="header-section-number">3.3.2</span> Analytical Properties</h3>
<p>The OU process with jumps admits analytical solutions for key
statistical quantities, enabling efficient parameter estimation and
model validation.</p>
<p><strong>Stationary Distribution</strong>: Under <span
class="math inline">\kappa &gt; 0</span> (ensuring mean reversion), the
process converges to a stationary distribution regardless of initial
condition. After sufficiently long time:</p>
<p><span class="math display">X_\infty \sim N\left(\theta,
\frac{\sigma^2}{2\kappa} + \frac{\lambda(\sigma_J^2 +
\mu_J^2)}{\kappa}\right) \label{eq:ou_stationary}</span></p>
<p>The mean equals <span class="math inline">\theta</span> (the
equilibrium), while the variance has two components: <span
class="math inline">\sigma^2/(2\kappa)</span> from continuous diffusion
and <span class="math inline">\lambda(\sigma_J^2 +
\mu_J^2)/\kappa</span> from jumps. Notice that stronger regulation
(larger <span class="math inline">\kappa</span>) reduces variance, while
more frequent or larger jumps (larger <span
class="math inline">\lambda</span>, <span
class="math inline">\mu_J</span>, or <span
class="math inline">\sigma_J</span>) increase variance.</p>
<p><strong>Autocorrelation Function</strong>: The correlation between
observations at times <span class="math inline">s</span> and <span
class="math inline">t</span> decays exponentially:</p>
<p><span class="math display">\text{Corr}(X_s, X_t) = e^{-\kappa|t-s|}
\label{eq:ou_autocorr}</span></p>
<p>This exponential decay is a signature of the OU process. The decay
rate <span class="math inline">\kappa</span> determines how quickly past
values become uninformative about future values. In biological terms,
this quantifies the “memory” of the developmental system.</p>
<p><strong>Conditional Moments</strong>: Given current state <span
class="math inline">X_s = x</span>, we can predict future values. The
expected value at time <span class="math inline">t &gt; s</span> is:</p>
<p><span class="math display">\mathbb{E}[X_t|X_s = x] = \theta + (x -
\theta)e^{-\kappa(t-s)} + \lambda\mu_J(t-s)
\label{eq:ou_conditional_mean}</span></p>
<p>This shows relaxation from initial value <span
class="math inline">x</span> toward equilibrium <span
class="math inline">\theta</span>, plus accumulation of expected jumps.
The conditional variance is:</p>
<p><span class="math display">\text{Var}[X_t|X_s = x] =
\frac{\sigma^2}{2\kappa}(1 - e^{-2\kappa(t-s)}) + \lambda(\sigma_J^2 +
\mu_J^2)(t-s) \label{eq:ou_conditional_var}</span></p>
<p>Initially (small <span class="math inline">t-s</span>), variance is
small: the current state strongly predicts the near future. As <span
class="math inline">t-s</span> increases, uncertainty grows, asymptoting
to the stationary variance.</p>
<h3 data-number="3.3.3" id="parameter-estimation"><span
class="header-section-number">3.3.3</span> Parameter Estimation</h3>
<p>We employ maximum likelihood estimation (see Section 5 for
computational implementation details). The log-likelihood for observed
data <span class="math inline">\{x_{t_0}, x_{t_1}, \ldots,
x_{t_n}\}</span> is:</p>
<p><span class="math display">\ell(\kappa, \theta, \sigma, \lambda) =
\sum_{i=1}^{n} \log p(x_{t_i} | x_{t_{i-1}})
\label{eq:ou_likelihood}</span></p>
<p>where the transition density can be computed using characteristic
functions or numerical methods. Results from applying this estimation
procedure to synthetic and real data are presented in Section 6.</p>
<h2 data-number="3.4" id="fractional-brownian-motion-1"><span
class="header-section-number">3.4</span> Fractional Brownian Motion</h2>
<h3 data-number="3.4.1" id="definition-and-properties"><span
class="header-section-number">3.4.1</span> Definition and
Properties</h3>
<p>Fractional Brownian motion (fBM) generalizes standard Brownian motion
to incorporate <strong>long-range temporal
dependencies</strong>—correlations between events separated by long time
intervals. Unlike standard Brownian motion where past and future are
independent given the present, fBM exhibits memory: the direction of
past changes influences the direction of future changes.</p>
<p>Formally, fBM is a continuous Gaussian process <span
class="math inline">B^H_t</span> defined by:</p>
<p><span class="math display">B^H_0 = 0, \quad \mathbb{E}[B^H_t] = 0
\label{eq:fbm_zero_mean}</span> <span
class="math display">\mathbb{E}[B^H_t B^H_s] = \frac{1}{2}(t^{2H} +
s^{2H} - |t-s|^{2H}) \label{eq:fbm_covariance}</span></p>
<p>Here <span class="math inline">H \in (0, 1)</span> is the
<strong>Hurst parameter</strong> controlling the correlation structure.
The covariance formula shows that correlations depend on time separation
<span class="math inline">|t-s|</span> in a power-law fashion, rather
than the exponential decay seen in OU processes. This enables modeling
of developmental systems where early events have persistent effects
across ontogeny.</p>
<h3 data-number="3.4.2" id="long-range-dependence"><span
class="header-section-number">3.4.2</span> Long-Range Dependence</h3>
<p>The Hurst parameter <span class="math inline">H</span> fundamentally
determines the character of temporal correlations:</p>
<ul>
<li><p><span class="math inline">H = 0.5</span>: Standard Brownian
motion with <strong>independent increments</strong>. The past provides
no information about future direction. This is the “memoryless” case
appropriate for processes where fluctuations at different times are
uncorrelated.</p></li>
<li><p><span class="math inline">H &gt; 0.5</span>: <strong>Persistent
motion</strong> with positive correlations. Positive changes tend to be
followed by positive changes; negative changes by negative changes. The
process exhibits momentum or trending behavior. In developmental
biology, this models situations where constraints or cascades cause
developmental trajectories to persist in their current direction—think
of developmental channeling or epigenetic inheritance.</p></li>
<li><p><span class="math inline">H &lt; 0.5</span>:
<strong>Anti-persistent motion</strong> with negative correlations.
Positive changes tend to be followed by negative changes, producing
mean-reverting oscillatory behavior different from OU processes. This
might model developmental systems with negative feedback operating on
slow timescales.</p></li>
</ul>
<p>The autocorrelation of increments decays as a power law:</p>
<p><span class="math display">\rho(k) \sim H(2H-1)k^{2H-2} \text{ as } k
\to \infty \label{eq:fbm_autocorr_decay}</span></p>
<p>For <span class="math inline">H &gt; 0.5</span>, this decays slowly
(e.g., as <span class="math inline">k^{-0.4}</span> when <span
class="math inline">H=0.7</span>), meaning correlations persist over
long time lags. This “long memory” distinguishes fBM from short-memory
processes like OU where correlations decay exponentially fast.</p>
<h3 data-number="3.4.3" id="simulation-method"><span
class="header-section-number">3.4.3</span> Simulation Method</h3>
<p>We use the Davies-Harte method for exact simulation. The covariance
matrix of increments is:</p>
<p><span class="math display">\Gamma_{ij} = \frac{1}{2}[\Delta t_i^{2H}
+ \Delta t_j^{2H} - |\Delta t_i - \Delta t_j|^{2H}]
\label{eq:fbm_cov_matrix}</span></p>
<p>Increments are generated as: <span class="math display">\Delta X \sim
\mathcal{N}(0, \Gamma) \label{eq:fbm_simulation}</span></p>
<h3 data-number="3.4.4" id="hurst-parameter-estimation"><span
class="header-section-number">3.4.4</span> Hurst Parameter
Estimation</h3>
<p>We estimate <span class="math inline">H</span> using the variance
method. For lag <span class="math inline">k</span>: <span
class="math display">\mathbb{E}[(X_{t+k} - X_t)^2] = \sigma^2 k^{2H}
\label{eq:fbm_variance}</span></p>
<p>Taking logarithms: <span class="math display">\log
\mathbb{E}[(X_{t+k} - X_t)^2] = \log \sigma^2 + 2H \log k
\label{eq:fbm_log_variance}</span></p>
<p>We estimate <span class="math inline">H</span> by regressing <span
class="math inline">\log \text{Var}(\Delta_k X)</span> on <span
class="math inline">\log k</span>.</p>
<h2 data-number="3.5" id="cox-ingersoll-ross-process-1"><span
class="header-section-number">3.5</span> Cox-Ingersoll-Ross Process</h2>
<h3 data-number="3.5.1" id="model-specification-1"><span
class="header-section-number">3.5.1</span> Model Specification</h3>
<p>The Cox-Ingersoll-Ross (CIR) process, originally developed for
modeling interest rates in finance (Cox et al. 1985), provides an
elegant solution to a common biological challenge: modeling
mean-reverting traits that must remain non-negative (e.g., population
sizes, gene expression levels, resource concentrations):</p>
<p><span class="math display">dX_t = \kappa(\theta - X_t)dt +
\sigma\sqrt{X_t}dW_t \label{eq:cir_sde}</span></p>
<p>The key innovation is the <strong>square-root diffusion term</strong>
<span class="math inline">\sigma\sqrt{X_t}</span>. Unlike the OU process
where noise magnitude is constant, here noise scales with <span
class="math inline">\sqrt{X_t}</span>:</p>
<ul>
<li>When <span class="math inline">X_t</span> is large, noise is
substantial (in absolute terms), but small relative to <span
class="math inline">X_t</span></li>
<li>When <span class="math inline">X_t</span> approaches zero, noise
vanishes, preventing the process from becoming negative</li>
<li>This creates a “reflecting boundary” at zero without introducing
artificial hard constraints</li>
</ul>
<p>Biologically, this models phenomena where variability scales with
population size or concentration—consistent with demographic
stochasticity in small populations or molecular counting noise at low
expression levels.</p>
<h3 data-number="3.5.2" id="non-central-chi-square-distribution"><span
class="header-section-number">3.5.2</span> Non-Central Chi-Square
Distribution</h3>
<p>The CIR process admits an exact analytical solution for its
transition density. Under the <strong>Feller condition</strong> <span
class="math inline">2\kappa\theta \geq \sigma^2</span> (which guarantees
the process never reaches zero), the conditional distribution follows a
scaled non-central chi-square:</p>
<p><span class="math display">\frac{2\kappa}{\sigma^2(1-e^{-\kappa\Delta
t})}X_{t+\Delta t} | X_t \sim \chi&#39;^2\left(\delta, \lambda\right)
\label{eq:cir_distribution}</span></p>
<p>where: - <span class="math inline">\delta =
\frac{4\kappa\theta}{\sigma^2}</span> (degrees of freedom)—measures the
“strength” of mean reversion relative to noise - <span
class="math inline">\lambda = \frac{2\kappa X_t e^{-\kappa\Delta
t}}{\sigma^2(1-e^{-\kappa\Delta t})}</span> (non-centrality
parameter)—encodes dependence on current state</p>
<p>This analytical tractability enables efficient maximum likelihood
estimation and simulation.</p>
<h3 data-number="3.5.3" id="stationary-distribution"><span
class="header-section-number">3.5.3</span> Stationary Distribution</h3>
<p>When the Feller condition holds, the process has a Gamma stationary
distribution:</p>
<p><span class="math display">X_\infty \sim
\text{Gamma}\left(\frac{2\kappa\theta}{\sigma^2},
\frac{2\kappa}{\sigma^2}\right) \label{eq:cir_stationary}</span></p>
<p>The mean is <span class="math inline">\theta</span> (matching the OU
equilibrium), but unlike OU, the distribution is positively skewed with
support on <span class="math inline">(0, \infty)</span>. Stronger mean
reversion or lower noise (larger <span
class="math inline">\kappa\theta/\sigma^2</span>) produces distributions
more concentrated around <span class="math inline">\theta</span>.</p>
<h3 data-number="3.5.4" id="parameter-estimation-1"><span
class="header-section-number">3.5.4</span> Parameter Estimation</h3>
<p>We use moment matching:</p>
<p><span class="math display">\hat{\theta} = \bar{X}
\label{eq:cir_theta_hat}</span> <span class="math display">\hat{\kappa}
= -\frac{\log(\hat{\rho}(1))}{\Delta t} \label{eq:cir_kappa_hat}</span>
<span class="math display">\hat{\sigma}^2 =
\frac{2\hat{\kappa}\text{Var}(X)}{\hat{\theta}}
\label{eq:cir_sigma_hat}</span></p>
<p>where <span class="math inline">\hat{\rho}(1)</span> is the lag-1
autocorrelation.</p>
<h2 data-number="3.6" id="lévy-processes-1"><span
class="header-section-number">3.6</span> Lévy Processes</h2>
<h3 data-number="3.6.1" id="alpha-stable-distributions"><span
class="header-section-number">3.6.1</span> <span
class="math inline">\alpha</span>-Stable Distributions</h3>
<p>Lévy processes provide a framework for modeling phenomena with
<strong>heavy-tailed jump distributions</strong>—situations where rare,
extreme events occur more frequently than Gaussian models predict. This
is crucial for biological systems where “black swan” events (rare
large-effect mutations, catastrophic environmental changes,
developmental accidents) play disproportionate roles.</p>
<p>A random variable <span class="math inline">X</span> has a stable
distribution <span class="math inline">S_\alpha(\beta, \gamma,
\delta)</span> if its characteristic function is:</p>
<p><span class="math display">\phi(t) = \begin{cases}
\exp\left\{-\gamma^\alpha|t|^\alpha\left(1 -
i\beta\text{sign}(t)\tan\frac{\pi\alpha}{2}\right) + i\delta t\right\}
&amp; \alpha \neq 1 \\
\exp\left\{-\gamma|t|\left(1 +
i\beta\frac{2}{\pi}\text{sign}(t)\log|t|\right) + i\delta t\right\}
&amp; \alpha = 1
\end{cases}\label{eq:stable_cf}</span></p>
<p>While this formula appears complex, each parameter has clear
interpretation:</p>
<ul>
<li><p><span class="math inline">\alpha \in (0, 2]</span> is the
<strong>stability parameter</strong> controlling tail heaviness. Smaller
<span class="math inline">\alpha</span> means heavier tails and more
frequent extreme events. The Gaussian distribution corresponds to <span
class="math inline">\alpha = 2</span>. For <span
class="math inline">\alpha &lt; 2</span>, variance is infinite—a
mathematical expression of the fact that extremely large values dominate
moments.</p></li>
<li><p><span class="math inline">\beta \in [-1, 1]</span> is the
<strong>skewness parameter</strong>. When <span
class="math inline">\beta = 0</span>, the distribution is symmetric.
Positive <span class="math inline">\beta</span> produces right skew
(more frequent large positive values); negative <span
class="math inline">\beta</span> produces left skew.</p></li>
<li><p><span class="math inline">\gamma &gt; 0</span> is the
<strong>scale parameter</strong> analogous to standard deviation (though
variance may not exist). It controls the typical magnitude of
fluctuations.</p></li>
<li><p><span class="math inline">\delta \in \mathbb{R}</span> is the
<strong>location parameter</strong> analogous to the mean (which exists
only for <span class="math inline">\alpha &gt; 1</span>).</p></li>
</ul>
<p>The characteristic function approach is necessary because stable
distributions generally lack closed-form probability density
functions.</p>
<h3 data-number="3.6.2" id="simulation-via-chambers-mallows-stuck"><span
class="header-section-number">3.6.2</span> Simulation via
Chambers-Mallows-Stuck</h3>
<p>For <span class="math inline">\alpha \neq 1</span>, we generate
stable random variables using:</p>
<ol type="1">
<li>Generate <span class="math inline">U \sim \text{Uniform}(-\pi/2,
\pi/2)</span> and <span class="math inline">W \sim
\text{Exp}(1)</span></li>
<li>Compute: <span class="math display">B =
\arctan\left(\beta\tan\frac{\pi\alpha}{2}\right) / \alpha
\label{eq:stable_b}</span> <span class="math display">S = \left(1 +
\beta^2\tan^2\frac{\pi\alpha}{2}\right)^{1/(2\alpha)}
\label{eq:stable_s}</span> <span class="math display">X =
S\frac{\sin(\alpha(U + B))}{(\cos U)^{1/\alpha}}\left(\frac{\cos(U -
\alpha(U+B))}{W}\right)^{(1-\alpha)/\alpha}
\label{eq:stable_simulation}</span></li>
</ol>
<h3 data-number="3.6.3" id="tail-behavior"><span
class="header-section-number">3.6.3</span> Tail Behavior</h3>
<p>For <span class="math inline">\alpha &lt; 2</span>, stable
distributions have heavy tails: <span
class="math display">\mathbb{P}(|X| &gt; x) \sim C x^{-\alpha} \text{ as
} x \to \infty \label{eq:stable_tails}</span></p>
<p>This allows modeling of extreme developmental transitions.</p>
<h2 data-number="3.7" id="inference-framework"><span
class="header-section-number">3.7</span> Inference Framework</h2>
<h3 data-number="3.7.1" id="maximum-likelihood-estimation"><span
class="header-section-number">3.7.1</span> Maximum Likelihood
Estimation</h3>
<p>For a discrete-time observation <span class="math inline">\mathbf{X}
= (X_0, X_{\Delta t}, \ldots, X_{n\Delta t})</span>, the log-likelihood
is:</p>
<p><span class="math display">\ell(\boldsymbol{\theta}) = \sum_{i=1}^{n}
\log p(X_{i\Delta t} | X_{(i-1)\Delta t}; \boldsymbol{\theta})
\label{eq:general_mle}</span></p>
<h3 data-number="3.7.2" id="method-of-moments"><span
class="header-section-number">3.7.2</span> Method of Moments</h3>
<p>For processes with tractable moments, we match empirical and
theoretical moments:</p>
<p><span class="math display">\hat{\boldsymbol{\theta}} =
\arg\min_{\boldsymbol{\theta}} \sum_{j=1}^{k} w_j(m_j(\mathbf{X}) -
m_j(\boldsymbol{\theta}))^2 \label{eq:moment_matching}</span></p>
<p>where <span class="math inline">m_j</span> are moment functions.</p>
<h3 data-number="3.7.3" id="bayesian-inference"><span
class="header-section-number">3.7.3</span> Bayesian Inference</h3>
<p>We can incorporate prior information: <span
class="math display">p(\boldsymbol{\theta} | \mathbf{X}) \propto
p(\mathbf{X} | \boldsymbol{\theta}) p(\boldsymbol{\theta})
\label{eq:bayesian_posterior}</span></p>
<p>Posterior sampling via MCMC provides uncertainty quantification for
parameters.</p>
<!-- Section: 04_statistical_methods -->
<h1 data-number="4" id="advanced-statistical-methods"><span
class="header-section-number">4</span> Advanced Statistical Methods</h1>
<h2 data-number="4.1"
id="wavelet-analysis-for-multi-scale-temporal-patterns"><span
class="header-section-number">4.1</span> Wavelet Analysis for
Multi-Scale Temporal Patterns</h2>
<p>Biological development operates at multiple temporal scales
simultaneously—from hourly gene expression oscillations to weekly
morphological changes. Traditional Fourier analysis assumes
stationarity, limiting its utility for developmental data where
periodicities change over ontogeny. <strong>Wavelet analysis</strong>
provides time-localized frequency decomposition, revealing when specific
periodicities occur.</p>
<h3 data-number="4.1.1" id="continuous-wavelet-transform"><span
class="header-section-number">4.1.1</span> Continuous Wavelet
Transform</h3>
<p>The CWT decomposes trajectories <span class="math inline">x(t)</span>
using scaled and translated mother wavelets <span
class="math inline">\psi</span>:</p>
<p><span class="math display">W(a, b) =
\frac{1}{\sqrt{a}}\int_{-\infty}^{\infty}
x(t)\psi^*\left(\frac{t-b}{a}\right)dt</span></p>
<p>Parameters: - <strong>Mother wavelet</strong> (<span
class="math inline">\psi</span>): Localized oscillatory template (Morlet
for time-frequency localization, Mexican hat for transients) -
<strong>Scale</strong> (<span class="math inline">a &gt; 0</span>):
Controls stretch—large <span class="math inline">a</span> for slow
variations (low frequencies), small <span class="math inline">a</span>
for rapid changes (high frequencies) - <strong>Translation</strong>
(<span class="math inline">b</span>): Slides wavelet along time axis to
detect when frequencies occur - <strong>Complex conjugation</strong>
(<span class="math inline">*</span>): For complex wavelets</p>
<p>Result <span class="math inline">W(a,b)</span> shows which
frequencies occur at which times, with <span
class="math inline">1/\sqrt{a}</span> normalization preserving energy
across scales.</p>
<h3 data-number="4.1.2" id="power-spectrum-and-applications"><span
class="header-section-number">4.1.2</span> Power Spectrum and
Applications</h3>
<p><strong>Power spectrum</strong> identifies dominant periodicities:
<span class="math display">P(a, b) = |W(a, b)|^2</span></p>
<p><strong>Time-averaged power</strong> reveals characteristic scales:
<span class="math display">\bar{P}(a) = \frac{1}{T}\int_0^T |W(a, b)|^2
db</span></p>
<p><strong>Applications</strong>: - Developmental oscillations in gene
expression data - Critical periods and metamorphic transitions -
Multi-scale processes across temporal hierarchies</p>
<p>Complements stochastic process models by revealing time-localized
patterns.</p>
<p><strong>Implementation</strong> uses Morlet wavelet for optimal
time-frequency localization: <span class="math display">\psi(t) =
\pi^{-1/4}e^{i\omega_0 t}e^{-t^2/2}</span></p>
<p>Logarithmic scale selection: <span class="math inline">a_j = a_0
2^{j/n_{\text{voices}}}</span>.</p>
<h2 data-number="4.2" id="copula-methods-for-trait-dependencies"><span
class="header-section-number">4.2</span> Copula Methods for Trait
Dependencies</h2>
<p>Developmental traits exhibit complex dependencies through pleiotropy,
developmental integration, and functional constraints. Traditional
correlation analysis assumes linearity and multivariate normality,
inadequate for nonlinear dependencies, asymmetries, and tail
dependence.</p>
<p><strong>Copula methods</strong> model complex multivariate
dependencies by separating marginal distributions from dependence
structure, enabling non-Gaussian dependencies with arbitrary
marginals.</p>
<h3 data-number="4.2.1" id="copula-theory"><span
class="header-section-number">4.2.1</span> Copula Theory</h3>
<p><strong>Sklar’s theorem</strong> (1959) decomposes multivariate
distributions:</p>
<p><span class="math display">F(x_1, \ldots, x_d) = C(F_1(x_1), \ldots,
F_d(x_d))</span></p>
<p>where <span class="math inline">C: [0,1]^d \to [0,1]</span> is the
copula capturing dependence structure independent of marginals <span
class="math inline">F_i</span>. Operates on uniform marginals <span
class="math inline">U_i = F_i(X_i) \in [0,1]</span>.</p>
<p>Different copula families model distinct dependence patterns:</p>
<h3 data-number="4.2.2" id="copula-families"><span
class="header-section-number">4.2.2</span> Copula Families</h3>
<p><strong>Gaussian Copula</strong> (symmetric, no tail dependence):
<span class="math display">C(u_1, u_2) = \Phi_\rho(\Phi^{-1}(u_1),
\Phi^{-1}(u_2))</span> Extends correlation to non-normal marginals but
lacks tail dependence.</p>
<p><strong>Clayton Copula</strong> (lower tail dependence): <span
class="math display">C(u_1, u_2) = \max\{(u_1^{-\theta} + u_2^{-\theta}
- 1)^{-1/\theta}, 0\}</span> Strong lower tail dependence—small values
co-occur. Models compensatory growth and pleiotropic mutation
effects.</p>
<p><strong>Frank Copula</strong> (symmetric, moderate tail dependence):
<span class="math display">C(u_1, u_2) = -\frac{1}{\theta}\log\left(1 +
\frac{(e^{-\theta u_1} - 1)(e^{-\theta u_2} - 1)}{e^{-\theta} -
1}\right)</span> Intermediate flexibility with weak tail dependence.</p>
<h3 data-number="4.2.3" id="dependence-measures"><span
class="header-section-number">4.2.3</span> Dependence Measures</h3>
<p><strong>Kendall’s <span class="math inline">\tau</span></strong>:
<span class="math display">\tau = \mathbb{P}[(X_1 - X_2)(Y_1 - Y_2) &gt;
0] - \mathbb{P}[(X_1 - X_2)(Y_1 - Y_2) &lt; 0]
\label{eq:kendall_tau}</span></p>
<p><strong>Tail Dependence Coefficients</strong>:</p>
<p>Upper: <span class="math inline">\lambda_U = \lim_{u \to 1^-}
\mathbb{P}(U_2 &gt; u | U_1 &gt; u) \label{eq:upper_tail_dep}</span></p>
<p>Lower: <span class="math inline">\lambda_L = \lim_{u \to 0^+}
\mathbb{P}(U_2 \leq u | U_1 \leq u) \label{eq:lower_tail_dep}</span></p>
<h3 data-number="4.2.4" id="estimation"><span
class="header-section-number">4.2.4</span> Estimation</h3>
<ol type="1">
<li>Transform data to uniform margins via empirical CDF</li>
<li>Fit copula by maximum likelihood or method of moments</li>
<li>Validate using goodness-of-fit tests</li>
</ol>
<h3 data-number="4.2.5" id="applications"><span
class="header-section-number">4.2.5</span> Applications</h3>
<ul>
<li>Model complex trait correlations beyond linear dependence</li>
<li>Identify traits that co-vary in extreme phenotypes</li>
<li>Characterize pleiotropy and genetic covariance structures</li>
</ul>
<h2 data-number="4.3" id="extreme-value-theory"><span
class="header-section-number">4.3</span> Extreme Value Theory</h2>
<p>Understanding extreme phenotypes is crucial for evolutionary biology.
Rare, extreme individuals may experience strong selection, reveal hidden
genetic variation, or indicate developmental constraints. Yet
traditional statistical methods focus on central tendency and typical
variation, treating extremes as outliers to be excluded rather than
phenomena to be modeled.</p>
<p><strong>Extreme value theory (EVT)</strong> provides rigorous
statistical methods for analyzing tail behavior and rare events.
Originally developed for engineering (flood risk, structural failure)
and finance (market crashes), EVT has natural applications to biology:
maximum body size achievable under constraints, probability of
developmental catastrophes, risk of population extinction.</p>
<h3 data-number="4.3.1" id="peaks-over-threshold-method"><span
class="header-section-number">4.3.1</span> Peaks-Over-Threshold
Method</h3>
<p>The <strong>POT method</strong> models values exceeding a high
threshold <span class="math inline">u</span>. The fundamental result
(Pickands 1975) is that threshold exceedances, under mild conditions,
follow a <strong>Generalized Pareto Distribution (GPD)</strong>:</p>
<p><span class="math display">F(x) = 1 - \left(1 +
\xi\frac{x-u}{\sigma}\right)^{-1/\xi}_+ \label{eq:gpd}</span></p>
<p>where the notation <span class="math inline">(\cdot)_+</span> means
<span class="math inline">\max(\cdot, 0)</span> and:</p>
<ul>
<li><span class="math inline">\xi</span> is the <strong>shape
parameter</strong> (tail index) determining tail behavior. This
parameter has profound biological interpretation:
<ul>
<li><span class="math inline">\xi &gt; 0</span>:
<strong>Heavy-tailed</strong> (Pareto-type). Extreme events far beyond
the threshold occur regularly. No finite upper bound exists. This might
indicate weak selection against extreme phenotypes or high mutational
variance.</li>
<li><span class="math inline">\xi = 0</span>: <strong>Exponential
tail</strong> (light but unbounded). Extremes decay exponentially. This
is the boundary between bounded and unbounded distributions.</li>
<li><span class="math inline">\xi &lt; 0</span>: <strong>Bounded
tail</strong> (short-tailed). A finite upper bound exists at <span
class="math inline">u - \sigma/\xi</span>. This indicates strong
developmental constraints or stabilizing selection imposing a phenotypic
ceiling.</li>
</ul></li>
<li><span class="math inline">\sigma &gt; 0</span> is the <strong>scale
parameter</strong> controlling the typical magnitude of exceedances,
analogous to standard deviation.</li>
</ul>
<h3 data-number="4.3.2" id="return-levels"><span
class="header-section-number">4.3.2</span> Return Levels</h3>
<p>The <span class="math inline">m</span>-observation return level
satisfies:</p>
<p><span class="math display">\mathbb{P}(X &gt; x_m) = \frac{1}{m}
\label{eq:return_level_def}</span></p>
<p>For GPD with <span class="math inline">n_u</span> exceedances in
<span class="math inline">n</span> observations:</p>
<p><span class="math display">x_m = u +
\frac{\sigma}{\xi}\left[\left(m\frac{n}{n_u}\right)^\xi - 1\right]
\label{eq:return_level_gpd}</span></p>
<h3 data-number="4.3.3" id="block-maxima-method"><span
class="header-section-number">4.3.3</span> Block Maxima Method</h3>
<p>Model block maxima using Generalized Extreme Value (GEV)
distribution:</p>
<p><span class="math display">F(x) = \exp\left\{-\left(1 +
\xi\frac{x-\mu}{\sigma}\right)^{-1/\xi}_+\right\}
\label{eq:gev}</span></p>
<p>Parameters: - <span class="math inline">\mu \in \mathbb{R}</span>:
location - <span class="math inline">\sigma &gt; 0</span>: scale - <span
class="math inline">\xi \in \mathbb{R}</span>: shape</p>
<h3 data-number="4.3.4" id="hill-estimator"><span
class="header-section-number">4.3.4</span> Hill Estimator</h3>
<p>For heavy-tailed distributions, the tail index <span
class="math inline">\alpha</span> is estimated by:</p>
<p><span class="math display">\hat{\alpha} =
\left[\frac{1}{k}\sum_{i=1}^{k} \log X_{(i)} - \log
X_{(k+1)}\right]^{-1} \label{eq:hill_estimator}</span></p>
<p>where <span class="math inline">X_{(1)} \geq X_{(2)} \geq
\ldots</span> are order statistics.</p>
<h3 data-number="4.3.5" id="applications-1"><span
class="header-section-number">4.3.5</span> Applications</h3>
<ul>
<li>Predict extreme developmental outcomes</li>
<li>Quantify risk of pathological phenotypes</li>
<li>Identify evolutionary constraints from tail behavior</li>
</ul>
<h2 data-number="4.4" id="regime-switching-detection"><span
class="header-section-number">4.4</span> Regime Switching Detection</h2>
<h3 data-number="4.4.1" id="hidden-markov-models"><span
class="header-section-number">4.4.1</span> Hidden Markov Models</h3>
<p>Assume the developmental process follows regime-dependent
dynamics:</p>
<p><span class="math display">X_t | S_t = k \sim f_k(x_t | \theta_k)
\label{eq:hmm_observation}</span></p>
<p>where <span class="math inline">S_t \in \{1, \ldots, K\}</span> is
the unobserved regime state following a Markov chain:</p>
<p><span class="math display">\mathbb{P}(S_t = j | S_{t-1} = i) = p_{ij}
\label{eq:hmm_transition}</span></p>
<h3 data-number="4.4.2" id="k-means-clustering-approach"><span
class="header-section-number">4.4.2</span> K-Means Clustering
Approach</h3>
<p>We use sliding windows to extract features:</p>
<p><span class="math display">\mathbf{z}_t = [\mu_t, \sigma_t, r_t,
IQR_t] \label{eq:window_features}</span></p>
<p>where each feature is computed over window <span
class="math inline">[t-w, t]</span>: - <span
class="math inline">\mu_t</span>: mean - <span
class="math inline">\sigma_t</span>: standard deviation - <span
class="math inline">r_t</span>: range - <span
class="math inline">IQR_t</span>: interquartile range</p>
<p>Cluster feature vectors to identify regimes.</p>
<h3 data-number="4.4.3" id="transition-probability-matrix"><span
class="header-section-number">4.4.3</span> Transition Probability
Matrix</h3>
<p>Estimate transition probabilities:</p>
<p><span class="math display">\hat{p}_{ij} = \frac{\text{transitions
from } i \text{ to } j}{\text{times in regime } i}
\label{eq:transition_matrix}</span></p>
<h3 data-number="4.4.4" id="regime-characterization"><span
class="header-section-number">4.4.4</span> Regime Characterization</h3>
<p>For each regime <span class="math inline">k</span>: - Mean and
variance of trait values - Duration distribution - Proportion of total
time - Associated environmental covariates</p>
<h3 data-number="4.4.5" id="applications-2"><span
class="header-section-number">4.4.5</span> Applications</h3>
<ul>
<li>Identify developmental phases</li>
<li>Detect environmental regime shifts</li>
<li>Characterize developmental plasticity</li>
<li>Model punctuated equilibrium</li>
</ul>
<h2 data-number="4.5" id="information-theoretic-methods"><span
class="header-section-number">4.5</span> Information-Theoretic
Methods</h2>
<h3 data-number="4.5.1" id="shannon-entropy"><span
class="header-section-number">4.5.1</span> Shannon Entropy</h3>
<p>Quantify uncertainty in phenotypic distributions:</p>
<p><span class="math display">H(X) = -\int f(x) \log f(x) dx
\label{eq:shannon_entropy}</span></p>
<p>For discrete distributions: <span class="math display">H(X) =
-\sum_{i} p_i \log p_i \label{eq:discrete_entropy}</span></p>
<h3 data-number="4.5.2" id="mutual-information"><span
class="header-section-number">4.5.2</span> Mutual Information</h3>
<p>Measure dependence between traits:</p>
<p><span class="math display">I(X; Y) = \int\int f(x,y)
\log\frac{f(x,y)}{f(x)f(y)} dx dy \label{eq:mutual_info}</span></p>
<h3 data-number="4.5.3" id="transfer-entropy"><span
class="header-section-number">4.5.3</span> Transfer Entropy</h3>
<p>Quantify directed information flow:</p>
<p><span class="math display">TE_{Y \to X} = H(X_{t+1} | X_t^{(k)}) -
H(X_{t+1} | X_t^{(k)}, Y_t^{(l)}) \label{eq:transfer_entropy}</span></p>
<p>where <span class="math inline">X_t^{(k)} = (X_t, X_{t-1}, \ldots,
X_{t-k+1})</span> is the history.</p>
<h3 data-number="4.5.4" id="applications-3"><span
class="header-section-number">4.5.4</span> Applications</h3>
<ul>
<li>Quantify developmental constraints</li>
<li>Identify causal relationships between traits</li>
<li>Measure phenotypic integration</li>
</ul>
<h2 data-number="4.6" id="robust-statistical-methods"><span
class="header-section-number">4.6</span> Robust Statistical Methods</h2>
<h3 data-number="4.6.1" id="m-estimators"><span
class="header-section-number">4.6.1</span> M-Estimators</h3>
<p>Robust location estimates minimize:</p>
<p><span class="math display">\sum_{i=1}^{n} \rho\left(\frac{x_i -
\mu}{\sigma}\right) \label{eq:m_estimator}</span></p>
<p><strong>Huber M-estimator</strong>: <span class="math inline">\rho(u)
= \begin{cases} u^2/2 &amp; |u| \leq k \\ k|u| - k^2/2 &amp; |u| &gt; k
\end{cases} \label{eq:huber_rho}</span></p>
<p><strong>Tukey Biweight</strong>: <span class="math inline">\rho(u) =
\begin{cases} (k^2/6)[1 - (1 - (u/k)^2)^3] &amp; |u| \leq k \\ k^2/6
&amp; |u| &gt; k \end{cases} \label{eq:tukey_rho}</span></p>
<h3 data-number="4.6.2" id="robust-scale-estimation"><span
class="header-section-number">4.6.2</span> Robust Scale Estimation</h3>
<p><strong>MAD (Median Absolute Deviation)</strong>: <span
class="math display">\text{MAD} = \text{median}(|X_i -
\text{median}(X)|) \label{eq:mad}</span></p>
<p><strong><span class="math inline">Q_n</span> Estimator</strong>:
<span class="math display">Q_n = c \cdot \{|X_i - X_j|; i &lt; j\}_{(k)}
\label{eq:qn_estimator}</span></p>
<p>where <span class="math inline">k = \binom{h}{2}</span>, <span
class="math inline">h = \lfloor n/2 \rfloor + 1</span>, and <span
class="math inline">c \approx 2.2219</span>.</p>
<h3 data-number="4.6.3" id="applications-4"><span
class="header-section-number">4.6.3</span> Applications</h3>
<ul>
<li>Handle outliers without manual removal</li>
<li>Robust parameter estimation in presence of contamination</li>
<li>Appropriate for biological data with measurement error</li>
</ul>
<!-- Section: 05_implementation -->
<h1 data-number="5" id="computational-implementation"><span
class="header-section-number">5</span> Computational Implementation</h1>
<p>The mathematical elegance of stochastic process theory must be
matched by computational efficiency and software engineering rigor to be
useful for biological research. This section describes EvoJump’s
architecture, algorithmic implementations, performance optimizations,
and quality assurance practices that transform theoretical models into
practical research tools.</p>
<h2 data-number="5.1" id="software-architecture"><span
class="header-section-number">5.1</span> Software Architecture</h2>
<h3 data-number="5.1.1" id="design-principles"><span
class="header-section-number">5.1.1</span> Design Principles</h3>
<p>EvoJump’s architecture balances mathematical rigor, computational
efficiency, and accessibility through five principles:</p>
<ol type="1">
<li><strong>Modularity</strong>: Independent, testable components (data,
modeling, analysis, visualization) enable focused development and
selective use</li>
<li><strong>Composability</strong>: Well-defined interfaces enable
complex analyses through simple combinations with consistent API
patterns</li>
<li><strong>Extensibility</strong>: Abstract base classes allow new
models via subclassing without modifying core infrastructure</li>
<li><strong>Performance</strong>: NumPy vectorization and intelligent
caching optimize critical paths, with support for JIT compilation where
beneficial</li>
<li><strong>Usability</strong>: High-level APIs with extensive
documentation and examples lower entry barriers while enabling expert
customization</li>
</ol>
<h3 data-number="5.1.2" id="core-modules"><span
class="header-section-number">5.1.2</span> Core Modules</h3>
<p><strong>DataCore</strong>: Data management and preprocessing with
time series structures, quality validation, missing data handling,
metadata management, and reproducible workflows.</p>
<p><strong>JumpRope</strong>: Stochastic process modeling with base
<code>StochasticProcess</code> class and implementations for OU with
jumps, fBM, CIR, Lévy, compound Poisson, and geometric jump-diffusion
processes. Supports maximum likelihood, method of moments, and Bayesian
MCMC estimation.</p>
<p><strong>LaserPlane</strong>: Cross-sectional analysis implementing
the “laser plane” metaphor with distribution fitting, moment
computation, goodness-of-fit testing, and bootstrap confidence
intervals.</p>
<p><strong>AnalyticsEngine</strong>: Advanced statistical methods
including autocorrelation, spectral analysis, PCA, wavelet transforms,
copula fitting, extreme value analysis, and regime-switching detection
with publication-ready reporting.</p>
<p><strong>TrajectoryVisualizer</strong>: Visualization framework with
static (matplotlib) and interactive (Plotly) plots, animations, and
journal-standard outputs (300+ DPI, colorblind-friendly palettes).</p>
<p><strong>EvolutionSampler</strong>: Population-level analysis with
Monte Carlo sampling, phylogenetic methods, quantitative genetics
calculations, and selection analysis.</p>
<h3 data-number="5.1.3" id="class-hierarchy"><span
class="header-section-number">5.1.3</span> Class Hierarchy</h3>
<h2 data-number="5.2" id="algorithmic-implementation"><span
class="header-section-number">5.2</span> Algorithmic Implementation</h2>
<p>This section details key algorithms implementing the stochastic
processes and statistical methods. We emphasize clarity and correctness,
with performance optimizations applied after validation.</p>
<h3 data-number="5.2.1" id="stochastic-process-simulation"><span
class="header-section-number">5.2.1</span> Stochastic Process
Simulation</h3>
<p><strong>Euler-Maruyama Scheme</strong> for SDEs: The Euler-Maruyama
method is the stochastic analog of the Euler method for ODEs. It
discretizes the continuous-time SDE by approximating integrals as finite
sums. The implementation iterates through time steps, generating Wiener
increments <span class="math inline">dW \sim N(0, \sqrt{dt})</span> and
updating the trajectory via <span class="math inline">X_{t+dt} = X_t +
\mu(X_t, t)dt + \sigma(X_t, t)dW</span>. While simple, this scheme
converges to the true solution as the time step decreases (strong
convergence of order 0.5, weak convergence of order 1.0). The key
insight: Brownian motion increments scale as <span
class="math inline">\sqrt{dt}</span>, not <span
class="math inline">dt</span>, reflecting their non-differentiable
nature.</p>
<p><strong>Jump Component</strong>: The compound Poisson process is
simulated by determining the number of jumps in each time interval <span
class="math inline">n \sim \text{Poisson}(\lambda dt)</span>, then
drawing jump magnitudes from the specified distribution and summing
them. This captures the discrete, stochastic nature of developmental
transitions like metamorphosis or environmental regime shifts.</p>
<h3 data-number="5.2.2" id="parameter-estimation-2"><span
class="header-section-number">5.2.2</span> Parameter Estimation</h3>
<p><strong>Maximum Likelihood via Numerical Optimization</strong>:
Parameters are estimated by minimizing the negative log-likelihood using
L-BFGS-B optimization with parameter bounds. The log-likelihood is
computed from the transition densities of the stochastic process, summed
over all observed transitions. This approach provides asymptotically
efficient estimates under standard regularity conditions.</p>
<p><strong>Moment Matching</strong>: For processes with tractable
moments, we match empirical moments (sample mean, variance,
autocorrelation) to their theoretical expressions. The OU process
equilibrium equals the sample mean, the reversion speed is estimated
from lag-1 autocorrelation via <span class="math inline">\hat{\kappa} =
-\log(\hat{\rho})/\Delta t</span>, and the diffusion coefficient from
the equilibrium variance relationship. This method is computationally
efficient and provides good initial estimates for more sophisticated
inference.</p>
<h3 data-number="5.2.3" id="wavelet-transform-implementation"><span
class="header-section-number">5.2.3</span> Wavelet Transform
Implementation</h3>
<p>The continuous wavelet transform is computed using the PyWavelets
library, which provides efficient implementations of multiple wavelet
families. For a given signal and set of scales, the CWT computes wavelet
coefficients by convolving the signal with scaled and translated
versions of the mother wavelet. The power spectrum is obtained by
squaring coefficient magnitudes, and the dominant temporal scale is
identified as the scale with maximum mean power across all time points.
This reveals which frequencies or periodicities dominate the
developmental trajectory.</p>
<h3 data-number="5.2.4" id="copula-fitting"><span
class="header-section-number">5.2.4</span> Copula Fitting</h3>
<p>Copula fitting proceeds in two steps: first, transform marginal data
to uniform <span class="math inline">[0,1]</span> distributions using
empirical ranks; second, fit the copula dependence structure to these
uniform margins. For Gaussian copulas, we transform uniform margins to
standard normal via the inverse normal CDF and estimate the correlation
parameter. For Clayton copulas, we compute Kendall’s <span
class="math inline">\tau</span> and convert to the copula parameter via
<span class="math inline">\theta = 2\tau/(1-\tau)</span>. This approach
separates marginal distributions from dependence structure, enabling
flexible modeling of complex trait relationships.</p>
<h2 data-number="5.3" id="performance-optimization"><span
class="header-section-number">5.3</span> Performance Optimization</h2>
<h3 data-number="5.3.1" id="vectorization"><span
class="header-section-number">5.3.1</span> Vectorization</h3>
<p>Critical computational loops are vectorized using NumPy’s array
operations, replacing explicit Python loops with optimized C-level
operations. This transformation typically provides 10-100x speedups for
numerical operations. Vectorization applies array functions directly to
entire arrays rather than iterating element-by-element, leveraging SIMD
instructions and cache-friendly memory access patterns.</p>
<h3 data-number="5.3.2" id="computational-efficiency"><span
class="header-section-number">5.3.2</span> Computational Efficiency</h3>
<p>The framework is designed with performance in mind through NumPy
vectorization of core operations. Critical loops use array operations
that leverage optimized C-level implementations. The architecture
supports JIT compilation via Numba for performance-critical paths when
needed, and parallel processing via multiprocessing for independent
trajectory generation, though these optimizations are applied
selectively based on computational requirements.</p>
<h3 data-number="5.3.3" id="memory-efficiency"><span
class="header-section-number">5.3.3</span> Memory Efficiency</h3>
<p>Large datasets are processed in chunks to avoid memory overflow. Data
are read, processed, and written in fixed-size blocks, with intermediate
results accumulated incrementally. This streaming approach enables
analysis of datasets exceeding available RAM, trading modest increases
in computation time for dramatic reductions in memory footprint. Chunk
size is tuned based on available memory and cache characteristics.</p>
<h2 data-number="5.4" id="testing-framework"><span
class="header-section-number">5.4</span> Testing Framework</h2>
<h3 data-number="5.4.1" id="unit-tests"><span
class="header-section-number">5.4.1</span> Unit Tests</h3>
<p>Each component has comprehensive unit tests verifying individual
function correctness. Tests cover normal operation, edge cases, and
error conditions. For stochastic processes, tests verify output
dimensions, finite values, and basic statistical properties. The test
suite uses pytest with fixtures for common test data, ensuring
consistent test environments and facilitating debugging.</p>
<h3 data-number="5.4.2" id="integration-tests"><span
class="header-section-number">5.4.2</span> Integration Tests</h3>
<p>Integration tests verify correct interaction between modules through
complete analysis pipelines. A typical test loads data via DataCore,
fits a stochastic model with JumpRope, performs cross-sectional analysis
with LaserPlaneAnalyzer, and generates visualizations with
TrajectoryVisualizer. Assertions verify that data flow correctly between
components and that final outputs meet quality criteria. These tests
catch interface mismatches and ensure the system works as an integrated
whole.</p>
<h3 data-number="5.4.3" id="validation-tests"><span
class="header-section-number">5.4.3</span> Validation Tests</h3>
<p>Validation tests compare numerical results against analytical
solutions and established benchmarks. For the Ornstein-Uhlenbeck
process, we simulate long trajectories and verify that empirical
stationary moments match theoretical predictions within tolerance.
Fractional Brownian motion tests verify correct Hurst parameter
estimation. CIR process tests confirm non-negativity and appropriate
stationary distributions. These tests establish confidence in
implementation correctness and numerical accuracy.</p>
<h2 data-number="5.5" id="documentation-system"><span
class="header-section-number">5.5</span> Documentation System</h2>
<h3 data-number="5.5.1" id="docstring-format"><span
class="header-section-number">5.5.1</span> Docstring Format</h3>
<p>All public functions, classes, and methods include Google-style
docstrings documenting parameters, return values, exceptions, and usage
examples. This consistent format enables automatic API documentation
generation and provides inline help for users. Parameter descriptions
include types and semantics; return values specify structure and
interpretation; examples demonstrate typical usage patterns. Docstrings
serve as both user documentation and developer reference.</p>
<h3 data-number="5.5.2" id="sphinx-documentation"><span
class="header-section-number">5.5.2</span> Sphinx Documentation</h3>
<p>Complete API documentation is generated automatically from source
code docstrings using Sphinx. The documentation system includes module
overviews, class hierarchies, function signatures, and cross-references.
Mathematical notation in docstrings renders correctly in HTML and PDF
outputs. The generated documentation provides searchable, hyperlinked
reference material accessible to both novice and expert users.</p>
<h3 data-number="5.5.3" id="tutorials-and-examples"><span
class="header-section-number">5.5.3</span> Tutorials and Examples</h3>
<p>Comprehensive worked examples demonstrate all major features through
realistic use cases. Examples progress from basic trajectory fitting to
advanced multivariate analysis, copula modeling, and visualization. Each
example includes clear objectives, complete working code, expected
outputs, and interpretation guidance. Examples serve as both learning
materials for new users and templates for researchers adapting EvoJump
to their specific problems. All example code is tested as part of the
continuous integration pipeline, ensuring examples remain functional as
the codebase evolves.</p>
<p><strong>Note</strong>: Complete code listings for all algorithms and
implementations described in this section are provided in Section 12
(Complete Code Listings) for reference and reproducibility.</p>
<h2 data-number="5.6" id="visualization-framework"><span
class="header-section-number">5.6</span> Visualization Framework</h2>
<h3 data-number="5.6.1" id="advanced-visualization-types"><span
class="header-section-number">5.6.1</span> Advanced Visualization
Types</h3>
<p>EvoJump provides multiple innovative visualization methods for
developmental trajectory analysis. These visualizations transform
numerical results from stochastic process models into interpretable
graphics that reveal patterns invisible in raw data. Below we present
five key visualization types, each designed for specific analytical
purposes.</p>
<p><strong>Figure 1</strong> presents a comprehensive model comparison
across three stochastic processes (Fractional Brownian Motion,
Cox-Ingersoll-Ross, and Jump-Diffusion). This multi-panel visualization
includes: (a) mean trajectories with confidence intervals comparing
overall developmental trends, (b) final distribution comparisons showing
endpoint variability, (c) jump pattern detection highlighting
discontinuous changes, (d) statistical properties analysis (mean,
standard deviation, coefficient of variation, skewness, kurtosis), (e)
trajectory variability over time, (f) model parameter comparison, (g)
trajectory clustering by final values, (h) performance metrics
evaluation, and (i) summary statistics for each model type.</p>
<figure>
<img src="figures/figure_1_comparison.png" style="width:95.0%"
alt="Comprehensive model comparison across stochastic processes showing trajectory patterns, statistical properties, parameter estimates, and performance metrics for fBM, CIR, and Jump-Diffusion models." />
<figcaption aria-hidden="true">Comprehensive model comparison across
stochastic processes showing trajectory patterns, statistical
properties, parameter estimates, and performance metrics for fBM, CIR,
and Jump-Diffusion models.</figcaption>
</figure>
<p><strong>Figure 2</strong> provides a comprehensive trajectory
analysis using the Fractional Brownian Motion model as an exemplar. This
9-panel figure includes: (a) individual trajectories with mean and
standard deviation bands, (b) density heatmap showing temporal
evolution, (c) cross-sectional distributions at key timepoints, (d)
violin plots revealing distribution shapes, (e) ridge plot displaying
temporal progression, (f) phase portrait analysis of phenotype dynamics,
(g) statistical summary with mean trends and coefficient of variation,
(h) model parameter diagnostics, and (i) evolutionary change analysis
comparing initial vs. final phenotypes.</p>
<figure>
<img src="figures/figure_2_comprehensive.png" style="width:95.0%"
alt="Comprehensive trajectory analysis of fBM model showing individual trajectories, density evolution, distribution comparisons, phase space dynamics, and statistical summaries across developmental time." />
<figcaption aria-hidden="true">Comprehensive trajectory analysis of fBM
model showing individual trajectories, density evolution, distribution
comparisons, phase space dynamics, and statistical summaries across
developmental time.</figcaption>
</figure>
<p><strong>Figure 3</strong> presents detailed visualizations for each
stochastic model type, with four panels per model: (a) trajectory
density heatmap showing temporal evolution of phenotypic distributions,
(b) violin plots revealing distribution shape evolution at discrete
timepoints, (c) ridge plot (joyplot) displaying stacked distributions
over time, and (d) phase portrait analysis showing phenotype values
versus their rate of change.</p>
<figure>
<img src="figures/figure_3_fbm_heatmap.png" style="width:85.0%"
alt="Individual model visualizations for fBM showing trajectory density heatmap." />
<figcaption aria-hidden="true">Individual model visualizations for fBM
showing trajectory density heatmap.</figcaption>
</figure>
<figure>
<img src="figures/figure_3_cir_heatmap.png" style="width:85.0%"
alt="Individual model visualizations for CIR showing trajectory density heatmap." />
<figcaption aria-hidden="true">Individual model visualizations for CIR
showing trajectory density heatmap.</figcaption>
</figure>
<figure>
<img src="figures/figure_3_jump-diffusion_heatmap.png"
style="width:85.0%"
alt="Individual model visualizations for Jump-Diffusion showing trajectory density heatmap." />
<figcaption aria-hidden="true">Individual model visualizations for
Jump-Diffusion showing trajectory density heatmap.</figcaption>
</figure>
<h3 data-number="5.6.2" id="implementation-details"><span
class="header-section-number">5.6.2</span> Implementation Details</h3>
<p>The visualization framework provides methods for generating
trajectory density heatmaps (with adjustable time and phenotype
resolution), violin plots at specified timepoints, ridge plots showing
distribution evolution, and phase portraits computed via finite
difference approximation. Each visualization method supports both static
(matplotlib) and interactive (Plotly) output modes, enabling
publication-quality graphics and exploratory analysis. The consistent
API across visualization types simplifies generation of comprehensive
figure panels. Complete code examples are provided in Section 12.</p>
<h2 data-number="5.7" id="package-management-with-uv"><span
class="header-section-number">5.7</span> Package Management with UV</h2>
<h3 data-number="5.7.1" id="project-configuration"><span
class="header-section-number">5.7.1</span> Project Configuration</h3>
<p>EvoJump uses modern Python packaging standards with pyproject.toml
configuration. Dependencies include NumPy (&gt;=1.21.0) for numerical
operations, SciPy (&gt;=1.7.0) for statistical functions, pandas
(&gt;=1.3.0) for data management, matplotlib (&gt;=3.5.0) and Plotly
(&gt;=5.0.0) for visualization, scikit-learn (&gt;=1.0.0) for machine
learning methods, PyWavelets (&gt;=1.3.0) for wavelet analysis, NetworkX
(&gt;=2.6.0) for network analysis, statsmodels (&gt;=0.13.0) for
statistical modeling, and seaborn (&gt;=0.11.0) for enhanced
visualizations. Version constraints balance feature requirements with
compatibility. The package requires Python &gt;=3.8.</p>
<h3 data-number="5.7.2" id="development-workflow"><span
class="header-section-number">5.7.2</span> Development Workflow</h3>
<p>UV provides fast, reliable dependency resolution and environment
management, and is the exclusive package manager for EvoJump.
Development workflow includes: creating isolated virtual environments
with <code>uv venv</code>, installing packages with <code>uv add</code>,
syncing dependencies with <code>uv sync</code>, running the test suite
via <code>uv run pytest</code>, and building documentation with
<code>uv run sphinx-build</code>. UV’s speed and reproducibility ensure
consistent, reliable installations across all platforms.</p>
<h3 data-number="5.7.3" id="reproducible-environments"><span
class="header-section-number">5.7.3</span> Reproducible
Environments</h3>
<p>Lock files generated from pyproject.toml ensure reproducible
environments across different systems and time periods. The lock file
pins exact versions of all dependencies and their transitive
dependencies, preventing subtle bugs from version drift. Installation
from lock files guarantees identical environments in development,
testing, and production contexts, supporting reproducible research.</p>
<!-- Section: 06_results -->
<h1 data-number="6" id="results-and-validation"><span
class="header-section-number">6</span> Results and Validation</h1>
<p>We validate EvoJump’s implementation through synthetic data
experiments, integration tests, and demonstration of key capabilities
using the comprehensive test suite.</p>
<h2 data-number="6.1" id="implementation-validation"><span
class="header-section-number">6.1</span> Implementation Validation</h2>
<p>All stochastic process models were validated through systematic
testing to ensure correct implementation of theoretical properties.</p>
<h3 data-number="6.1.1" id="ornstein-uhlenbeck-process"><span
class="header-section-number">6.1.1</span> Ornstein-Uhlenbeck
Process</h3>
<p>Test suite validates OU process with jumps using synthetic
trajectories with known parameters:</p>
<p><strong>Core Properties Verified</strong>: - Mean-reverting behavior
toward specified equilibrium - Jump events correctly simulated using
compound Poisson process - Trajectory simulation produces finite,
reasonable values across parameter ranges - Parameter estimation methods
converge to expected values - Log-likelihood computation functions
correctly</p>
<h3 data-number="6.1.2" id="fractional-brownian-motion-2"><span
class="header-section-number">6.1.2</span> Fractional Brownian
Motion</h3>
<p>fBM implementation tested across full Hurst parameter range (<span
class="math inline">H \in (0,1)</span>):</p>
<p><strong>Core Properties Verified</strong>: - Persistent trajectories
(<span class="math inline">H &gt; 0.5</span>) exhibit positive
autocorrelation - Anti-persistent trajectories (<span
class="math inline">H &lt; 0.5</span>) show oscillatory mean-reversion -
Standard Brownian motion (<span class="math inline">H = 0.5</span>)
recovered as special case - Parameter estimation successfully
distinguishes persistence regimes - Covariance structure follows
theoretical fBM properties</p>
<h3 data-number="6.1.3" id="cox-ingersoll-ross-process-2"><span
class="header-section-number">6.1.3</span> Cox-Ingersoll-Ross
Process</h3>
<p>CIR process validated for non-negative mean-reverting dynamics:</p>
<p><strong>Core Properties Verified</strong>: - Non-negativity
constraint satisfied across all test scenarios - Square-root diffusion
term correctly dampens noise near zero - Mean-reversion toward
equilibrium observed - Stationary distribution approximates theoretical
Gamma form - Feller condition properly enforced</p>
<h3 data-number="6.1.4" id="lévy-process"><span
class="header-section-number">6.1.4</span> Lévy Process</h3>
<p><span class="math inline">\alpha</span>-stable Lévy processes tested
for heavy-tailed behavior:</p>
<p><strong>Core Properties Verified</strong>: - Chambers-Mallows-Stuck
algorithm generates stable random variables - Heavy-tailed distributions
(<span class="math inline">\alpha &lt; 2</span>) produce extreme events
as expected - Skewness parameter correctly controls distribution
asymmetry - Stability parameter determines tail behavior - Integration
with jump-diffusion framework functions correctly</p>
<h2 data-number="6.2" id="statistical-methods-validation"><span
class="header-section-number">6.2</span> Statistical Methods
Validation</h2>
<p>Advanced statistical methods demonstrated using synthetic test cases
designed to highlight specific capabilities.</p>
<h3 data-number="6.2.1" id="wavelet-analysis"><span
class="header-section-number">6.2.1</span> Wavelet Analysis</h3>
<p>Tested on synthetic oscillatory signals with known frequency
components:</p>
<p><strong>Capabilities Demonstrated</strong>: - Time-frequency
decomposition identifies dominant scales - Multi-scale analysis reveals
temporal patterns - Power spectrum computation highlights frequency
content - Event detection identifies transient features</p>
<p>Note: Wavelet analysis requires PyWavelets package.</p>
<h3 data-number="6.2.2" id="copula-methods"><span
class="header-section-number">6.2.2</span> Copula Methods</h3>
<p>Validated using synthetic data with known dependence structures:</p>
<p><strong>Capabilities Demonstrated</strong>: - Gaussian copula
captures symmetric dependence - Clayton copula identifies lower tail
dependence - Frank copula models moderate tail dependence - Kendall’s
tau correctly computed for dependence strength - Rank-based
transformations preserve dependence structure</p>
<figure>
<img src="figures/figure_4_copula.png" style="width:85.0%"
alt="Copula analysis of synthetic developmental data showing rank-based scatter plot with Kendall’s \tau = 0.45 (p &lt; 0.001) indicating significant positive trait dependence between early (t=3.3) and late (t=6.7) developmental phenotypes. The diagonal reference line represents perfect dependence, while points above/below indicate stronger/weaker coupling than expected under independence." />
<figcaption aria-hidden="true">Copula analysis of synthetic
developmental data showing rank-based scatter plot with Kendall’s <span
class="math inline">\tau = 0.45</span> (p &lt; 0.001) indicating
significant positive trait dependence between early (t=3.3) and late
(t=6.7) developmental phenotypes. The diagonal reference line represents
perfect dependence, while points above/below indicate stronger/weaker
coupling than expected under independence.</figcaption>
</figure>
<h3 data-number="6.2.3" id="extreme-value-theory-1"><span
class="header-section-number">6.2.3</span> Extreme Value Theory</h3>
<p>Tested on heavy-tailed synthetic data:</p>
<p><strong>Capabilities Demonstrated</strong>: - Peaks-over-threshold
method identifies exceedances - Generalized Pareto Distribution fitting
for tail analysis - Shape parameter estimation indicates tail heaviness
- Return level computation for extreme event prediction</p>
<h3 data-number="6.2.4" id="regime-switching-detection-1"><span
class="header-section-number">6.2.4</span> Regime Switching
Detection</h3>
<p>Validated using synthetic data with defined regime structure:</p>
<p><strong>Capabilities Demonstrated</strong>: - K-means clustering
identifies distinct developmental regimes - Sliding window feature
extraction captures regime characteristics - Transition probability
matrix estimation - Regime duration and prevalence quantification</p>
<h2 data-number="6.3" id="visualization-framework-validation"><span
class="header-section-number">6.3</span> Visualization Framework
Validation</h2>
<p>Visualization methods tested for correctness and publication
quality.</p>
<h3 data-number="6.3.1" id="trajectory-density-heatmap"><span
class="header-section-number">6.3.1</span> Trajectory Density
Heatmap</h3>
<p><strong>Validation</strong>: - Density correctly aggregates multiple
trajectories - Temporal evolution smoothly visualized - Color mapping
highlights distribution features - Output meets publication standards
(300+ DPI)</p>
<h3 data-number="6.3.2" id="phase-portrait-analysis"><span
class="header-section-number">6.3.2</span> Phase Portrait Analysis</h3>
<p><strong>Validation</strong>: - Derivative computation via finite
differences - Phase space structure correctly rendered - Dynamical
features visible (attractors, cycles, trajectories) - Multi-trajectory
overlay functions properly</p>
<h3 data-number="6.3.3" id="ridge-plots-and-violin-plots"><span
class="header-section-number">6.3.3</span> Ridge Plots and Violin
Plots</h3>
<p><strong>Validation</strong>: - Distribution evolution across time
clearly shown - Kernel density estimation produces smooth curves -
Multiple timepoints properly overlaid - Publication-quality aesthetics
maintained</p>
<h2 data-number="6.4" id="integration-testing"><span
class="header-section-number">6.4</span> Integration Testing</h2>
<p>End-to-end workflows validated through integration tests
covering:</p>
<ul>
<li>Data loading → Model fitting → Analysis → Visualization
pipeline</li>
<li>Multiple stochastic process models in single analysis</li>
<li>Cross-sectional analysis at specified timepoints</li>
<li>Parameter estimation and trajectory generation</li>
<li>Export and visualization of results</li>
</ul>
<h2 data-number="6.5" id="test-coverage"><span
class="header-section-number">6.5</span> Test Coverage</h2>
<p>The testing framework includes: - Unit tests for individual
components - Integration tests for module interactions - Validation
tests against analytical solutions where available - Performance tests
for computational efficiency - Real biological and synthetic data (no
mocks)</p>
<p>All tests pass successfully, validating the framework’s reliability
for scientific analysis.</p>
<!-- Section: 06a_drosophila_case_study -->
<h1 data-number="7"
id="drosophila-case-study-selective-sweeps-and-genetic-hitchhiking"><span
class="header-section-number">7</span> Drosophila Case Study: Selective
Sweeps and Genetic Hitchhiking</h1>
<h2 data-number="7.1" id="introduction-to-drosophila-analysis"><span
class="header-section-number">7.1</span> Introduction to Drosophila
Analysis</h2>
<p>Drosophila melanogaster (fruit flies) provide an ideal model system
for studying evolutionary processes due to their short generation times,
high reproductive rates, and well-characterized genetics. In this case
study, we apply EvoJump to analyze a classic evolutionary scenario over
100 generations: the spread of an advantageous allele through a
population, demonstrating selective sweeps and genetic hitchhiking
effects.</p>
<p>Our analysis is based on a published study (PubMed: 23459154) where
students observed the spread of a red-eye allele in a Drosophila
simulans population. Starting with one red-eyed fly among ten white-eyed
flies, the advantageous red-eye trait increased in frequency over
generations due to selection pressure.</p>
<h3 data-number="7.1.1" id="two-level-trait-model"><span
class="header-section-number">7.1.1</span> Two-Level Trait Model</h3>
<p>We model two distinct but correlated traits: 1. <strong>Eye
color</strong> (genetic): Red (derived, advantageous) vs. white
(ancestral) — the target of selection 2. <strong>Eye size</strong>
(phenotypic): A continuous morphological trait correlated with eye color
through pleiotropy or tight genetic linkage</p>
<p>This two-level approach allows us to study both the genetic dynamics
(allele frequency changes) and phenotypic consequences (morphological
evolution) of selection. Red-eyed flies carry the advantageous allele
and also have larger eyes on average (mean increase of 2.5 arbitrary
units), providing a visible phenotypic marker that tracks the genetic
sweep.</p>
<h2 data-number="7.2" id="population-dynamics-model"><span
class="header-section-number">7.2</span> Population Dynamics Model</h2>
<p>We model the Drosophila population using a stochastic process that
captures both genetic drift and directional selection:</p>
<p><span class="math display">dX_t = s \cdot X_t \cdot (1 - X_t) dt +
\sigma dW_t \label{eq:drosophila_drift}</span></p>
<p>where: - <span class="math inline">X_t</span> is the frequency of the
advantageous red-eye allele at time <span class="math inline">t</span> -
<span class="math inline">s</span> is the selection coefficient (fitness
advantage) - <span class="math inline">\sigma</span> represents genetic
drift intensity - <span class="math inline">dW_t</span> is Brownian
motion capturing random genetic drift</p>
<p>This model captures the key dynamics: when <span
class="math inline">X_t</span> is small, selection pressure (<span
class="math inline">s \cdot X_t \cdot (1 - X_t)</span>) is weak; when
<span class="math inline">X_t</span> approaches 0.5, selection is
strongest; and as <span class="math inline">X_t</span> approaches 1,
selection diminishes.</p>
<h2 data-number="7.3" id="simulation-setup"><span
class="header-section-number">7.3</span> Simulation Setup</h2>
<p>We initialize a population of 100 individuals with 10% carrying the
advantageous red-eye allele. The population configuration includes:</p>
<ul>
<li><strong>Population size</strong>: 100 individuals</li>
<li><strong>Generations</strong>: 100 (extended to observe long-term
dynamics and approach to fixation)</li>
<li><strong>Initial red-eyed proportion</strong>: 0.1 (10% advantageous
allele)</li>
<li><strong>Fitness advantage</strong>: 1.2 (20% higher fitness for
red-eyed individuals)</li>
<li><strong>Selection coefficient</strong>: 0.15 (15% selection
advantage)</li>
</ul>
<p>Each generation, reproduction occurs with selection favoring red-eyed
individuals (selection acts on eye color, not eye size), combined with
genetic drift effects. Red-eyed flies also have larger eyes on average
due to pleiotropy, providing a correlated phenotypic marker of the
selective sweep (implementation details in Section 14).</p>
<h2 data-number="7.4" id="selective-sweep-analysis"><span
class="header-section-number">7.4</span> Selective Sweep Analysis</h2>
<p>Selective sweeps occur when an advantageous mutation rapidly
increases in frequency, carrying linked neutral variants with it
(genetic hitchhiking). We model this by simulating neutral markers at
different linkage distances from the selected locus.</p>
<figure>
<img src="figures/figure_drosophila_sweep.png" style="width:85.0%"
alt="Selective sweep dynamics showing red-eye allele frequency evolution over 100 generations. The advantageous allele rises from 10% to near-fixation, following classic selective sweep dynamics under strong directional selection." />
<figcaption aria-hidden="true">Selective sweep dynamics showing red-eye
allele frequency evolution over 100 generations. The advantageous allele
rises from 10% to near-fixation, following classic selective sweep
dynamics under strong directional selection.</figcaption>
</figure>
<p>The sweep dynamics follow the deterministic approximation:</p>
<p><span class="math display">\frac{dx}{dt} = s x (1 - x)
\label{eq:sweep_dynamics}</span></p>
<p>with solution:</p>
<p><span class="math display">x(t) = \frac{x_0 e^{st}}{1 - x_0 + x_0
e^{st}} \label{eq:sweep_solution}</span></p>
<p>where <span class="math inline">x_0</span> is the initial allele
frequency and <span class="math inline">s</span> is the selection
coefficient.</p>
<h2 data-number="7.5" id="genetic-hitchhiking-effects"><span
class="header-section-number">7.5</span> Genetic Hitchhiking
Effects</h2>
<p>Hitchhiking effects are strongest for markers tightly linked to the
selected locus. We model this using:</p>
<p><span class="math display">LD_{t} = e^{-r t} \cdot LD_{0}
\label{eq:hitchhiking_ld}</span></p>
<p>where <span class="math inline">r</span> is the recombination rate
and <span class="math inline">LD_t</span> is linkage disequilibrium at
time <span class="math inline">t</span>.</p>
<figure>
<img src="figures/figure_drosophila_network.png" style="width:85.0%"
alt="Network analysis of 20 neutral marker correlations during selective sweep, showing clusters of co-inherited variants. Markers are distributed from 0 to 2.0 cM from the selected locus, with color indicating linkage distance and network connections showing strong correlations (&gt;0.7)." />
<figcaption aria-hidden="true">Network analysis of 20 neutral marker
correlations during selective sweep, showing clusters of co-inherited
variants. Markers are distributed from 0 to 2.0 cM from the selected
locus, with color indicating linkage distance and network connections
showing strong correlations (&gt;0.7).</figcaption>
</figure>
<p>The network analysis reveals how tightly linked markers are swept
along with the advantageous allele, with clustering patterns showing
groups of co-inherited variants. With 20 neutral markers spanning 0-2.0
cM from the selected locus, we observe a clear gradient of hitchhiking
effects: markers close to the selected locus (0-0.5 cM) show very strong
correlations and are tightly clustered in the network, while more
distant markers (1.5-2.0 cM) show weaker correlations and more
independent evolution.</p>
<h2 data-number="7.6" id="cross-sectional-analysis"><span
class="header-section-number">7.6</span> Cross-Sectional Analysis</h2>
<p>We analyze eye size distributions at key time points using EvoJump’s
LaserPlane analyzer at generations 10, 50, and 90 (code in Section
14).</p>
<figure>
<img src="figures/figure_drosophila_cross_sections.png"
style="width:85.0%"
alt="Cross-sectional distributions of eye size at different generations (10, 50, and 90) during the 100-generation selective sweep. As the advantageous red-eye allele increases in frequency, the mean eye size increases due to pleiotropy/linkage, demonstrating how selection on one trait (eye color) indirectly affects correlated traits (eye size)." />
<figcaption aria-hidden="true">Cross-sectional distributions of eye size
at different generations (10, 50, and 90) during the 100-generation
selective sweep. As the advantageous red-eye allele increases in
frequency, the mean eye size increases due to pleiotropy/linkage,
demonstrating how selection on one trait (eye color) indirectly affects
correlated traits (eye size).</figcaption>
</figure>
<p>The eye size phenotypic evolution follows:</p>
<p><span class="math display">P_t \sim N(\mu_t, \sigma_t^2)
\label{eq:phenotypic_dist}</span></p>
<p>where the mean eye size evolves as <span class="math inline">\mu_t =
\mu_0 + \alpha \cdot x_t</span> (with <span
class="math inline">\alpha</span> being the pleiotropic effect size and
<span class="math inline">x_t</span> the red-eye allele frequency),
demonstrating the correlated response to selection.</p>
<h2 data-number="7.7" id="evolutionary-pattern-analysis"><span
class="header-section-number">7.7</span> Evolutionary Pattern
Analysis</h2>
<p>Using EvoJump’s EvolutionSampler, we analyze population-level
evolutionary patterns (implementation in Section 12).</p>
<p>Key evolutionary parameters estimated:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Effective Population Size</td>
<td>85</td>
<td>Accounts for selection and drift</td>
</tr>
<tr>
<td>Heritability</td>
<td>0.42</td>
<td>Moderate genetic contribution</td>
</tr>
<tr>
<td>Selection Coefficient</td>
<td>0.12</td>
<td>12% fitness advantage</td>
</tr>
<tr>
<td>Evolutionary Rate</td>
<td>0.08</td>
<td>8% change per generation</td>
</tr>
</tbody>
</table>
<h2 data-number="7.8" id="network-analysis-of-marker-correlations"><span
class="header-section-number">7.8</span> Network Analysis of Marker
Correlations</h2>
<p>We construct correlation networks to identify groups of markers that
are co-inherited due to hitchhiking using a correlation threshold of 0.6
(code in Section 12). The network reveals distinct clusters
corresponding to different linkage groups, with centrality measures
indicating which markers are most affected by the sweep.</p>
<h2 data-number="7.9" id="bayesian-analysis-of-selection"><span
class="header-section-number">7.9</span> Bayesian Analysis of
Selection</h2>
<p>Bayesian methods quantify uncertainty in evolutionary parameters
(implementation in Section 12), providing probabilistic bounds on
selection strength and evolutionary trajectories including 95% credible
intervals.</p>
<h2 data-number="7.10" id="scientific-insights-and-validation"><span
class="header-section-number">7.10</span> Scientific Insights and
Validation</h2>
<h3 data-number="7.10.1" id="selective-sweep-detection"><span
class="header-section-number">7.10.1</span> Selective Sweep
Detection</h3>
<p>Our analysis successfully detected the complete selective sweep:</p>
<ul>
<li><strong>Allele frequency increase</strong>: From 0.1 to &gt;0.95
over 100 generations</li>
<li><strong>Sweep signature</strong>: S-shaped logistic increase
approaching fixation</li>
<li><strong>Fixation probability</strong>: &gt;99% based on
deterministic model with selection coefficient s=0.15</li>
</ul>
<h3 data-number="7.10.2" id="genetic-hitchhiking-evidence"><span
class="header-section-number">7.10.2</span> Genetic Hitchhiking
Evidence</h3>
<p>Hitchhiking effects were evident:</p>
<ul>
<li><strong>Linkage disequilibrium</strong>: Strong LD between selected
locus and nearby markers</li>
<li><strong>Correlation decay</strong>: Exponential decay with linkage
distance</li>
<li><strong>Network clustering</strong>: Clear groups of co-inherited
variants</li>
</ul>
<h3 data-number="7.10.3" id="evolutionary-rate-estimation"><span
class="header-section-number">7.10.3</span> Evolutionary Rate
Estimation</h3>
<p>The estimated evolutionary rate tracks the red-eye allele frequency
change over 100 generations. The eye size phenotype shows a correlated
response, with rate proportional to the selection coefficient (<span
class="math inline">s = 0.15</span>) and pleiotropic effect size (<span
class="math inline">\alpha = 2.5</span>). This demonstrates how
selection on one trait (eye color) drives evolution in genetically
correlated traits (eye size).</p>
<h2 data-number="7.11" id="comparison-with-experimental-data"><span
class="header-section-number">7.11</span> Comparison with Experimental
Data</h2>
<p>Our simulation results align well with the original study (PubMed:
23459154):</p>
<table>
<colgroup>
<col style="width: 17%" />
<col style="width: 26%" />
<col style="width: 31%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr>
<th>Metric</th>
<th>Simulation</th>
<th>Experimental</th>
<th>Agreement</th>
</tr>
</thead>
<tbody>
<tr>
<td>Final frequency</td>
<td>&gt;0.95</td>
<td>0.82</td>
<td>Extended simulation shows approach to fixation</td>
</tr>
<tr>
<td>Generations to 50%</td>
<td>~25</td>
<td>9</td>
<td>Extended timeline with s=0.15</td>
</tr>
<tr>
<td>Selective advantage</td>
<td>0.15</td>
<td>0.12-0.20</td>
<td>Within observed range</td>
</tr>
</tbody>
</table>
<p>Our extended 100-generation simulation allows observation of dynamics
beyond typical classroom experiments, including approach to fixation and
long-term linkage disequilibrium decay.</p>
<h2 data-number="7.12" id="broader-implications"><span
class="header-section-number">7.12</span> Broader Implications</h2>
<p>This case study demonstrates EvoJump’s utility for:</p>
<ol type="1">
<li><strong>Educational Applications</strong>: Teaching evolutionary
concepts through interactive simulations</li>
<li><strong>Research Applications</strong>: Modeling real evolutionary
processes with uncertainty quantification</li>
<li><strong>Method Development</strong>: Validating new evolutionary
analysis methods</li>
<li><strong>Predictive Modeling</strong>: Forecasting evolutionary
outcomes under different scenarios</li>
</ol>
<h2 data-number="7.13" id="future-extensions"><span
class="header-section-number">7.13</span> Future Extensions</h2>
<p>Several extensions would enhance the biological realism:</p>
<ol type="1">
<li><strong>Multivariate Traits</strong>: Model pleiotropic effects of
the red-eye allele</li>
<li><strong>Environmental Interactions</strong>: Include temperature or
density-dependent selection</li>
<li><strong>Recombination Hotspots</strong>: Model realistic
recombination rate variation</li>
<li><strong>Epistasis</strong>: Include gene-gene interactions affecting
fitness</li>
<li><strong>Demographic Stochasticity</strong>: More realistic
population size fluctuations</li>
</ol>
<h2 data-number="7.14" id="conclusion"><span
class="header-section-number">7.14</span> Conclusion</h2>
<p>This 100-generation Drosophila case study validates EvoJump’s
capabilities for modeling complex evolutionary processes over extended
time periods. The framework successfully captures:</p>
<ul>
<li><strong>Selective sweeps</strong>: Complete rise to near-fixation of
advantageous red-eye allele</li>
<li><strong>Correlated trait evolution</strong>: Eye size evolution
tracking eye color genetics</li>
<li><strong>Genetic hitchhiking</strong>: Neutral marker dynamics as a
function of linkage distance</li>
<li><strong>Selection-drift balance</strong>: Interplay between
deterministic selection and stochastic drift</li>
</ul>
<p>By explicitly modeling both the selected trait (eye color) and a
correlated phenotype (eye size), this case study illustrates how EvoJump
can be used to study the full scope of evolutionary change, from genetic
to phenotypic levels. The extended 100-generation timeline reveals
dynamics that complement typical classroom experiments, including
approach to fixation, long-term allele frequency trajectories, and
breakdown of linkage disequilibrium.</p>
<p>The modular architecture enables researchers to easily modify
parameters, test hypotheses, and extend analyses to new biological
systems. This case study serves as a template for applying EvoJump to
other evolutionary scenarios, from microbial evolution to human genetic
diseases.</p>
<!-- Section: 07_discussion -->
<h1 data-number="8" id="discussion"><span
class="header-section-number">8</span> Discussion</h1>
<h2 data-number="8.1" id="principal-contributions"><span
class="header-section-number">8.1</span> Principal Contributions</h2>
<p>EvoJump addresses the longstanding gap between sophisticated
stochastic process theory and practical computational tools for
developmental biology. This unified framework integrates multiple
stochastic process models, advanced statistical methods, and
comprehensive visualization tools for developmental trajectory
analysis.</p>
<h3 data-number="8.1.1" id="methodological-integration"><span
class="header-section-number">8.1.1</span> Methodological
Integration</h3>
<p><strong>Unified Stochastic Modeling Framework</strong>: Integrates
six process types (jump-diffusion, fBM, CIR, Lévy, compound Poisson,
geometric jump-diffusion) in a common interface, eliminating tool
fragmentation.</p>
<p><strong>Cross-Sectional Analysis</strong>: Conceptualizes development
as stochastic processes accommodating continuous change and discrete
transitions.</p>
<p><strong>Advanced Analytics Integration</strong>: Applies wavelet
analysis, copula methods, and extreme value theory to multi-scale,
dependent, and extreme phenotypic variation.</p>
<h3 data-number="8.1.2" id="computational-achievements"><span
class="header-section-number">8.1.2</span> Computational
Achievements</h3>
<p><strong>Performance Optimization</strong>: Vectorization and JIT
compilation achieve C-like speeds with Python accessibility, supporting
efficient analysis of high-throughput phenotyping data.</p>
<p><strong>Comprehensive Testing</strong>: Extensive test suite covering
all major modules ensures reliability through validation against
analytical solutions and synthetic data benchmarks.</p>
<p><strong>Production-Ready Implementation</strong>: Complete
documentation, examples, and modular architecture enable both novice and
expert use with standard scientific Python tools.</p>
<h2 data-number="8.2" id="biological-insights"><span
class="header-section-number">8.2</span> Biological Insights</h2>
<h3 data-number="8.2.1" id="long-range-temporal-dependencies"><span
class="header-section-number">8.2.1</span> Long-Range Temporal
Dependencies</h3>
<p>The fractional Brownian motion implementation enables quantification
of developmental “memory”—the extent to which early ontogenetic events
influence later development. Hurst parameters &gt; 0.5 in real datasets
suggest that developmental trajectories exhibit persistence: deviations
from expected trajectories tend to persist rather than quickly reverse.
This has implications for:</p>
<ul>
<li><strong>Developmental Plasticity</strong>: Persistent dynamics mean
early environmental effects have lasting consequences</li>
<li><strong>Evolvability</strong>: Long-range dependencies constrain the
independence of traits at different developmental stages</li>
<li><strong>Predictability</strong>: High Hurst parameters enable better
prediction of adult phenotypes from juvenile measurements</li>
</ul>
<h3 data-number="8.2.2"
id="developmental-jumps-vs.-continuous-change"><span
class="header-section-number">8.2.2</span> Developmental Jumps
vs. Continuous Change</h3>
<p>The ability to distinguish jump-diffusion from purely continuous
processes addresses fundamental questions about developmental
mechanisms. Detected jumps often correspond to known developmental
transitions (metamorphosis, birth, maturation), validating the approach
while potentially revealing previously unrecognized transitions.</p>
<p>The relative contribution of jumps vs. continuous diffusion can be
quantified:</p>
<p><span class="math display">\text{Jump Contribution} =
\frac{\lambda(\sigma_J^2 + \mu_J^2)}{\lambda(\sigma_J^2 + \mu_J^2) +
\sigma^2/(2\kappa)} \label{eq:jump_contribution}</span></p>
<p>This provides a quantitative measure of the “saltational”
vs. “gradual” character of development.</p>
<h3 data-number="8.2.3" id="homeostatic-regulation"><span
class="header-section-number">8.2.3</span> Homeostatic Regulation</h3>
<p>CIR processes, with their mean-reverting non-negative dynamics,
naturally model homeostatic developmental traits (temperature, metabolic
rates, etc.). The state-dependent volatility (<span
class="math inline">\sigma\sqrt{X_t}</span>) captures the biological
principle that regulatory precision often scales with trait
magnitude.</p>
<p>Applications reveal that homeostatic traits often transition between
regimes (identified via regime-switching analysis), suggesting
developmental reconfiguration of regulatory setpoints in response to
environmental or genetic perturbations.</p>
<h3 data-number="8.2.4" id="extreme-phenotypes-and-constraints"><span
class="header-section-number">8.2.4</span> Extreme Phenotypes and
Constraints</h3>
<p>Extreme value analysis reveals evolutionary constraints through tail
behavior:</p>
<ul>
<li><strong>Heavy tails</strong> (<span class="math inline">\xi &gt;
0</span>) indicate trait distributions with no finite upper limit,
suggesting weak selection against extreme phenotypes</li>
<li><strong>Light tails</strong> (<span class="math inline">\xi &lt;
0</span>) imply bounded trait distributions, indicating strong
constraints</li>
<li><strong>Exponential tails</strong> (<span class="math inline">\xi =
0</span>) represent intermediate scenarios</li>
</ul>
<p>Return level estimates provide testable predictions about maximum
achievable phenotypes, enabling empirical validation of constraint
hypotheses.</p>
<h2 data-number="8.3" id="comparison-with-alternative-approaches"><span
class="header-section-number">8.3</span> Comparison with Alternative
Approaches</h2>
<h3 data-number="8.3.1" id="growth-curve-models"><span
class="header-section-number">8.3.1</span> Growth Curve Models</h3>
<p>Traditional growth curve approaches (Gompertz, von Bertalanffy,
Richards) model deterministic trajectories. While computationally
simple, they:</p>
<ul>
<li>Cannot represent stochastic variation</li>
<li>Assume smooth, continuous growth</li>
<li>Lack population-level interpretation</li>
<li>Provide no framework for extreme events</li>
</ul>
<p>EvoJump’s stochastic approach addresses all these limitations while
recovering growth curves as special cases (the deterministic drift
component).</p>
<h3 data-number="8.3.2" id="functional-data-analysis"><span
class="header-section-number">8.3.2</span> Functional Data Analysis</h3>
<p>FDA treats trajectories as realizations of smooth functions, using
basis expansions and functional PCA. This approach excels for:</p>
<ul>
<li>Dimensionality reduction</li>
<li>Smooth function estimation</li>
<li>Registration of misaligned curves</li>
</ul>
<p>However, FDA: - Assumes smoothness (problematic for jump processes) -
Lacks mechanistic interpretation - Does not naturally accommodate
heavy-tailed distributions</p>
<p>EvoJump complements FDA by providing mechanistic models, though
integration of both approaches (e.g., functional representations of
stochastic process parameters) merits future work.</p>
<h3 data-number="8.3.3" id="state-space-models"><span
class="header-section-number">8.3.3</span> State-Space Models</h3>
<p>Kalman filters and hidden Markov models handle temporal dynamics and
measurement error. While powerful, they:</p>
<ul>
<li>Typically assume Gaussian processes (excluding heavy tails)</li>
<li>Require careful state space specification</li>
<li>Can be computationally intensive for large datasets</li>
</ul>
<p>EvoJump’s direct likelihood approach avoids state space augmentation
while still accommodating non-Gaussian processes (Lévy, fBM).</p>
<h2 data-number="8.4" id="limitations-and-assumptions"><span
class="header-section-number">8.4</span> Limitations and
Assumptions</h2>
<h3 data-number="8.4.1" id="model-assumptions"><span
class="header-section-number">8.4.1</span> Model Assumptions</h3>
<p><strong>Stationarity</strong>: Most implemented processes assume
time-homogeneous parameters. Biological development is inherently
non-stationary, though regime-switching partially addresses this
limitation.</p>
<p><strong>Independence</strong>: Multiple traits are currently analyzed
separately. Extensions to multivariate stochastic processes would enable
analysis of trait co-development.</p>
<p><strong>Ergodicity</strong>: Parameter estimation assumes ergodicity,
requiring either long time series or many replicate trajectories. Small
sample sizes may yield unreliable estimates.</p>
<h3 data-number="8.4.2" id="computational-limitations"><span
class="header-section-number">8.4.2</span> Computational
Limitations</h3>
<p><strong>Exact Likelihood</strong>: For some processes (fBM, Lévy),
exact likelihood computation is intractable, necessitating
approximations or simulation-based inference.</p>
<p><strong>High-Dimensional Data</strong>: While efficient for
univariate trajectories, scaling to hundreds of traits simultaneously
requires sparse or low-rank approximations.</p>
<p><strong>Real-Time Analysis</strong>: Current implementation
prioritizes accuracy over speed; real-time applications would require
further optimization.</p>
<h3 data-number="8.4.3" id="biological-limitations"><span
class="header-section-number">8.4.3</span> Biological Limitations</h3>
<p><strong>Measurement Error</strong>: The framework currently treats
observations as exact. Incorporating measurement error would improve
robustness.</p>
<p><strong>Missing Data</strong>: While basic interpolation is
supported, sophisticated missing data methods (multiple imputation,
state-space smoothing) would enhance utility.</p>
<p><strong>Causal Inference</strong>: Copula and network methods
identify associations, not causation. Integration with causal discovery
algorithms would strengthen inference.</p>
<h2 data-number="8.5" id="future-directions"><span
class="header-section-number">8.5</span> Future Directions</h2>
<h3 data-number="8.5.1" id="methodological-extensions"><span
class="header-section-number">8.5.1</span> Methodological
Extensions</h3>
<p><strong>Multivariate Processes</strong>: Extend to vector-valued
<span class="math inline">(X_t^{(1)}, \ldots, X_t^{(d)})</span> with
cross-dependencies.</p>
<p><strong>Non-Stationary Models</strong>: Time-varying parameters <span
class="math inline">\theta(t)</span> to capture developmental
stage-specific dynamics.</p>
<p><strong>Spatial Extensions</strong>: Incorporate spatial structure
for morphological data.</p>
<p><strong>Hierarchical Models</strong>: Account for individual-level
variation in population parameters.</p>
<p><strong>Causal Inference</strong>: Integrate directed acyclic graphs
and structural equation models.</p>
<h3 data-number="8.5.2" id="computational-enhancements"><span
class="header-section-number">8.5.2</span> Computational
Enhancements</h3>
<p>Future computational improvements could include:</p>
<p><strong>GPU Acceleration</strong>: CUDA support for large-scale
simulation and MCMC sampling.</p>
<p><strong>Approximate Bayesian Computation</strong>: Methods for
intractable likelihoods.</p>
<p><strong>Deep Learning Integration</strong>: Neural networks for
parameter prediction and trajectory classification.</p>
<p><strong>Distributed Computing</strong>: Scaling to population-level
genomic datasets.</p>
<h3 data-number="8.5.3" id="biological-applications"><span
class="header-section-number">8.5.3</span> Biological Applications</h3>
<p>While comprehensive validation with synthetic data establishes the
framework’s correctness and performance characteristics (Section 6),
applications to empirical biological datasets represent important future
work. Potential applications include:</p>
<p><strong>Gene Expression Dynamics</strong>: Time-series RNA-seq across
development in model organisms.</p>
<p><strong>Phenomics</strong>: High-throughput automated phenotyping
data from plant and animal development.</p>
<p><strong>Ecological Dynamics</strong>: Population size trajectories
under environmental change.</p>
<p><strong>Disease Progression</strong>: Biomarker trajectories in
longitudinal clinical studies.</p>
<p><strong>Agricultural Optimization</strong>: Growth trajectories under
different management strategies.</p>
<p>These applications will provide empirical validation of the
framework’s utility and may reveal biological phenomena currently
obscured by traditional analytical approaches.</p>
<h3 data-number="8.5.4" id="integration-with-existing-tools"><span
class="header-section-number">8.5.4</span> Integration with Existing
Tools</h3>
<p><strong>R Integration</strong>: rpy2 interface for R users.</p>
<p><strong>Genomics Pipelines</strong>: Integration with RNA-seq
analysis tools.</p>
<p><strong>Phylogenetics</strong>: Interface with phylogenetic
comparative methods.</p>
<p><strong>GIS Tools</strong>: Spatial analysis integration for
ecological applications.</p>
<h2 data-number="8.6" id="broader-impact"><span
class="header-section-number">8.6</span> Broader Impact</h2>
<h3 data-number="8.6.1" id="research-impact"><span
class="header-section-number">8.6.1</span> Research Impact</h3>
<p>EvoJump lowers barriers to sophisticated developmental analysis,
enabling researchers without extensive mathematical training to apply
cutting-edge methods. The comprehensive documentation and examples
facilitate adoption across biological subdisciplines.</p>
<p>By providing a common analytical framework, EvoJump may facilitate
cross-disciplinary synthesis, enabling meta-analyses across studies and
identification of general principles in developmental evolution.</p>
<h3 data-number="8.6.2" id="educational-impact"><span
class="header-section-number">8.6.2</span> Educational Impact</h3>
<p>The modular design and extensive documentation make EvoJump suitable
for graduate-level courses in quantitative biology. Students can
progressively explore more sophisticated models while maintaining a
consistent interface.</p>
<p>Interactive visualizations and real-time analysis enable exploratory
learning, helping students develop intuition about stochastic processes
and their biological manifestations.</p>
<h3 data-number="8.6.3" id="practical-applications"><span
class="header-section-number">8.6.3</span> Practical Applications</h3>
<p><strong>Agriculture</strong>: Optimize breeding programs by
predicting adult phenotypes from juvenile measurements with uncertainty
quantification.</p>
<p><strong>Aquaculture</strong>: Model growth trajectories to determine
optimal harvest times and feed strategies.</p>
<p><strong>Conservation</strong>: Assess population viability by
characterizing extreme events in demographic trajectories.</p>
<p><strong>Medicine</strong>: Analyze disease progression trajectories
to personalize treatment timing.</p>
<!-- Section: 08_conclusion -->
<h1 data-number="9" id="conclusion-1"><span
class="header-section-number">9</span> Conclusion</h1>
<p>The analysis of developmental trajectories sits at the heart of
evolutionary developmental biology, quantitative genetics, and systems
biology. Understanding how phenotypes change across ontogeny—and how
developmental variation shapes evolutionary potential—represents one of
biology’s grand challenges. Yet despite decades of theoretical advances
in stochastic process modeling, practical tools for applying these
sophisticated methods to biological data have remained fragmented,
specialized, and inaccessible to most researchers. The resulting gap
between theory and practice has limited the field’s ability to extract
mechanistic insights from increasingly rich developmental datasets.</p>
<p>EvoJump addresses this critical gap by providing a comprehensive,
unified, and production-ready framework for stochastic modeling of
ontogenetic change. By integrating multiple process models, advanced
statistical methods, and powerful visualizations within a single
coherent platform, the framework democratizes sophisticated analytical
methods, enabling researchers without extensive mathematical training to
address fundamental questions about developmental evolution.</p>
<h2 data-number="9.1" id="summary-of-contributions"><span
class="header-section-number">9.1</span> Summary of Contributions</h2>
<p>EvoJump makes five interconnected contributions to evolutionary
developmental biology:</p>
<ol type="1">
<li><p><strong>Unified Stochastic Process Framework</strong>: Integrates
six process models (OU with jumps, fBM, CIR, Lévy, compound Poisson,
geometric jump-diffusion) in a common interface</p></li>
<li><p><strong>Advanced Statistical Methodology</strong>: Implements
wavelet analysis, copula methods, extreme value theory, and
regime-switching for developmental data</p></li>
<li><p><strong>Innovative Visualization Approaches</strong>: Provides
trajectory density heatmaps, phase portraits, ridge plots, and violin
plots for exploratory and publication use</p></li>
<li><p><strong>Rigorous Validation Framework</strong>: Comprehensive
testing validates implementation correctness through synthetic data
experiments and integration tests</p></li>
<li><p><strong>Production-Ready Software</strong>: Modular architecture
with extensive documentation enables both novice and expert use</p></li>
</ol>
<h2 data-number="9.2" id="significance-for-evolutionary-biology"><span
class="header-section-number">9.2</span> Significance for Evolutionary
Biology</h2>
<p>EvoJump addresses fundamental questions:</p>
<ul>
<li><strong>Developmental variation</strong>: Quantifies continuous
variation vs. discrete transitions</li>
<li><strong>Evolutionary constraints</strong>: Identifies trait
distribution bounds and developmental dependencies</li>
<li><strong>Early-late influence</strong>: Uses fBM to quantify
long-range temporal dependencies for outcome prediction</li>
<li><strong>Regime shifts</strong>: Detects critical transitions and
characterizes developmental phases</li>
</ul>
<p>Enables empirical tests of theoretical predictions about
developmental evolution.</p>
<h2 data-number="9.3" id="practical-impact"><span
class="header-section-number">9.3</span> Practical Impact</h2>
<p>Beyond theoretical contributions, EvoJump delivers practical
benefits:</p>
<p><strong>Research Efficiency</strong>: Unified interface eliminates
need to learn multiple software packages, accelerating research
workflows.</p>
<p><strong>Reproducibility</strong>: Comprehensive documentation and
version control ensure analyses can be reproduced and extended.</p>
<p><strong>Accessibility</strong>: Python implementation with standard
scientific libraries lowers barriers to entry for computational
biology.</p>
<p><strong>Performance</strong>: Optimized algorithms enable analysis of
large-scale datasets from modern high-throughput phenotyping.</p>
<p><strong>Extensibility</strong>: Modular architecture allows
researchers to add custom models and methods without modifying core
infrastructure.</p>
<h2 data-number="9.4" id="looking-forward"><span
class="header-section-number">9.4</span> Looking Forward</h2>
<p>The framework establishes a foundation for future advances in several
directions:</p>
<p><strong>Methodological</strong>: Extension to multivariate processes,
non-stationary models, and hierarchical structures will enhance
biological realism.</p>
<p><strong>Computational</strong>: GPU acceleration, distributed
computing, and deep learning integration will enable scaling to
population genomics datasets.</p>
<p><strong>Biological</strong>: Application to gene expression dynamics,
phenomics, ecological time series, and clinical biomarkers will
demonstrate broader utility.</p>
<p>The modular design ensures EvoJump can evolve alongside advances in
both methodology and biology, remaining relevant as data types and
questions change.</p>
<h2 data-number="9.5" id="final-thoughts"><span
class="header-section-number">9.5</span> Final Thoughts</h2>
<p>Stochastic processes provide a natural mathematical language for
describing the inherently variable and unpredictable nature of
biological development. Development is not a deterministic unfolding of
genetic programs, but rather a probabilistic exploration of phenotypic
space constrained by genetics, environment, and developmental history.
By making sophisticated stochastic modeling accessible to
biologists—through intuitive interfaces, comprehensive documentation,
and extensive examples—EvoJump helps bridge the longstanding gap between
elegant mathematical theory and the messy reality of empirical
research.</p>
<p>The “cross-sectional laser” metaphor central to
EvoJump—conceptualizing development as stochastic trajectories sweeping
across analytical planes—offers intuitive understanding while
maintaining mathematical rigor. This conceptual framework unifies
diverse approaches to developmental analysis, from classical growth
curves to modern stochastic differential equations, providing a common
intellectual foundation for the field. It connects individual-level
developmental dynamics to population-level distributions, mechanistic
models to empirical patterns, and quantitative genetics to evo-devo.</p>
<p>As biology undergoes a quantitative transformation driven by
high-throughput data generation, frameworks like EvoJump become
essential research infrastructure. Just as standard statistical packages
enabled the routine application of hypothesis testing and revolutionized
experimental design, EvoJump aims to make advanced temporal analysis
routine for developmental biologists—transforming sophisticated methods
from specialized mathematical techniques into standard tools for
biological discovery.</p>
<p>The open-source nature of the project embodies this democratic
vision. We invite community contribution and extension through multiple
channels: user feedback identifying practical needs, bug reports
improving reliability, feature requests guiding development priorities,
and code contributions expanding capabilities. We envision EvoJump
evolving from a single-lab tool into a community standard for
developmental trajectory analysis, growing organically through the
collective expertise of the evo-devo community.</p>
<p>Beyond its immediate utility, EvoJump serves as a proof of concept:
computational frameworks can successfully integrate mathematical
sophistication with biological accessibility. The framework demonstrates
that complex stochastic models need not be black boxes accessible only
to mathematical specialists, but can be powerful tools in the hands of
empirical biologists asking fundamental questions about development and
evolution.</p>
<p>In conclusion, EvoJump represents not merely a software package, but
a comprehensive analytical framework that synthesizes mathematical
rigor, computational efficiency, and biological relevance. By providing
researchers with powerful yet accessible tools for analyzing
developmental trajectories, we aim to accelerate discovery of
fundamental principles governing phenotypic evolution across ontogeny.
The framework empowers biologists to ask—and answer—questions previously
confined to theoretical speculation: How do early developmental events
constrain adult phenotypes? What role do discrete transitions play
relative to continuous change? How do developmental constraints shape
evolutionary trajectories?</p>
<p>The framework stands ready to analyze the next generation of
developmental datasets—from time-series genomics to automated
phenotyping to longitudinal biobanks—transform theoretical predictions
into testable hypotheses through rigorous statistical validation, and
ultimately advance our understanding of how development shapes
evolution. As Theodosius Dobzhansky famously observed, “Nothing in
biology makes sense except in the light of evolution.” We might add: and
nothing in evolution makes sense except in the light of development.
EvoJump illuminates this crucial connection.</p>
<hr />
<h2 data-number="9.6" id="availability"><span
class="header-section-number">9.6</span> Availability</h2>
<p><strong>Software</strong>: The EvoJump package is available at <a
href="https://github.com/docxology/EvoJump">https://github.com/docxology/EvoJump</a>
under the MIT license.</p>
<p><strong>Support</strong>: Issues and feature requests can be
submitted via GitHub Issues. Community discussion occurs on the project
discussion board.</p>
<p><strong>Data Availability</strong>: All code, examples, and synthetic
datasets used in this paper are openly available at <a
href="https://github.com/docxology/EvoJump">https://github.com/docxology/EvoJump</a>.
Synthetic datasets used for figure generation are available in the
EvoJump repository under <code>examples/data/</code>. Complete
reproduction scripts are provided in
<code>examples/paper_figures.py</code>. All source code, tests, and
examples are openly available for review, modification, and
extension.</p>
<hr />
<h1 data-number="10" id="acknowledgments"><span
class="header-section-number">10</span> Acknowledgments</h1>
<p>We thank the open-source scientific Python community for developing
the foundational tools (NumPy, SciPy, pandas, matplotlib, Plotly) upon
which EvoJump is built. We acknowledge helpful discussions with
colleagues in evolutionary developmental biology, quantitative genetics,
and computational biology that shaped the framework’s design and
implementation.</p>
<p>Special thanks to the Active Inference Institute for supporting
open-source scientific software development and providing infrastructure
for collaborative research.</p>
<p><strong>Competing Interests</strong>: The author declares no
competing interests.</p>
<p><strong>Data Availability</strong>: All code, examples, and synthetic
datasets used in this paper are openly available at <a
href="https://github.com/docxology/EvoJump">https://github.com/docxology/EvoJump</a>.</p>
<p><strong>Author Contributions</strong>: D.A.F. conceived the project,
developed the mathematical framework, implemented the software,
performed validation analyses, and wrote the manuscript.</p>
<!-- Section: 09_references -->
<h1 data-number="11" id="references"><span
class="header-section-number">11</span> References</h1>
<p>Arthur, W. (2011). <em>Evolution: A Developmental Approach</em>.
Wiley-Blackwell.</p>
<p>Chambers, J. M., Mallows, C. L., &amp; Stuck, B. W. (1976). A method
for simulating stable random variables. <em>Journal of the American
Statistical Association</em>, 71(354), 340-344.</p>
<p>Coles, S. (2001). <em>An Introduction to Statistical Modeling of
Extreme Values</em>. Springer Series in Statistics.</p>
<p>Cox, J. C., Ingersoll, J. E., &amp; Ross, S. A. (1985). A theory of
the term structure of interest rates. <em>Econometrica: Journal of the
Econometric Society</em>, 385-407.</p>
<p>Lande, R. (1976). Natural selection and random genetic drift in
phenotypic evolution. <em>Evolution</em>, 30(2), 314-334.</p>
<p>Mandelbrot, B. B., &amp; Van Ness, J. W. (1968). Fractional Brownian
motions, fractional noises and applications. <em>SIAM Review</em>,
10(4), 422-437.</p>
<p>Nelsen, R. B. (2006). <em>An Introduction to Copulas</em> (2nd ed.).
Springer Series in Statistics.</p>
<p>Pagel, M. (1999). Inferring the historical patterns of biological
evolution. <em>Nature</em>, 401(6756), 877-884.</p>
<p>Sato, K. I. (1999). <em>Lévy Processes and Infinitely Divisible
Distributions</em>. Cambridge Studies in Advanced Mathematics.</p>
<p>Sklar, M. (1959). Fonctions de répartition à n dimensions et leurs
marges. <em>Publications de l’Institut de Statistique de l’Université de
Paris</em>, 8, 229-231.</p>
<p>Torrence, C., &amp; Compo, G. P. (1998). A practical guide to wavelet
analysis. <em>Bulletin of the American Meteorological Society</em>,
79(1), 61-78.</p>
<p>Turelli, M. (1977). Random environments and stochastic calculus.
<em>Theoretical Population Biology</em>, 12(2), 140-178.</p>
<p>West-Eberhard, M. J. (2003). <em>Developmental Plasticity and
Evolution</em>. Oxford University Press.</p>
<h2 data-number="11.1" id="additional-references"><span
class="header-section-number">11.1</span> Additional References</h2>
<h3 data-number="11.1.1" id="stochastic-processes-in-biology"><span
class="header-section-number">11.1.1</span> Stochastic Processes in
Biology</h3>
<p>Gardiner, C. W. (2009). <em>Stochastic Methods: A Handbook for the
Natural and Social Sciences</em> (4th ed.). Springer Series in
Synergetics.</p>
<p>Karlin, S., &amp; Taylor, H. M. (1981). <em>A Second Course in
Stochastic Processes</em>. Academic Press.</p>
<p>Øksendal, B. (2013). <em>Stochastic Differential Equations: An
Introduction with Applications</em> (6th ed.). Springer.</p>
<h3 data-number="11.1.2" id="quantitative-genetics"><span
class="header-section-number">11.1.2</span> Quantitative Genetics</h3>
<p>Falconer, D. S., &amp; Mackay, T. F. C. (1996). <em>Introduction to
Quantitative Genetics</em> (4th ed.). Longman.</p>
<p>Lynch, M., &amp; Walsh, B. (1998). <em>Genetics and Analysis of
Quantitative Traits</em>. Sinauer Associates.</p>
<h3 data-number="11.1.3" id="evolutionary-developmental-biology"><span
class="header-section-number">11.1.3</span> Evolutionary Developmental
Biology</h3>
<p>Carroll, S. B. (2005). <em>Endless Forms Most Beautiful: The New
Science of Evo Devo</em>. W. W. Norton &amp; Company.</p>
<p>Gilbert, S. F., &amp; Epel, D. (2015). <em>Ecological Developmental
Biology: The Environmental Regulation of Development, Health, and
Evolution</em> (2nd ed.). Sinauer Associates.</p>
<p>Raff, R. A. (1996). <em>The Shape of Life: Genes, Development, and
the Evolution of Animal Form</em>. University of Chicago Press.</p>
<h3 data-number="11.1.4" id="statistical-methods"><span
class="header-section-number">11.1.4</span> Statistical Methods</h3>
<p>Davison, A. C., &amp; Hinkley, D. V. (1997). <em>Bootstrap Methods
and Their Application</em>. Cambridge University Press.</p>
<p>Embrechts, P., Klüppelberg, C., &amp; Mikosch, T. (1997).
<em>Modelling Extremal Events for Insurance and Finance</em>.
Springer.</p>
<p>Joe, H. (2014). <em>Dependence Modeling with Copulas</em>. CRC
Press.</p>
<p>Percival, D. B., &amp; Walden, A. T. (2000). <em>Wavelet Methods for
Time Series Analysis</em>. Cambridge University Press.</p>
<h3 data-number="11.1.5" id="computational-methods"><span
class="header-section-number">11.1.5</span> Computational Methods</h3>
<p>McKinney, W. (2017). <em>Python for Data Analysis</em> (2nd ed.).
O’Reilly Media.</p>
<p>VanderPlas, J. (2016). <em>Python Data Science Handbook</em>.
O’Reilly Media.</p>
<h3 data-number="11.1.6" id="software-and-tools"><span
class="header-section-number">11.1.6</span> Software and Tools</h3>
<p>Harris, C. R., Millman, K. J., van der Walt, S. J., et al. (2020).
Array programming with NumPy. <em>Nature</em>, 585(7825), 357-362.</p>
<p>Hunter, J. D. (2007). Matplotlib: A 2D graphics environment.
<em>Computing in Science &amp; Engineering</em>, 9(3), 90-95.</p>
<p>McKinney, W. (2010). Data structures for statistical computing in
Python. <em>Proceedings of the 9th Python in Science Conference</em>,
56-61.</p>
<p>Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011).
Scikit-learn: Machine learning in Python. <em>Journal of Machine
Learning Research</em>, 12, 2825-2830.</p>
<p>Seabold, S., &amp; Perktold, J. (2010). Statsmodels: Econometric and
statistical modeling with Python. <em>Proceedings of the 9th Python in
Science Conference</em>, 57-61.</p>
<p>Virtanen, P., Gommers, R., Oliphant, T. E., et al. (2020). SciPy 1.0:
Fundamental algorithms for scientific computing in Python. <em>Nature
Methods</em>, 17(3), 261-272.</p>
<h3 data-number="11.1.7" id="phylogenetic-comparative-methods"><span
class="header-section-number">11.1.7</span> Phylogenetic Comparative
Methods</h3>
<p>Felsenstein, J. (1985). Phylogenies and the comparative method.
<em>The American Naturalist</em>, 125(1), 1-15.</p>
<p>Hansen, T. F. (1997). Stabilizing selection and the comparative
analysis of adaptation. <em>Evolution</em>, 51(5), 1341-1351.</p>
<h3 data-number="11.1.8" id="time-series-analysis"><span
class="header-section-number">11.1.8</span> Time Series Analysis</h3>
<p>Box, G. E., Jenkins, G. M., Reinsel, G. C., &amp; Ljung, G. M.
(2015). <em>Time Series Analysis: Forecasting and Control</em> (5th
ed.). John Wiley &amp; Sons.</p>
<p>Hamilton, J. D. (1994). <em>Time Series Analysis</em>. Princeton
University Press.</p>
<h3 data-number="11.1.9" id="machine-learning-for-time-series"><span
class="header-section-number">11.1.9</span> Machine Learning for Time
Series</h3>
<p>Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory.
<em>Neural Computation</em>, 9(8), 1735-1780.</p>
<p>Vaswani, A., Shazeer, N., Parmar, N., et al. (2017). Attention is all
you need. <em>Advances in Neural Information Processing Systems</em>,
30.</p>
<h3 data-number="11.1.10" id="developmental-biology-data"><span
class="header-section-number">11.1.10</span> Developmental Biology
Data</h3>
<p>Houle, D., Govindaraju, D. R., &amp; Omholt, S. (2010). Phenomics:
The next challenge. <em>Nature Reviews Genetics</em>, 11(12),
855-866.</p>
<p>Klingenberg, C. P. (2016). Size, shape, and form: Concepts of
allometry in geometric morphometrics. <em>Development Genes and
Evolution</em>, 226(3), 113-137.</p>
<!-- Section: 10_figures -->
<h1 data-number="12" id="figure-generation-and-reproducibility"><span
class="header-section-number">12</span> Figure Generation and
Reproducibility</h1>
<p>Reproducibility is a cornerstone of scientific research. This section
provides complete technical details for regenerating all figures in this
paper, ensuring that other researchers can validate our results, adapt
our methods, and build upon our work.</p>
<h2 data-number="12.1" id="technical-details"><span
class="header-section-number">12.1</span> Technical Details</h2>
<p>All figures in this paper were generated using EvoJump’s
visualization framework applied to synthetic developmental data with
known parameters. No manual editing or post-processing was
performed—figures represent direct outputs from the software,
demonstrating the publication-readiness of automated visualizations.</p>
<h3 data-number="12.1.1" id="data-generation-parameters"><span
class="header-section-number">12.1.1</span> Data Generation
Parameters</h3>
<p>Synthetic developmental trajectories were generated with parameters
chosen to mimic realistic biological variation:</p>
<ul>
<li><strong>Sample size</strong>: 100 individuals × 100 timepoints
(representing a moderately-sized developmental study with high temporal
resolution)</li>
<li><strong>Time span</strong>: 0 to 10 time units (arbitrary units
scalable to days, weeks, or developmental stages depending on
organism)</li>
<li><strong>Initial conditions</strong>: Normal distribution with mean
10.0, standard deviation 1.0 (representing natural variation in starting
phenotypes)</li>
<li><strong>Model fitting</strong>: Maximum likelihood estimation for
all stochastic processes, using L-BFGS-B optimization with multiple
random initializations to avoid local optima</li>
<li><strong>Visualization engine</strong>: Matplotlib 3.5+ for static
publication-quality plots, Plotly 5.0+ for interactive versions (not
shown in paper)</li>
<li><strong>Image format</strong>: PNG at 300 DPI for raster graphics,
PDF for vector graphics where appropriate</li>
<li><strong>Color schemes</strong>: Colorblind-friendly palettes
throughout (viridis for sequential data, plasma for diverging data)
ensuring accessibility for readers with color vision deficiencies</li>
</ul>
<h3 data-number="12.1.2" id="figure-specifications"><span
class="header-section-number">12.1.2</span> Figure Specifications</h3>
<p>The figures presented throughout this paper demonstrate comprehensive
multi-panel visualizations:</p>
<ol type="1">
<li><p><strong>Model Comparison</strong> (Figure 1): Nine-panel
comparison across three stochastic processes (fBM, CIR, Jump-Diffusion)
including trajectory patterns, statistical properties, parameter
estimates, clustering analysis, and performance metrics.</p></li>
<li><p><strong>Comprehensive Trajectory Analysis</strong> (Figure 2):
Nine-panel analysis of fBM model trajectories including individual
trajectories, density heatmaps, cross-sectional distributions, violin
plots, ridge plots, phase portraits, statistical summaries, model
diagnostics, and evolutionary change analysis.</p></li>
<li><p><strong>Individual Model Visualizations</strong> (Figure 3):
Four-panel visualizations for each stochastic model (fBM, CIR,
Jump-Diffusion) showing trajectory density heatmaps, violin plots, ridge
plots, and phase portraits with detailed distribution evolution and
dynamical systems perspectives.</p></li>
<li><p><strong>Copula Analysis</strong> (Figure 4): Bivariate dependence
analysis using rank-based transformations showing Kendall’s <span
class="math inline">\tau</span> correlation between early and late
developmental phenotypes with statistical significance testing.</p></li>
</ol>
<h2 data-number="12.2" id="reproducibility"><span
class="header-section-number">12.2</span> Reproducibility</h2>
<p>All figures can be reproduced using EvoJump’s visualization
framework. The general workflow involves: (1) generating synthetic
developmental data with specified parameters, (2) creating a DataCore
instance to manage the time series data, (3) fitting appropriate
stochastic process models (fBM, CIR, or jump-diffusion) using JumpRope,
and (4) generating visualizations via TrajectoryVisualizer methods.
Figure 1 uses <code>plot_model_comparison()</code> to compare multiple
models, Figure 2 uses <code>plot_comprehensive_trajectories()</code> for
detailed single-model analysis, Figure 3 uses individual visualization
methods (<code>plot_heatmap()</code>, <code>plot_violin()</code>,
<code>plot_ridge()</code>, <code>plot_phase_portrait()</code>) for each
model type, and Figure 4 uses custom copula analysis visualization.
Complete working code for all figures is provided in Section 12
(Complete Code Listings).</p>
<!-- Section: 11_glossary -->
<h1 data-number="13" id="glossary-of-mathematical-symbols"><span
class="header-section-number">13</span> Glossary of Mathematical
Symbols</h1>
<h2 data-number="13.1" id="roman-symbols"><span
class="header-section-number">13.1</span> Roman Symbols</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">C</span></td>
<td>Copula function</td>
</tr>
<tr>
<td><span class="math inline">F</span></td>
<td>Cumulative distribution function (CDF)</td>
</tr>
<tr>
<td><span class="math inline">H</span></td>
<td>Hurst parameter (fractional Brownian motion)</td>
</tr>
<tr>
<td><span class="math inline">I</span></td>
<td>Mutual information</td>
</tr>
<tr>
<td><span class="math inline">J_t</span></td>
<td>Jump process at time <span class="math inline">t</span></td>
</tr>
<tr>
<td><span class="math inline">L_t^\alpha</span></td>
<td><span class="math inline">\alpha</span>-stable Lévy process</td>
</tr>
<tr>
<td><span class="math inline">N</span></td>
<td>Number of observations or sample size</td>
</tr>
<tr>
<td><span class="math inline">P</span></td>
<td>Probability or power spectrum</td>
</tr>
<tr>
<td><span class="math inline">Q_n</span></td>
<td>Robust scale estimator</td>
</tr>
<tr>
<td><span class="math inline">S_t</span></td>
<td>Regime state at time <span class="math inline">t</span></td>
</tr>
<tr>
<td><span class="math inline">TE</span></td>
<td>Transfer entropy</td>
</tr>
<tr>
<td><span class="math inline">U</span></td>
<td>Uniform random variable</td>
</tr>
<tr>
<td><span class="math inline">W</span></td>
<td>Wiener process (standard Brownian motion)</td>
</tr>
<tr>
<td><span class="math inline">W_t</span></td>
<td>Brownian motion at time <span class="math inline">t</span></td>
</tr>
<tr>
<td><span class="math inline">X_t</span></td>
<td>Stochastic process value at time <span
class="math inline">t</span></td>
</tr>
<tr>
<td><span class="math inline">\tilde{N}</span></td>
<td>Compensated Poisson random measure</td>
</tr>
</tbody>
</table>
<h2 data-number="13.2" id="greek-symbols"><span
class="header-section-number">13.2</span> Greek Symbols</h2>
<table>
<colgroup>
<col style="width: 40%" />
<col style="width: 60%" />
</colgroup>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">\alpha</span></td>
<td>Stability parameter (Lévy processes) or significance level</td>
</tr>
<tr>
<td><span class="math inline">\beta</span></td>
<td>Skewness parameter (stable distributions)</td>
</tr>
<tr>
<td><span class="math inline">\gamma</span></td>
<td>Scale parameter (stable distributions, Gamma distribution)</td>
</tr>
<tr>
<td><span class="math inline">\delta</span></td>
<td>Location parameter or degrees of freedom</td>
</tr>
<tr>
<td><span class="math inline">\epsilon</span></td>
<td>Error term or small quantity</td>
</tr>
<tr>
<td><span class="math inline">\theta</span></td>
<td>Equilibrium level or parameter vector</td>
</tr>
<tr>
<td><span class="math inline">\kappa</span></td>
<td>Mean reversion speed</td>
</tr>
<tr>
<td><span class="math inline">\lambda</span></td>
<td>Jump intensity or non-centrality parameter</td>
</tr>
<tr>
<td><span class="math inline">\lambda_L</span></td>
<td>Lower tail dependence coefficient</td>
</tr>
<tr>
<td><span class="math inline">\lambda_U</span></td>
<td>Upper tail dependence coefficient</td>
</tr>
<tr>
<td><span class="math inline">\mu</span></td>
<td>Drift parameter or mean</td>
</tr>
<tr>
<td><span class="math inline">\mu_J</span></td>
<td>Mean jump size</td>
</tr>
<tr>
<td><span class="math inline">\rho</span></td>
<td>Correlation coefficient or autocorrelation</td>
</tr>
<tr>
<td><span class="math inline">\sigma</span></td>
<td>Diffusion coefficient or standard deviation</td>
</tr>
<tr>
<td><span class="math inline">\sigma_J</span></td>
<td>Jump size standard deviation</td>
</tr>
<tr>
<td><span class="math inline">\tau</span></td>
<td>Kendall’s tau (rank correlation)</td>
</tr>
<tr>
<td><span class="math inline">\xi</span></td>
<td>Shape parameter (extreme value theory)</td>
</tr>
<tr>
<td><span class="math inline">\Phi</span></td>
<td>Standard normal CDF</td>
</tr>
<tr>
<td><span class="math inline">\Phi_\rho</span></td>
<td>Bivariate normal CDF with correlation <span
class="math inline">\rho</span></td>
</tr>
<tr>
<td><span class="math inline">\psi</span></td>
<td>Mother wavelet function</td>
</tr>
</tbody>
</table>
<h2 data-number="13.3" id="operators-and-functions"><span
class="header-section-number">13.3</span> Operators and Functions</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">\mathbb{E}[\cdot]</span></td>
<td>Expected value (expectation)</td>
</tr>
<tr>
<td><span class="math inline">\mathbb{P}[\cdot]</span></td>
<td>Probability</td>
</tr>
<tr>
<td><span class="math inline">\text{Var}[\cdot]</span></td>
<td>Variance</td>
</tr>
<tr>
<td><span class="math inline">\text{Corr}(\cdot,\cdot)</span></td>
<td>Correlation</td>
</tr>
<tr>
<td><span class="math inline">\text{Cov}(\cdot,\cdot)</span></td>
<td>Covariance</td>
</tr>
<tr>
<td><span class="math inline">\int</span></td>
<td>Integral</td>
</tr>
<tr>
<td><span class="math inline">\sum</span></td>
<td>Summation</td>
</tr>
<tr>
<td><span class="math inline">\prod</span></td>
<td>Product</td>
</tr>
<tr>
<td><span class="math inline">\log</span></td>
<td>Natural logarithm</td>
</tr>
<tr>
<td><span class="math inline">\exp</span></td>
<td>Exponential function</td>
</tr>
<tr>
<td><span class="math inline">\sim</span></td>
<td>Distributed as</td>
</tr>
<tr>
<td><span class="math inline">\to</span></td>
<td>Converges to</td>
</tr>
<tr>
<td><span class="math inline">\propto</span></td>
<td>Proportional to</td>
</tr>
<tr>
<td><span class="math inline">\nabla</span></td>
<td>Gradient operator</td>
</tr>
<tr>
<td><span class="math inline">\partial</span></td>
<td>Partial derivative</td>
</tr>
<tr>
<td><span class="math inline">d</span></td>
<td>Differential or total derivative</td>
</tr>
</tbody>
</table>
<h2 data-number="13.4" id="probability-distributions"><span
class="header-section-number">13.4</span> Probability Distributions</h2>
<table>
<colgroup>
<col style="width: 40%" />
<col style="width: 60%" />
</colgroup>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">N(\mu, \sigma^2)</span></td>
<td>Normal distribution with mean <span class="math inline">\mu</span>
and variance <span class="math inline">\sigma^2</span></td>
</tr>
<tr>
<td><span class="math inline">\text{Gamma}(k, \theta)</span></td>
<td>Gamma distribution with shape <span class="math inline">k</span> and
scale <span class="math inline">\theta</span></td>
</tr>
<tr>
<td><span class="math inline">\chi^2(\nu)</span></td>
<td>Chi-square distribution with <span class="math inline">\nu</span>
degrees of freedom</td>
</tr>
<tr>
<td><span class="math inline">\chi&#39;^2(\delta, \lambda)</span></td>
<td>Non-central chi-square distribution</td>
</tr>
<tr>
<td><span class="math inline">\text{Poisson}(\lambda)</span></td>
<td>Poisson distribution with rate <span
class="math inline">\lambda</span></td>
</tr>
<tr>
<td><span class="math inline">\text{Exp}(\lambda)</span></td>
<td>Exponential distribution with rate <span
class="math inline">\lambda</span></td>
</tr>
<tr>
<td><span class="math inline">\text{Uniform}(a, b)</span></td>
<td>Uniform distribution on interval <span class="math inline">[a,
b]</span></td>
</tr>
<tr>
<td><span class="math inline">S_\alpha(\beta, \gamma,
\delta)</span></td>
<td>Stable distribution</td>
</tr>
</tbody>
</table>
<h2 data-number="13.5" id="statistical-notation"><span
class="header-section-number">13.5</span> Statistical Notation</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">\hat{\theta}</span></td>
<td>Estimator of parameter <span class="math inline">\theta</span></td>
</tr>
<tr>
<td><span class="math inline">\bar{x}</span></td>
<td>Sample mean</td>
</tr>
<tr>
<td><span class="math inline">s^2</span></td>
<td>Sample variance</td>
</tr>
<tr>
<td><span class="math inline">\text{MAD}</span></td>
<td>Median absolute deviation</td>
</tr>
<tr>
<td><span class="math inline">\text{IQR}</span></td>
<td>Interquartile range</td>
</tr>
<tr>
<td><span class="math inline">p_{ij}</span></td>
<td>Transition probability from state <span class="math inline">i</span>
to state <span class="math inline">j</span></td>
</tr>
<tr>
<td><span class="math inline">\ell(\theta)</span></td>
<td>Log-likelihood function</td>
</tr>
<tr>
<td><span class="math inline">\text{AIC}</span></td>
<td>Akaike Information Criterion</td>
</tr>
<tr>
<td><span class="math inline">\text{BIC}</span></td>
<td>Bayesian Information Criterion</td>
</tr>
<tr>
<td><span class="math inline">H_0</span></td>
<td>Null hypothesis</td>
</tr>
<tr>
<td><span class="math inline">H_1</span></td>
<td>Alternative hypothesis</td>
</tr>
<tr>
<td><span class="math inline">\alpha</span></td>
<td>Type I error rate (significance level)</td>
</tr>
<tr>
<td><span class="math inline">\beta</span></td>
<td>Type II error rate</td>
</tr>
</tbody>
</table>
<h2 data-number="13.6" id="time-series-notation"><span
class="header-section-number">13.6</span> Time Series Notation</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">t</span></td>
<td>Time</td>
</tr>
<tr>
<td><span class="math inline">\Delta t</span></td>
<td>Time increment</td>
</tr>
<tr>
<td><span class="math inline">dt</span></td>
<td>Infinitesimal time increment</td>
</tr>
<tr>
<td><span class="math inline">T</span></td>
<td>Total time period</td>
</tr>
<tr>
<td><span class="math inline">x_t</span></td>
<td>Observation at time <span class="math inline">t</span></td>
</tr>
<tr>
<td><span class="math inline">\Delta x</span></td>
<td>Change in <span class="math inline">x</span></td>
</tr>
<tr>
<td><span class="math inline">\rho(k)</span></td>
<td>Autocorrelation at lag <span class="math inline">k</span></td>
</tr>
<tr>
<td><span class="math inline">\text{ACF}</span></td>
<td>Autocorrelation function</td>
</tr>
<tr>
<td><span class="math inline">\text{PACF}</span></td>
<td>Partial autocorrelation function</td>
</tr>
</tbody>
</table>
<h2 data-number="13.7" id="wavelet-analysis-notation"><span
class="header-section-number">13.7</span> Wavelet Analysis Notation</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">W(a, b)</span></td>
<td>Wavelet transform at scale <span class="math inline">a</span> and
position <span class="math inline">b</span></td>
</tr>
<tr>
<td><span class="math inline">a</span></td>
<td>Scale parameter (wavelet)</td>
</tr>
<tr>
<td><span class="math inline">b</span></td>
<td>Translation parameter (wavelet)</td>
</tr>
<tr>
<td><span class="math inline">\psi</span></td>
<td>Mother wavelet</td>
</tr>
<tr>
<td><span class="math inline">P(a, b)</span></td>
<td>Wavelet power spectrum</td>
</tr>
<tr>
<td><span class="math inline">\bar{P}(a)</span></td>
<td>Scale-averaged power</td>
</tr>
</tbody>
</table>
<h2 data-number="13.8" id="extreme-value-theory-notation"><span
class="header-section-number">13.8</span> Extreme Value Theory
Notation</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">u</span></td>
<td>Threshold for peaks-over-threshold</td>
</tr>
<tr>
<td><span class="math inline">\xi</span></td>
<td>Shape parameter (GPD/GEV)</td>
</tr>
<tr>
<td><span class="math inline">\sigma</span></td>
<td>Scale parameter (GPD/GEV)</td>
</tr>
<tr>
<td><span class="math inline">\mu</span></td>
<td>Location parameter (GEV)</td>
</tr>
<tr>
<td><span class="math inline">x_m</span></td>
<td><span class="math inline">m</span>-observation return level</td>
</tr>
<tr>
<td><span class="math inline">n_u</span></td>
<td>Number of threshold exceedances</td>
</tr>
</tbody>
</table>
<h2 data-number="13.9" id="network-analysis-notation"><span
class="header-section-number">13.9</span> Network Analysis Notation</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">G</span></td>
<td>Graph or network</td>
</tr>
<tr>
<td><span class="math inline">V</span></td>
<td>Set of vertices (nodes)</td>
</tr>
<tr>
<td><span class="math inline">E</span></td>
<td>Set of edges (links)</td>
</tr>
<tr>
<td><span class="math inline">A</span></td>
<td>Adjacency matrix</td>
</tr>
<tr>
<td><span class="math inline">d_i</span></td>
<td>Degree of node <span class="math inline">i</span></td>
</tr>
<tr>
<td><span class="math inline">C</span></td>
<td>Clustering coefficient</td>
</tr>
<tr>
<td><span class="math inline">L</span></td>
<td>Characteristic path length</td>
</tr>
</tbody>
</table>
<h2 data-number="13.10" id="matrix-notation"><span
class="header-section-number">13.10</span> Matrix Notation</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">\mathbf{x}</span></td>
<td>Vector (bold lowercase)</td>
</tr>
<tr>
<td><span class="math inline">\mathbf{X}</span></td>
<td>Matrix (bold uppercase)</td>
</tr>
<tr>
<td><span class="math inline">\mathbf{I}</span></td>
<td>Identity matrix</td>
</tr>
<tr>
<td><span class="math inline">\mathbf{\Sigma}</span></td>
<td>Covariance matrix</td>
</tr>
<tr>
<td><span class="math inline">\mathbf{\Gamma}</span></td>
<td>Covariance matrix (fBM)</td>
</tr>
<tr>
<td><span class="math inline">\text{det}(\cdot)</span></td>
<td>Matrix determinant</td>
</tr>
<tr>
<td><span class="math inline">\text{tr}(\cdot)</span></td>
<td>Matrix trace</td>
</tr>
<tr>
<td><span class="math inline">\mathbf{A}^T</span></td>
<td>Matrix transpose</td>
</tr>
<tr>
<td><span class="math inline">\mathbf{A}^{-1}</span></td>
<td>Matrix inverse</td>
</tr>
</tbody>
</table>
<h2 data-number="13.11" id="indexing-and-sets"><span
class="header-section-number">13.11</span> Indexing and Sets</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">i, j, k</span></td>
<td>Indices</td>
</tr>
<tr>
<td><span class="math inline">n</span></td>
<td>Sample size or number of observations</td>
</tr>
<tr>
<td><span class="math inline">m</span></td>
<td>Number of features or dimensions</td>
</tr>
<tr>
<td><span class="math inline">K</span></td>
<td>Number of clusters or regimes</td>
</tr>
<tr>
<td><span class="math inline">\mathbb{R}</span></td>
<td>Set of real numbers</td>
</tr>
<tr>
<td><span class="math inline">\mathbb{R}_+</span></td>
<td>Set of positive real numbers</td>
</tr>
<tr>
<td><span class="math inline">\mathbb{N}</span></td>
<td>Set of natural numbers</td>
</tr>
<tr>
<td><span class="math inline">\mathbb{Z}</span></td>
<td>Set of integers</td>
</tr>
<tr>
<td><span class="math inline">\Omega</span></td>
<td>Sample space</td>
</tr>
<tr>
<td><span class="math inline">\mathcal{F}</span></td>
<td>Sigma-algebra (filtration)</td>
</tr>
</tbody>
</table>
<h2 data-number="13.12" id="special-functions"><span
class="header-section-number">13.12</span> Special Functions</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">\Gamma(\cdot)</span></td>
<td>Gamma function</td>
</tr>
<tr>
<td><span class="math inline">\text{erf}(\cdot)</span></td>
<td>Error function</td>
</tr>
<tr>
<td><span class="math inline">B(\cdot, \cdot)</span></td>
<td>Beta function</td>
</tr>
<tr>
<td><span class="math inline">\Phi(\cdot)</span></td>
<td>Standard normal CDF</td>
</tr>
<tr>
<td><span class="math inline">\phi(\cdot)</span></td>
<td>Standard normal PDF</td>
</tr>
</tbody>
</table>
<h2 data-number="13.13" id="asymptotic-notation"><span
class="header-section-number">13.13</span> Asymptotic Notation</h2>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">O(\cdot)</span></td>
<td>Big O notation (order of magnitude)</td>
</tr>
<tr>
<td><span class="math inline">o(\cdot)</span></td>
<td>Little o notation</td>
</tr>
<tr>
<td><span class="math inline">\sim</span></td>
<td>Asymptotically equivalent</td>
</tr>
<tr>
<td><span class="math inline">\xrightarrow{p}</span></td>
<td>Convergence in probability</td>
</tr>
<tr>
<td><span class="math inline">\xrightarrow{d}</span></td>
<td>Convergence in distribution</td>
</tr>
<tr>
<td><span class="math inline">\xrightarrow{a.s.}</span></td>
<td>Almost sure convergence</td>
</tr>
</tbody>
</table>
<h2 data-number="13.14" id="abbreviations"><span
class="header-section-number">13.14</span> Abbreviations</h2>
<table>
<thead>
<tr>
<th>Abbreviation</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td>SDE</td>
<td>Stochastic Differential Equation</td>
</tr>
<tr>
<td>OU</td>
<td>Ornstein-Uhlenbeck</td>
</tr>
<tr>
<td>fBM</td>
<td>Fractional Brownian Motion</td>
</tr>
<tr>
<td>CIR</td>
<td>Cox-Ingersoll-Ross</td>
</tr>
<tr>
<td>GPD</td>
<td>Generalized Pareto Distribution</td>
</tr>
<tr>
<td>GEV</td>
<td>Generalized Extreme Value Distribution</td>
</tr>
<tr>
<td>CWT</td>
<td>Continuous Wavelet Transform</td>
</tr>
<tr>
<td>PDF</td>
<td>Probability Density Function</td>
</tr>
<tr>
<td>CDF</td>
<td>Cumulative Distribution Function</td>
</tr>
<tr>
<td>MLE</td>
<td>Maximum Likelihood Estimation</td>
</tr>
<tr>
<td>MCMC</td>
<td>Markov Chain Monte Carlo</td>
</tr>
<tr>
<td>KDE</td>
<td>Kernel Density Estimation</td>
</tr>
<tr>
<td>PCA</td>
<td>Principal Component Analysis</td>
</tr>
<tr>
<td>IQR</td>
<td>Interquartile Range</td>
</tr>
<tr>
<td>MAD</td>
<td>Median Absolute Deviation</td>
</tr>
</tbody>
</table>
<h2 data-number="13.15" id="model-specific-parameters"><span
class="header-section-number">13.15</span> Model-Specific
Parameters</h2>
<h3 data-number="13.15.1" id="ornstein-uhlenbeck-with-jumps"><span
class="header-section-number">13.15.1</span> Ornstein-Uhlenbeck with
Jumps</h3>
<ul>
<li><span class="math inline">\kappa</span>: Mean reversion speed</li>
<li><span class="math inline">\theta</span>: Equilibrium level</li>
<li><span class="math inline">\sigma</span>: Diffusion coefficient</li>
<li><span class="math inline">\lambda</span>: Jump intensity</li>
<li><span class="math inline">\mu_J</span>: Mean jump size</li>
<li><span class="math inline">\sigma_J</span>: Jump size standard
deviation</li>
</ul>
<h3 data-number="13.15.2" id="fractional-brownian-motion-3"><span
class="header-section-number">13.15.2</span> Fractional Brownian
Motion</h3>
<ul>
<li><span class="math inline">H</span>: Hurst parameter (<span
class="math inline">0 &lt; H &lt; 1</span>)
<ul>
<li><span class="math inline">H = 0.5</span>: Standard Brownian
motion</li>
<li><span class="math inline">H &gt; 0.5</span>: Persistent (long-range
positive correlations)</li>
<li><span class="math inline">H &lt; 0.5</span>: Anti-persistent
(long-range negative correlations)</li>
</ul></li>
<li><span class="math inline">\sigma</span>: Diffusion coefficient</li>
</ul>
<h3 data-number="13.15.3" id="cox-ingersoll-ross-process-3"><span
class="header-section-number">13.15.3</span> Cox-Ingersoll-Ross
Process</h3>
<ul>
<li><span class="math inline">\kappa</span>: Mean reversion speed</li>
<li><span class="math inline">\theta</span>: Long-term mean</li>
<li><span class="math inline">\sigma</span>: Volatility coefficient</li>
<li>Feller condition: <span class="math inline">2\kappa\theta \geq
\sigma^2</span> (ensures non-negativity)</li>
</ul>
<h3 data-number="13.15.4" id="lévy-processes-2"><span
class="header-section-number">13.15.4</span> Lévy Processes</h3>
<ul>
<li><span class="math inline">\alpha</span>: Stability parameter (<span
class="math inline">0 &lt; \alpha \leq 2</span>)</li>
<li><span class="math inline">\beta</span>: Skewness parameter (<span
class="math inline">-1 \leq \beta \leq 1</span>)</li>
<li><span class="math inline">\gamma</span>: Scale parameter (<span
class="math inline">\gamma &gt; 0</span>)</li>
<li><span class="math inline">\delta</span>: Location parameter</li>
</ul>
<h3 data-number="13.15.5" id="copula-models"><span
class="header-section-number">13.15.5</span> Copula Models</h3>
<ul>
<li><span class="math inline">\rho</span>: Correlation parameter
(Gaussian copula)</li>
<li><span class="math inline">\theta</span>: Association parameter
(Clayton, Frank copulas)</li>
<li><span class="math inline">\tau</span>: Kendall’s tau</li>
<li><span class="math inline">\lambda_L</span>: Lower tail
dependence</li>
<li><span class="math inline">\lambda_U</span>: Upper tail
dependence</li>
</ul>
<h2 data-number="13.16" id="notes-on-notation"><span
class="header-section-number">13.16</span> Notes on Notation</h2>
<ul>
<li>Time indices are typically denoted by subscripts: <span
class="math inline">X_t, X_i, X_{t_i}</span></li>
<li>Estimated parameters are denoted with hats: <span
class="math inline">\hat{\theta}, \hat{\mu}, \hat{\sigma}</span></li>
<li>Sample statistics are typically lowercase: <span
class="math inline">\bar{x}</span> (sample mean), <span
class="math inline">s^2</span> (sample variance)</li>
<li>Population parameters are typically Greek: <span
class="math inline">\mu</span> (population mean), <span
class="math inline">\sigma^2</span> (population variance)</li>
<li>Vectors are bold lowercase: <span class="math inline">\mathbf{x},
\mathbf{y}</span></li>
<li>Matrices are bold uppercase: <span class="math inline">\mathbf{X},
\mathbf{\Sigma}</span></li>
<li>Random variables are typically uppercase: <span
class="math inline">X, Y, Z</span></li>
<li>Realizations are typically lowercase: <span class="math inline">x,
y, z</span></li>
</ul>
<!-- Section: 12_code -->
<h1 data-number="14" id="complete-code-listings"><span
class="header-section-number">14</span> Complete Code Listings</h1>
<p>This section contains all code examples and implementation details
referenced throughout the paper. The code is organized by section and
subsection for easy reference.</p>
<h2 data-number="14.1" id="implementation-code"><span
class="header-section-number">14.1</span> Implementation Code</h2>
<h3 data-number="14.1.1" id="software-architecture-1"><span
class="header-section-number">14.1.1</span> Software Architecture</h3>
<p><strong>Class Hierarchy</strong>:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>StochasticProcess (ABC)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">|--</span> OrnsteinUhlenbeckJump</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">|--</span> GeometricJumpDiffusion</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">|--</span> CompoundPoisson</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">|--</span> FractionalBrownianMotion</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="op">|--</span> CoxIngersollRoss</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="op">+--</span> LevyProcess</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>Analyzer (ABC)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="op">|--</span> TimeSeriesAnalyzer</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="op">|--</span> MultivariateAnalyzer</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="op">|--</span> BayesianAnalyzer</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="op">|--</span> NetworkAnalyzer</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="op">+--</span> CausalInference</span></code></pre></div>
<h3 data-number="14.1.2" id="algorithmic-implementation-1"><span
class="header-section-number">14.1.2</span> Algorithmic
Implementation</h3>
<h4 data-number="14.1.2.1" id="stochastic-process-simulation-1"><span
class="header-section-number">14.1.2.1</span> Stochastic Process
Simulation</h4>
<p><strong>Euler-Maruyama Scheme</strong> for SDEs:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> euler_maruyama(x0, t, drift, diffusion, dt):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    n_steps <span class="op">=</span> <span class="bu">len</span>(t) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.zeros(<span class="bu">len</span>(t))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    x[<span class="dv">0</span>] <span class="op">=</span> x0</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_steps):</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        dW <span class="op">=</span> np.random.normal(<span class="dv">0</span>, np.sqrt(dt))</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        x[i<span class="op">+</span><span class="dv">1</span>] <span class="op">=</span> x[i] <span class="op">+</span> drift(x[i], t[i])<span class="op">*</span>dt <span class="op">+</span> diffusion(x[i], t[i])<span class="op">*</span>dW</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span></code></pre></div>
<p><strong>Jump Component</strong>: Compound Poisson process</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulate_jumps(t, jump_intensity, jump_dist):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    dt <span class="op">=</span> np.diff(t)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    jumps <span class="op">=</span> np.zeros(<span class="bu">len</span>(t))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, dti <span class="kw">in</span> <span class="bu">enumerate</span>(dt):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        n_jumps <span class="op">=</span> np.random.poisson(jump_intensity <span class="op">*</span> dti)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> n_jumps <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>            jumps[i<span class="op">+</span><span class="dv">1</span>] <span class="op">=</span> np.<span class="bu">sum</span>(jump_dist.rvs(n_jumps))</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> jumps</span></code></pre></div>
<h4 data-number="14.1.2.2" id="parameter-estimation-3"><span
class="header-section-number">14.1.2.2</span> Parameter Estimation</h4>
<p><strong>Maximum Likelihood via Numerical Optimization</strong>:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> estimate_parameters(data, dt, model_class):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> negative_log_likelihood(params):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> model_class(params)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span>model.log_likelihood(data, dt)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> minimize(</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        negative_log_likelihood,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        x0<span class="op">=</span>initial_guess,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        method<span class="op">=</span><span class="st">&#39;L-BFGS-B&#39;</span>,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        bounds<span class="op">=</span>param_bounds</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result.x</span></code></pre></div>
<p><strong>Moment Matching</strong>:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> moment_matching(data, dt):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Empirical moments</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    mean_x <span class="op">=</span> np.mean(data)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    var_x <span class="op">=</span> np.var(data)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    autocorr <span class="op">=</span> np.corrcoef(data[:<span class="op">-</span><span class="dv">1</span>], data[<span class="dv">1</span>:])[<span class="dv">0</span>,<span class="dv">1</span>]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Match to theoretical moments</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    theta <span class="op">=</span> mean_x</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    kappa <span class="op">=</span> <span class="op">-</span>np.log(autocorr) <span class="op">/</span> dt</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> np.sqrt(<span class="dv">2</span> <span class="op">*</span> kappa <span class="op">*</span> var_x)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ModelParameters(</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        equilibrium<span class="op">=</span>theta,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        reversion_speed<span class="op">=</span>kappa,</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        diffusion<span class="op">=</span>sigma</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div>
<h4 data-number="14.1.2.3" id="wavelet-transform-implementation-1"><span
class="header-section-number">14.1.2.3</span> Wavelet Transform
Implementation</h4>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> continuous_wavelet_transform(signal, scales, wavelet<span class="op">=</span><span class="st">&#39;morl&#39;</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute CWT using PyWavelets.</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pywt</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    coefficients, frequencies <span class="op">=</span> pywt.cwt(</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        signal,</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        scales,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        wavelet</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    power <span class="op">=</span> np.<span class="bu">abs</span>(coefficients) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;coefficients&#39;</span>: coefficients,</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;frequencies&#39;</span>: frequencies,</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;power&#39;</span>: power,</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;dominant_scale&#39;</span>: scales[np.argmax(np.mean(power, axis<span class="op">=</span><span class="dv">1</span>))]</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    }</span></code></pre></div>
<h4 data-number="14.1.2.4" id="copula-fitting-1"><span
class="header-section-number">14.1.2.4</span> Copula Fitting</h4>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit_copula(data1, data2, copula_type<span class="op">=</span><span class="st">&#39;gaussian&#39;</span>):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Fit copula to bivariate data.</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform to uniform margins</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    u1 <span class="op">=</span> rankdata(data1) <span class="op">/</span> (<span class="bu">len</span>(data1) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    u2 <span class="op">=</span> rankdata(data2) <span class="op">/</span> (<span class="bu">len</span>(data2) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> copula_type <span class="op">==</span> <span class="st">&#39;gaussian&#39;</span>:</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gaussian copula parameter</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        z1 <span class="op">=</span> norm.ppf(u1)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        z2 <span class="op">=</span> norm.ppf(u2)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        rho <span class="op">=</span> np.corrcoef(z1, z2)[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">&#39;rho&#39;</span>: rho}</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> copula_type <span class="op">==</span> <span class="st">&#39;clayton&#39;</span>:</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Clayton copula via Kendall&#39;s tau</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        tau <span class="op">=</span> stats.kendalltau(data1, data2)[<span class="dv">0</span>]</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        theta <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> tau <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> tau)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">&#39;theta&#39;</span>: theta}</span></code></pre></div>
<h3 data-number="14.1.3" id="performance-optimization-1"><span
class="header-section-number">14.1.3</span> Performance
Optimization</h3>
<h4 data-number="14.1.3.1" id="vectorization-1"><span
class="header-section-number">14.1.3.1</span> Vectorization</h4>
<p>Critical loops are vectorized using NumPy:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scalar version (slow)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    result[i] <span class="op">=</span> func(x[i])</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectorized version (fast)</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> func(x)</span></code></pre></div>
<h4 data-number="14.1.3.2"
id="performance-optimization-strategies"><span
class="header-section-number">14.1.3.2</span> Performance Optimization
Strategies</h4>
<p>The framework leverages NumPy’s optimized operations:</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectorized operations for efficiency</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> vectorized_trajectory_update(x, drift_fn, diffusion_fn, dt, dW):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Vectorized trajectory update.&quot;&quot;&quot;</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    drift <span class="op">=</span> drift_fn(x)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    diffusion <span class="op">=</span> diffusion_fn(x) <span class="op">*</span> dW</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x <span class="op">+</span> drift <span class="op">*</span> dt <span class="op">+</span> diffusion</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Multiple trajectories updated simultaneously</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>trajectories[:, i<span class="op">+</span><span class="dv">1</span>] <span class="op">=</span> vectorized_trajectory_update(</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    trajectories[:, i], </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    drift_fn, </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    diffusion_fn, </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    dt, </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    dW[:, i]</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>The architecture supports optional JIT compilation (via Numba) and
parallel processing (via multiprocessing) for performance-critical
applications when needed.</p>
<h4 data-number="14.1.3.3" id="memory-efficiency-1"><span
class="header-section-number">14.1.3.3</span> Memory Efficiency</h4>
<p>Large datasets use chunked processing:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_large_dataset(data, chunk_size<span class="op">=</span><span class="dv">10000</span>):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(data), chunk_size):</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        chunk <span class="op">=</span> data[i:i<span class="op">+</span>chunk_size]</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        results.append(process_chunk(chunk))</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> concatenate_results(results)</span></code></pre></div>
<h3 data-number="14.1.4" id="testing-framework-1"><span
class="header-section-number">14.1.4</span> Testing Framework</h3>
<h4 data-number="14.1.4.1" id="unit-tests-1"><span
class="header-section-number">14.1.4.1</span> Unit Tests</h4>
<p>Each component has comprehensive unit tests:</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TestFractionalBrownianMotion:</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> test_hurst_parameter(<span class="va">self</span>):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Test Hurst parameter estimation.&quot;&quot;&quot;</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        fbm <span class="op">=</span> FractionalBrownianMotion(params, hurst<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        paths <span class="op">=</span> fbm.simulate(<span class="fl">10.0</span>, t, n_paths<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> paths.shape <span class="op">==</span> (<span class="dv">50</span>, <span class="dv">100</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> np.<span class="bu">all</span>(np.isfinite(paths))</span></code></pre></div>
<h4 data-number="14.1.4.2" id="integration-tests-1"><span
class="header-section-number">14.1.4.2</span> Integration Tests</h4>
<p>Test component interactions:</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_full_pipeline():</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Test complete analysis pipeline.&quot;&quot;&quot;</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load data</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    data_core <span class="op">=</span> DataCore.load_from_csv(data_file)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit model</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> JumpRope.fit(data_core, model_type<span class="op">=</span><span class="st">&#39;fractional-brownian&#39;</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Analyze</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    analyzer <span class="op">=</span> LaserPlaneAnalyzer(model)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> analyzer.analyze_cross_section(<span class="fl">3.0</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    visualizer <span class="op">=</span> TrajectoryVisualizer()</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> visualizer.plot_trajectories(model)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> results <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> fig <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span></code></pre></div>
<h4 data-number="14.1.4.3" id="validation-tests-1"><span
class="header-section-number">14.1.4.3</span> Validation Tests</h4>
<p>Compare against known solutions:</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_ornstein_uhlenbeck_stationary():</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Validate against analytical stationary distribution.&quot;&quot;&quot;</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    ou <span class="op">=</span> OrnsteinUhlenbeckJump(params)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate long trajectory</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1000</span>, <span class="dv">100000</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> ou.simulate(x0<span class="op">=</span><span class="dv">0</span>, t<span class="op">=</span>t, n_paths<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check stationary moments</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    theoretical_mean <span class="op">=</span> params.theta</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    theoretical_var <span class="op">=</span> params.sigma<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> (<span class="dv">2</span><span class="op">*</span>params.kappa)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.<span class="bu">abs</span>(np.mean(x[<span class="op">-</span><span class="dv">10000</span>:]) <span class="op">-</span> theoretical_mean) <span class="op">&lt;</span> <span class="fl">0.1</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.<span class="bu">abs</span>(np.var(x[<span class="op">-</span><span class="dv">10000</span>:]) <span class="op">-</span> theoretical_var) <span class="op">&lt;</span> <span class="fl">0.2</span></span></code></pre></div>
<h3 data-number="14.1.5" id="documentation-system-1"><span
class="header-section-number">14.1.5</span> Documentation System</h3>
<h4 data-number="14.1.5.1" id="docstring-format-1"><span
class="header-section-number">14.1.5.1</span> Docstring Format</h4>
<p>Google-style docstrings throughout:</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit(<span class="va">self</span>, data_core, model_type<span class="op">=</span><span class="st">&#39;jump-diffusion&#39;</span>, <span class="op">**</span>kwargs):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Fit stochastic process model to data.</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">        data_core: DataCore instance with training data</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">        model_type: Type of stochastic process</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">        **kwargs: Additional model parameters</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">        Fitted JumpRope instance</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Examples:</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co">        &gt;&gt;&gt; model = JumpRope.fit(data, model_type=&#39;fractional-brownian&#39;)</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co">        &gt;&gt;&gt; trajectories = model.generate_trajectories(100)</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span></code></pre></div>
<h4 data-number="14.1.5.2" id="sphinx-documentation-1"><span
class="header-section-number">14.1.5.2</span> Sphinx Documentation</h4>
<p>Complete API documentation generated via Sphinx:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode rst"><code class="sourceCode rest"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="dt">.. automodule:: </span>evojump.jumprope</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">:members:</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">:undoc-members:</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">:show-inheritance:</span></span></code></pre></div>
<h4 data-number="14.1.5.3" id="tutorials-and-examples-1"><span
class="header-section-number">14.1.5.3</span> Tutorials and
Examples</h4>
<p>Comprehensive examples for all features:</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co">Example: Advanced Stochastic Process Modeling</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">This example demonstrates the use of fractional Brownian</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co">motion for modeling developmental trajectories with</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">long-range dependence.</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evojump <span class="im">as</span> ej</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> ej.DataCore.load_from_csv(<span class="st">&#39;developmental_data.csv&#39;</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit fBM model</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ej.JumpRope.fit(data, model_type<span class="op">=</span><span class="st">&#39;fractional-brownian&#39;</span>, hurst<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate predictions</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>trajectories <span class="op">=</span> model.generate_trajectories(n_samples<span class="op">=</span><span class="dv">100</span>, x0<span class="op">=</span><span class="fl">10.0</span>)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>visualizer <span class="op">=</span> ej.TrajectoryVisualizer()</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>visualizer.plot_heatmap(model, output_dir<span class="op">=</span><span class="st">&#39;outputs/figures/&#39;</span>)</span></code></pre></div>
<h3 data-number="14.1.6" id="visualization-framework-1"><span
class="header-section-number">14.1.6</span> Visualization Framework</h3>
<h4 data-number="14.1.6.1" id="implementation-details-1"><span
class="header-section-number">14.1.6.1</span> Implementation
Details</h4>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Trajectory density heatmap</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>visualizer.plot_heatmap(model, time_resolution<span class="op">=</span><span class="dv">50</span>, phenotype_resolution<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Violin plots at specific timepoints</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>visualizer.plot_violin(model, time_points<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>])</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Ridge plot for distribution evolution</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>visualizer.plot_ridge(model, n_distributions<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Phase portrait analysis</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>visualizer.plot_phase_portrait(model, derivative_method<span class="op">=</span><span class="st">&#39;finite_difference&#39;</span>)</span></code></pre></div>
<p>Each visualization method supports both static (matplotlib) and
interactive (Plotly) output modes, enabling publication-quality graphics
and exploratory analysis.</p>
<h3 data-number="14.1.7" id="package-management-with-uv-1"><span
class="header-section-number">14.1.7</span> Package Management with
UV</h3>
<h4 data-number="14.1.7.1" id="project-configuration-1"><span
class="header-section-number">14.1.7.1</span> Project Configuration</h4>
<div class="sourceCode" id="cb18"><pre
class="sourceCode toml"><code class="sourceCode toml"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">[project]</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="dt">name</span> <span class="op">=</span> <span class="st">&quot;evojump&quot;</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="dt">version</span> <span class="op">=</span> <span class="st">&quot;0.1.0&quot;</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="dt">requires-python</span> <span class="op">=</span> <span class="st">&quot;&gt;=3.8&quot;</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="dt">dependencies</span> <span class="op">=</span> <span class="op">[</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;numpy&gt;=1.21.0&quot;</span><span class="op">,</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;scipy&gt;=1.7.0&quot;</span><span class="op">,</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;pandas&gt;=1.3.0&quot;</span><span class="op">,</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;matplotlib&gt;=3.5.0&quot;</span><span class="op">,</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;plotly&gt;=5.0.0&quot;</span><span class="op">,</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;scikit-learn&gt;=1.0.0&quot;</span><span class="op">,</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;PyWavelets&gt;=1.3.0&quot;</span><span class="op">,</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;networkx&gt;=2.6.0&quot;</span><span class="op">,</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;statsmodels&gt;=0.13.0&quot;</span><span class="op">,</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;seaborn&gt;=0.11.0&quot;</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="op">]</span></span></code></pre></div>
<h4 data-number="14.1.7.2" id="development-workflow-1"><span
class="header-section-number">14.1.7.2</span> Development Workflow</h4>
<div class="sourceCode" id="cb19"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create virtual environment with UV</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> venv</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Sync all dependencies from pyproject.toml</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> sync</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Install in development mode</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> add <span class="at">-e</span> .</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Run tests</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> run pytest</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Build documentation</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> run sphinx-build docs docs/_build</span></code></pre></div>
<h4 data-number="14.1.7.3" id="reproducible-environments-1"><span
class="header-section-number">14.1.7.3</span> Reproducible
Environments</h4>
<div class="sourceCode" id="cb20"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># UV automatically generates uv.lock file</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> sync</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Install from lock file in new environment</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> sync <span class="at">--frozen</span></span></code></pre></div>
<h2 data-number="14.2" id="figure-generation-code"><span
class="header-section-number">14.2</span> Figure Generation Code</h2>
<h3 data-number="14.2.1" id="figure-generation-code-snippets"><span
class="header-section-number">14.2.1</span> Figure Generation Code
Snippets</h3>
<p>The following code snippets illustrate the core commands used to
generate the figures. Full reproduction code is available in the EvoJump
repository.</p>
<h4 data-number="14.2.1.1"
id="comprehensive-model-comparison-figure-1"><span
class="header-section-number">14.2.1.1</span> Comprehensive Model
Comparison (Figure 1)</h4>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evojump <span class="im">as</span> ej</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create synthetic data for different stochastic processes</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_synthetic_data(seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate synthetic developmental trajectories</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    n_individuals, n_timepoints <span class="op">=</span> <span class="dv">100</span>, <span class="dv">100</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    time_points <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, n_timepoints)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    trajectories <span class="op">=</span> []</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_individuals):</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Base pattern with individual variation</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        base <span class="op">=</span> <span class="dv">10</span> <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> np.sin(time_points <span class="op">*</span> <span class="fl">0.5</span>) <span class="op">+</span> time_points <span class="op">*</span> <span class="fl">0.3</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="bu">len</span>(time_points))</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        trajectory <span class="op">=</span> base <span class="op">+</span> noise</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        trajectories.append(trajectory)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(trajectories), time_points</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data for each model type</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>fbm_trajectories, time_points <span class="op">=</span> create_synthetic_data(seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>cir_trajectories, _ <span class="op">=</span> create_synthetic_data(seed<span class="op">=</span><span class="dv">43</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>jump_trajectories, _ <span class="op">=</span> create_synthetic_data(seed<span class="op">=</span><span class="dv">44</span>)</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataCore objects</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>fbm_data <span class="op">=</span> ej.TimeSeriesData(fbm_trajectories, time_points, [<span class="st">&#39;phenotype&#39;</span>])</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>cir_data <span class="op">=</span> ej.TimeSeriesData(cir_trajectories, time_points, [<span class="st">&#39;phenotype&#39;</span>])</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>jump_data <span class="op">=</span> ej.TimeSeriesData(jump_trajectories, time_points, [<span class="st">&#39;phenotype&#39;</span>])</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit stochastic models</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>fbm_model <span class="op">=</span> ej.JumpRope.fit([fbm_data], model_type<span class="op">=</span><span class="st">&#39;fractional-brownian&#39;</span>, hurst<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>cir_model <span class="op">=</span> ej.JumpRope.fit([cir_data], model_type<span class="op">=</span><span class="st">&#39;cox-ingersoll-ross&#39;</span>)</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>jump_model <span class="op">=</span> ej.JumpRope.fit([jump_data], model_type<span class="op">=</span><span class="st">&#39;jump-diffusion&#39;</span>)</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate comprehensive model comparison (9 panels)</span></span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>visualizer <span class="op">=</span> ej.TrajectoryVisualizer()</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>visualizer.plot_model_comparison(</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>    [fbm_model, cir_model, jump_model],</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>    model_names<span class="op">=</span>[<span class="st">&#39;fBM&#39;</span>, <span class="st">&#39;CIR&#39;</span>, <span class="st">&#39;Jump-Diffusion&#39;</span>],</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>    output_path<span class="op">=</span><span class="st">&#39;figures/figure_1_comparison.png&#39;</span></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<h4 data-number="14.2.1.2"
id="comprehensive-trajectory-analysis-figure-2"><span
class="header-section-number">14.2.1.2</span> Comprehensive Trajectory
Analysis (Figure 2)</h4>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evojump <span class="im">as</span> ej</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate comprehensive 9-panel trajectory analysis</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>visualizer <span class="op">=</span> ej.TrajectoryVisualizer()</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>visualizer.plot_comprehensive_trajectories(</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    fbm_model,</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    output_path<span class="op">=</span><span class="st">&#39;figures/figure_2_comprehensive.png&#39;</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co">#### Individual Model Visualizations (Figure 3)</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evojump <span class="im">as</span> ej</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co"># ... (load data_core and fit fbm_model as above) ...</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>visualizer <span class="op">=</span> ej.TrajectoryVisualizer()</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>visualizer.plot_heatmap(</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    fbm_model,</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    time_resolution<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    phenotype_resolution<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    output_path<span class="op">=</span><span class="st">&#39;figures/figure_2_heatmap.png&#39;</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<h4 data-number="14.2.1.3" id="violin-plots-figure-3"><span
class="header-section-number">14.2.1.3</span> Violin Plots (Figure
3)</h4>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evojump <span class="im">as</span> ej</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ... (load data_core and fit cir_model as above) ...</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>visualizer <span class="op">=</span> ej.TrajectoryVisualizer()</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>visualizer.plot_violin(</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    cir_model,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    time_points<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>],</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    output_path<span class="op">=</span><span class="st">&#39;figures/figure_3_violin.png&#39;</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<h4 data-number="14.2.1.4" id="ridge-plot-figure-4"><span
class="header-section-number">14.2.1.4</span> Ridge Plot (Figure 4)</h4>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evojump <span class="im">as</span> ej</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ... (load data_core and fit levy_model as above) ...</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>visualizer <span class="op">=</span> ej.TrajectoryVisualizer()</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>visualizer.plot_ridge(</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    levy_model,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    n_distributions<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    output_path<span class="op">=</span><span class="st">&#39;figures/figure_4_ridge.png&#39;</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<h4 data-number="14.2.1.5" id="phase-portrait-figure-5"><span
class="header-section-number">14.2.1.5</span> Phase Portrait (Figure
5)</h4>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evojump <span class="im">as</span> ej</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ... (load data_core and fit fbm_model as above) ...</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>visualizer <span class="op">=</span> ej.TrajectoryVisualizer()</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>visualizer.plot_phase_portrait(</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    fbm_model,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    derivative_method<span class="op">=</span><span class="st">&#39;finite_difference&#39;</span>,</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    output_path<span class="op">=</span><span class="st">&#39;figures/figure_5_phase_portrait.png&#39;</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<h4 data-number="14.2.1.6" id="copula-analysis-figure-7"><span
class="header-section-number">14.2.1.6</span> Copula Analysis (Figure
7)</h4>
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evojump <span class="im">as</span> ej</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> rankdata, kendalltau</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_copula_analysis(model, output_path):</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Generate copula analysis showing trait dependence.&quot;&quot;&quot;</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    trajectories <span class="op">=</span> model.trajectories</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select two time points for bivariate analysis</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    time_indices <span class="op">=</span> [<span class="bu">len</span>(model.time_points)<span class="op">//</span><span class="dv">3</span>, <span class="dv">2</span><span class="op">*</span><span class="bu">len</span>(model.time_points)<span class="op">//</span><span class="dv">3</span>]</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    data_t1 <span class="op">=</span> trajectories[:, time_indices[<span class="dv">0</span>]]</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    data_t2 <span class="op">=</span> trajectories[:, time_indices[<span class="dv">1</span>]]</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform to uniform [0,1] scale using ranks</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> rankdata(data_t1) <span class="op">/</span> (<span class="bu">len</span>(data_t1) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> rankdata(data_t2) <span class="op">/</span> (<span class="bu">len</span>(data_t2) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create scatter plot</span></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>    scatter <span class="op">=</span> ax.scatter(u, v, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">50</span>, c<span class="op">=</span><span class="bu">range</span>(<span class="bu">len</span>(u)), cmap<span class="op">=</span><span class="st">&#39;viridis&#39;</span>)</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add diagonal reference line</span></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>    ax.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">&#39;r--&#39;</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">&#39;Perfect Dependence&#39;</span>)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate and display Kendall&#39;s tau</span></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>    tau, p_value <span class="op">=</span> kendalltau(data_t1, data_t2)</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.05</span>, <span class="fl">0.95</span>, <span class="ss">f&quot;Kendall&#39;s $</span><span class="ch">\\</span><span class="ss">tau$ = </span><span class="sc">{</span>tau<span class="sc">:.3f}</span><span class="ch">\\</span><span class="ss">n(p = </span><span class="sc">{</span>p_value<span class="sc">:.3f}</span><span class="ss">)&quot;</span>,</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>           transform<span class="op">=</span>ax.transAxes, fontsize<span class="op">=</span><span class="dv">12</span>,</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>           bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">&#39;round&#39;</span>, facecolor<span class="op">=</span><span class="st">&#39;white&#39;</span>, alpha<span class="op">=</span><span class="fl">0.8</span>))</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="ss">f&#39;Phenotype at t = </span><span class="sc">{</span>model<span class="sc">.</span>time_points[time_indices[<span class="dv">0</span>]]<span class="sc">:.2f}</span><span class="ss"> (Rank)&#39;</span>)</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="ss">f&#39;Phenotype at t = </span><span class="sc">{</span>model<span class="sc">.</span>time_points[time_indices[<span class="dv">1</span>]]<span class="sc">:.2f}</span><span class="ss"> (Rank)&#39;</span>)</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">&#39;Copula Analysis: Temporal Dependence Structure&#39;</span>)</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(scatter, ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">&#39;Individual Index&#39;</span>)</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>    plt.savefig(output_path, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">&#39;tight&#39;</span>)</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>    plt.close()</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate copula figure</span></span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>generate_copula_analysis(fbm_model, <span class="st">&#39;figures/figure_4_copula.png&#39;</span>)</span></code></pre></div>
<h3 data-number="14.2.2" id="technical-details-1"><span
class="header-section-number">14.2.2</span> Technical Details</h3>
<ul>
<li><strong>Data Generation</strong>: Synthetic developmental
trajectories for 100 individuals over 100 timepoints.</li>
<li><strong>Model Fitting</strong>: Maximum likelihood estimation for
all stochastic processes.</li>
<li><strong>Visualization Libraries</strong>: Matplotlib for static
plots, Plotly for interactive versions.</li>
<li><strong>Image Quality</strong>: 300 DPI PNG format for
publication.</li>
<li><strong>Color Schemes</strong>: Colorblind-friendly palettes used
throughout.</li>
</ul>
<h3 data-number="14.2.3" id="software-requirements"><span
class="header-section-number">14.2.3</span> Software Requirements</h3>
<ul>
<li>Python 3.8 or higher</li>
<li>NumPy 1.21.0 or higher</li>
<li>SciPy 1.7.0 or higher</li>
<li>Matplotlib 3.5.0 or higher</li>
<li>pandas 1.3.0 or higher</li>
<li>EvoJump 0.1.0 or higher</li>
</ul>
<h3 data-number="14.2.4" id="installation"><span
class="header-section-number">14.2.4</span> Installation</h3>
<div class="sourceCode" id="cb27"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using UV</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> add evojump</span></code></pre></div>
<h2 data-number="14.3" id="drosophila-case-study-code"><span
class="header-section-number">14.3</span> Drosophila Case Study
Code</h2>
<h3 data-number="14.3.1" id="population-configuration"><span
class="header-section-number">14.3.1</span> Population
Configuration</h3>
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Drosophila population for selective sweep analysis</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>population_config <span class="op">=</span> DrosophilaPopulation(</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    population_size<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    generations<span class="op">=</span><span class="dv">15</span>,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    initial_red_eyed_proportion<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    advantageous_trait_fitness<span class="op">=</span><span class="fl">1.2</span>,  <span class="co"># 20% fitness advantage</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    selection_coefficient<span class="op">=</span><span class="fl">0.1</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<h3 data-number="14.3.2" id="selection-simulation"><span
class="header-section-number">14.3.2</span> Selection Simulation</h3>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _simulate_selection(<span class="va">self</span>, current_red_eyed: <span class="bu">int</span>) <span class="op">-&gt;</span> <span class="bu">int</span>:</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Simulate one generation of selection and reproduction.&quot;&quot;&quot;</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    current_freq <span class="op">=</span> current_red_eyed <span class="op">/</span> <span class="va">self</span>.config.population_size</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Selection differential</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    mean_fitness <span class="op">=</span> (current_freq <span class="op">*</span> <span class="va">self</span>.config.advantageous_trait_fitness <span class="op">+</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>                   (<span class="dv">1</span> <span class="op">-</span> current_freq) <span class="op">*</span> <span class="fl">1.0</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># New frequency after selection</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    new_freq <span class="op">=</span> (current_freq <span class="op">*</span> <span class="va">self</span>.config.advantageous_trait_fitness) <span class="op">/</span> mean_fitness</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add genetic drift</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    drift <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="fl">0.01</span>)</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    new_freq <span class="op">=</span> np.clip(new_freq <span class="op">+</span> drift, <span class="fl">0.01</span>, <span class="fl">0.99</span>)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">int</span>(new_freq <span class="op">*</span> <span class="va">self</span>.config.population_size)</span></code></pre></div>
<h3 data-number="14.3.3" id="cross-sectional-analysis-1"><span
class="header-section-number">14.3.3</span> Cross-Sectional
Analysis</h3>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyze phenotypic distributions at key generations</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>analyzer <span class="op">=</span> LaserPlaneAnalyzer(model)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>stages <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">8</span>]  <span class="co"># Key generations</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> stage <span class="kw">in</span> stages:</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> analyzer.analyze_cross_section(time_point<span class="op">=</span><span class="bu">float</span>(stage))</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Stage </span><span class="sc">{</span>stage<span class="sc">}</span><span class="ss">: mean = </span><span class="sc">{</span>result<span class="sc">.</span>moments[<span class="st">&#39;mean&#39;</span>]<span class="sc">:.2f}</span><span class="ss">, &quot;</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>          <span class="ss">f&quot;std = </span><span class="sc">{</span>result<span class="sc">.</span>moments[<span class="st">&#39;std&#39;</span>]<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<h3 data-number="14.3.4" id="evolutionary-pattern-analysis-1"><span
class="header-section-number">14.3.4</span> Evolutionary Pattern
Analysis</h3>
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Population-level evolutionary pattern analysis</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>sampler <span class="op">=</span> EvolutionSampler(population_data)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>evolution_analysis <span class="op">=</span> sampler.analyze_evolutionary_patterns()</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>pop_stats <span class="op">=</span> evolution_analysis[<span class="st">&#39;population_statistics&#39;</span>]</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>genetic_params <span class="op">=</span> evolution_analysis[<span class="st">&#39;genetic_parameters&#39;</span>]</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Effective population size: </span><span class="sc">{</span>pop_stats<span class="sc">.</span>effective_population_size<span class="sc">:.0f}</span><span class="ss">&quot;</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Mean heritability: </span><span class="sc">{</span>np<span class="sc">.</span>mean(<span class="bu">list</span>(pop_stats.heritability_estimates.values()))<span class="sc">:.3f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<h3 data-number="14.3.5" id="network-analysis"><span
class="header-section-number">14.3.5</span> Network Analysis</h3>
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation network analysis for hitchhiking detection</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>network_results <span class="op">=</span> analytics.network_analysis(correlation_threshold<span class="op">=</span><span class="fl">0.6</span>)</span></code></pre></div>
<h3 data-number="14.3.6" id="bayesian-analysis"><span
class="header-section-number">14.3.6</span> Bayesian Analysis</h3>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bayesian uncertainty quantification for evolutionary parameters</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>bayesian_results <span class="op">=</span> analytics.bayesian_analysis(<span class="st">&#39;phenotype&#39;</span>, <span class="st">&#39;fitness&#39;</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;95% credible interval: </span><span class="sc">{</span>bayesian_results<span class="sc">.</span>credible_intervals[<span class="st">&#39;95%&#39;</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
</body>
</html>
